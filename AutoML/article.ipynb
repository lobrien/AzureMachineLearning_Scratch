{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Use automated ML in ML pipelines \n",
    "titleSuffix: Azure Machine Learning\n",
    "description: The AutoMLStep allows you to use automated machine learning in your pipelines.\n",
    "services: machine-learning\n",
    "ms.service: machine-learning\n",
    "ms.subservice: core\n",
    "ms.topic: conceptual\n",
    "ms.author: laobri\n",
    "author: lobrien\n",
    "manager: cgronlun\n",
    "ms.date: 04/28/2020\n",
    "\n",
    "---\n",
    "\n",
    "# Use automated ML in an Azure Machine Learning pipeline in Python\n",
    "[!INCLUDE [applies-to-skus](../../includes/aml-applies-to-basic-enterprise-sku.md)]\n",
    "\n",
    "Azure Machine Learning's automated ML capability helps you discover high-performing models without you reimplementing every possible approach. Combined with Azure Machine Learning pipelines, you can create deployable workflows that can quickly discover the algorithm that works best for your data. This article will show you how to efficiently join a data preparation step to an automated ML step. Automated ML can quickly discover the algorithm that works best for your data, while putting you on the road to MLOps and model lifecycle operationalization with pipelines.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* An Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning](https://aka.ms/AMLFree) today.\n",
    "\n",
    "* An Azure Machine Learning workspace. See [Create an Azure Machine Learning workspace](how-to-manage-workspace.md).  \n",
    "\n",
    "* Basic familiarity with Azure's [automated machine learning](concept-automated-ml.md) and [machine learning pipelines](concept-ml-pipelines.md) facilities and SDK.\n",
    "\n",
    "## Review automated ML's central classes\n",
    "\n",
    "Automated ML in a pipeline is represented by an `AutoMLStep` object. The `AutoMLStep` class is a subclass of `PipelineStep`. A graph of `PipelineStep` objects defines a `Pipeline`.\n",
    "\n",
    "There are several subclasses of `PipelineStep`. In addition to the `AutoMLStep`, this article will show a `PythonScriptStep` for data preparation and another for registering the model.\n",
    "\n",
    "The preferred way to initially move data _into_ an ML pipeline is with `Dataset` objects. To move data _between_ steps, the preferred way is with `PipelineData` objects. To be used with `AutoMLStep`, the `PipelineData` object must be transformed into a `PipelineOutputTabularDataset` object. For more information, see [Input and output data from ML pipelines](how-to-move-data-in-out-of-pipelines.md).\n",
    "\n",
    "The `AutoMLStep` is configured via an `AutoMLConfig` object. `AutoMLConfig` is a flexible class, as discussed in [Configure automated ML experiments in Python](https://docs.microsoft.com/azure/machine-learning/how-to-configure-auto-train#configure-your-experiment-settings). \n",
    "\n",
    "A `Pipeline` runs in an `Experiment`. The pipeline `Run` has, for each step, a child `StepRun`. The outputs of the automated ML `StepRun` are the training metrics and highest-performing model.\n",
    "\n",
    "To make things concrete, this article creates a simple pipeline for a classification task. The task is predicting Titanic survival, but we won't be discussing the data or task except in passing.\n",
    "\n",
    "## Get started\n",
    "\n",
    "### Retrieve initial dataset\n",
    "\n",
    "Often, an ML workflow starts with pre-existing baseline data. This is a good scenario for a registered dataset. Datasets are visible across the workspace, support versioning, and can be interactively explored. There are many ways to create and populate a dataset, as discussed in [Create Azure Machine Learning datasets](how-to-create-register-datasets.md). Since we'll be using the Python SDK to create our pipeline, use the SDK to download baseline data and register it with the name 'titanic_ds'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "import os\n",
    "\n",
    "ws = Workspace.from_config(auth=InteractiveLoginAuthentication(tenant_id=os.environ[\"AML_TENANT_ID\"]))\n",
    "#ws = Workspace.from_config()\n",
    "if not 'titanic_ds' in ws.datasets.keys() :\n",
    "    # create a TabularDataset from Titanic training data\n",
    "    web_paths = ['https://dprepdata.blob.core.windows.net/demo/Titanic.csv',\n",
    "                 'https://dprepdata.blob.core.windows.net/demo/Titanic2.csv']\n",
    "    titanic_ds = Dataset.Tabular.from_delimited_files(path=web_paths)\n",
    "\n",
    "    titanic_ds.register(workspace = ws,\n",
    "                                     name = 'titanic_ds',\n",
    "                                     description = 'Titanic baseline data',\n",
    "                                     create_new_version = True)\n",
    "\n",
    "titanic_ds = Dataset.get_by_name(ws, 'titanic_ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code first logs in to the Azure Machine Learning workspace defined in **config.json** (for an explanation, see [Tutorial: Get started creating your first ML experiment with the Python SDK](tutorial-1st-experiment-sdk-setup.md)). If there isn't already a dataset named `'titanic_ds'` registered, then it creates one. The code downloads CSV data from the Web, uses them to instantiate a `TabularDataset` and then registers the dataset with the workspace. Finally, the function `Dataset.get_by_name()` assigns the `Dataset` to `titanic_ds`. \n",
    "\n",
    "### Configure your storage and compute target\n",
    "\n",
    "Additional resources that the pipeline will need are storage and, generally, Azure Machine Learning compute resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "compute_name = 'cpu-compute3'\n",
    "if not compute_name in ws.compute_targets :\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                                min_nodes=0,\n",
    "                                                                max_nodes=1)\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # Show the result\n",
    "    print(compute_target.get_status().serialize())\n",
    "\n",
    "compute_target = ws.compute_targets[compute_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intermediate data between the data preparation and the automated ML step can be stored in the workspace's default datastore, so we don't need to do more than call `get_default_datastore()` on the `Workspace` object. \n",
    "\n",
    "After that, the code checks if the AML compute target `'cpu-cluster'` already exists. If not, we specify that we want a small CPU-based compute target. If you plan to use automated ML's deep learning features (for instance, text featurization with DNN support) you should choose a compute with strong GPU support, as described in [GPU optimized virtual machine sizes](https://docs.microsoft.com/azure/virtual-machines/sizes-gpu). \n",
    "\n",
    "The code blocks until the target is provisioned and then prints some details of the just-created compute target. Finally, the named compute target is retrieved from the workspace and assigned to `compute_target`. \n",
    "\n",
    "### Configure the training run\n",
    "\n",
    "The next step is making sure that the remote training run has all the dependencies that are required by the training steps. Dependencies and the runtime context are set by creating and configuring a `RunConfiguration` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "aml_run_config = RunConfiguration()\n",
    "# Use just-specified compute target (\"cpu-cluster\")\n",
    "aml_run_config.target = compute_target\n",
    "aml_run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# Add some packages relied on by data prep step\n",
    "aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=['pandas','scikit-learn'], \n",
    "    pip_packages=['azureml-sdk[automl,explain]', 'azureml-dataprep[fuse,pandas]'], \n",
    "    pin_sdk_version=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for automated machine learning\n",
    "\n",
    "### Write the data preparation code\n",
    "\n",
    "The baseline Titanic dataset consists of mixed numerical and text data, with some values missing. To prepare it for automated machine learning, the data preparation pipeline step will:\n",
    "\n",
    "- Fill missing data with either random data or a category corresponding to \"Unknown\"\n",
    "- Transform categorical data to integers\n",
    "- Drop columns that we don't intend to use\n",
    "- Split the data into training and testing sets\n",
    "- Write the transformed data to the `PipelineData` output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataprep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataprep.py\n",
    "from azureml.core import Run\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import argparse\n",
    "\n",
    "RANDOM_SEED=42\n",
    "\n",
    "def prepare_age(df):\n",
    "    # Fill in missing Age values from distribution of present Age values \n",
    "    mean = df[\"Age\"].mean()\n",
    "    std = df[\"Age\"].std()\n",
    "    is_null = df[\"Age\"].isnull().sum()\n",
    "    # compute enough (== is_null().sum()) random numbers between the mean, std\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    # fill NaN values in Age column with random values generated\n",
    "    age_slice = df[\"Age\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    df[\"Age\"] = age_slice\n",
    "    df[\"Age\"] = df[\"Age\"].astype(int)\n",
    "    \n",
    "    # Quantize age into 5 classes\n",
    "    df['Age_Group'] = pd.qcut(df['Age'],5, labels=False)\n",
    "    df.drop(['Age'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def prepare_fare(df):\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    df['Fare_Group'] = pd.qcut(df['Fare'],5,labels=False)\n",
    "    df.drop(['Fare'], axis=1, inplace=True)\n",
    "    return df \n",
    "\n",
    "def prepare_genders(df):\n",
    "    genders = {\"male\": 0, \"female\": 1, \"unknown\": 2}\n",
    "    df['Sex'] = df['Sex'].map(genders)\n",
    "    df['Sex'].fillna(2, inplace=True)\n",
    "    df['Sex'] = df['Sex'].astype(int)\n",
    "    return df\n",
    "\n",
    "def prepare_embarked(df):\n",
    "    df['Embarked'].replace('', 'U', inplace=True)\n",
    "    df['Embarked'].fillna('U', inplace=True)\n",
    "    ports = {\"S\": 0, \"C\": 1, \"Q\": 2, \"U\": 3}\n",
    "    df['Embarked'] = df['Embarked'].map(ports)\n",
    "    return df\n",
    "    \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_path', dest='output_path', required=True)\n",
    "args = parser.parse_args()\n",
    "    \n",
    "titanic_ds = Run.get_context().input_datasets['titanic_ds']\n",
    "df = titanic_ds.to_pandas_dataframe().drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "df = prepare_embarked(prepare_genders(prepare_fare(prepare_age(df))))\n",
    "\n",
    "os.makedirs(os.path.dirname(args.output_path), exist_ok=True)\n",
    "pq.write_table(pa.Table.from_pandas(df), args.output_path)\n",
    "\n",
    "print(f\"Wrote test to {args.output_path} and train to {args.output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code snippet is a complete, but minimal, example of data preparation for the Titanic data. The snippet starts with a Jupyter \"magic command\" to output the code to a file. If you aren't using a Jupyter notebook, remove that line and create the file manually.\n",
    "\n",
    "The various `prepare_` functions in the above snippet modify the relevant column in the input dataset. These functions work on the data once it has been changed into a Pandas `DataFrame` object. In each case, missing data is either filled with representative random data or categorical data indicating \"Unknown.\" Text-based categorical data is mapped to integers. No-longer-needed columns are overwritten or dropped. \n",
    "\n",
    "After the code defines the data preparation functions, the code parses the input argument, which is the path to which we want to write our data. (These values will be determined by `PipelineData` objects that will be discussed in the next step.) The code retrieves the registered `'titanic_cs'` `Dataset`, converts it to a Pandas `DataFrame`, and calls the various data preparation functions. \n",
    "\n",
    "Since the `output_path` is fully qualified, the function `os.makedirs()` is used to prepare the directory structure. At this point, you could use `DataFrame.to_csv()` to write the output data, but Parquet files are  more efficient. This efficiency would probably be irrelevant with such a small dataset, but using the **PyArrow** package's `from_pandas()` and `write_table()` functions are only a few more keystrokes than `to_csv()`.\n",
    "\n",
    "Parquet files are natively supported by the automated ML step discussed below, so no special processing is required to consume them. \n",
    "\n",
    "### Write the data preparation pipeline step (`PythonScriptStep`)\n",
    "\n",
    "The data preparation code described above must be associated with a `PythonScripStep` object to be used with a pipeline. The path to which the Parquet data-preparation output is written is generated by a `PipelineData` object. The resources prepared earlier, such as the `ComputeTarget`, the `RunConfig`, and the `'titanic_ds' Dataset` are used to complete the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "prepped_data_path = PipelineData(\"titanic_train\", datastore).as_dataset()\n",
    "prepped_data_path = PipelineData(\"titanic_train\", datastore).as_dataset()\n",
    "\n",
    "dataprep_step = PythonScriptStep(\n",
    "    name=\"dataprep\", \n",
    "    script_name=\"dataprep.py\", \n",
    "    compute_target=compute_target, \n",
    "    runconfig=aml_run_config,\n",
    "    arguments=[\"--output_path\", prepped_data_path],\n",
    "    inputs=[titanic_ds.as_named_input(\"titanic_ds\")],\n",
    "    outputs=[prepped_data_path],\n",
    "    allow_reuse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `prepped_data_path` object is of type `PipelineOutputFileDataset`. Notice that it's specified in both the `arguments` and `outputs` arguments. If you review the previous step, you'll see that within the data preparation code, the value of the argument `'--output_path'` is the file path to which the Parquet file was written. \n",
    "\n",
    "## Train with AutoMLStep\n",
    "\n",
    "Configuring an automated ML pipeline step is done with the `AutoMLConfig` class. This flexible class is described in [Configure automated ML experiments in Python](https://docs.microsoft.com/azure/machine-learning/how-to-configure-auto-train). Data input and output are the only aspects of configuration that require special attention in an ML pipeline. Input and output for `AutoMLConfig` in pipelines is discussed in detail below. Beyond data, an advantage of ML pipelines is the ability to use different compute targets for different steps. You might choose to use a more powerful `ComputeTarget` only for the automated ML process. Doing so is as straightforward as assigning a more powerful `RunConfiguration` to the `AutoMLConfig` object's `run_configuration` parameter.\n",
    "\n",
    "### Send data to `AutoMLStep`\n",
    "\n",
    "In an ML pipeline, the input data must be a `Dataset` object. The highest-performing way is to provide the input data in the form of `PipelineOutputTabularDataset` objects. You create an object of that type with the `parse_parquet_files()` or `parse_delimited_files()` on a `PipelineOutputFileDataset`, such as the `prepped_data_path` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(prepped_data_path) == PipelineOutputFileDataset\n",
    "# type(prepped_data) == PipelineOutputTabularDataset\n",
    "prepped_data = prepped_data_path.parse_parquet_files(file_extension=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snippet above creates a high-performing `PipelineOutputTabularDataset` from the `PipelineOutputFileDataset` output of the data preparation step.\n",
    "\n",
    "Another option is to use `Dataset` objects registered in the workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepped_data = Dataset.get_by_name(ws, 'Data_prepared')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the two techniques:\n",
    "\n",
    "| Technique |  | \n",
    "|-|-|\n",
    "|`PipelineOutputTabularDataset`| Higher performance | \n",
    "|| Natural route from `PipelineData` | \n",
    "|| Data isn't persisted after pipeline run |\n",
    "|| [Notebook showing `PipelineOutputTabularDataset` technique](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/nyc-taxi-data-regression-model-building/nyc-taxi-data-regression-model-building.ipynb) |\n",
    "| Registered `Dataset` | Lower performance |\n",
    "| | Can be generated in many ways | \n",
    "| | Data persists and is visible throughout workspace |\n",
    "| | [Notebook showing registered `Dataset` technique](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/automated-machine-learning/continuous-retraining/auto-ml-continuous-retraining.ipynb)\n",
    "\n",
    "### Specify automated ML outputs\n",
    "\n",
    "The outputs of the `AutoMLStep` are the final metric scores of the higher-performing model and that model itself. To use these outputs in further pipeline steps, prepare `PipelineData` objects to receive them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import TrainingOutput\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                           datastore=datastore,\n",
    "                           pipeline_output_name='metrics_output',\n",
    "                           training_output=TrainingOutput(type='Metrics'))\n",
    "model_data = PipelineData(name='best_model_data',\n",
    "                           datastore=datastore,\n",
    "                           pipeline_output_name='model_output',\n",
    "                           training_output=TrainingOutput(type='Model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snippet above creates the two `PipelineData` objects for the metrics and model output. Each is named, assigned to the default datastore retrieved earlier, and associated with the particular `type` of `TrainingOutput` from the `AutoMLStep`. \n",
    "\n",
    "### Configure and create the automated ML pipeline step\n",
    "\n",
    "Once the inputs and outputs are defined, it's time to create the `AutoMLConfig` and `AutoMLStep`. The details of the configuration will depend on your task, as described in [Configure automated ML experiments in Python](https://docs.microsoft.com/azure/machine-learning/how-to-configure-auto-train]). For the Titanic survival classification task, the following snippet demonstrates a simple configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "\n",
    "# Change iterations to a reasonable number (50) to get better accuracy\n",
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\" : 10,\n",
    "    \"iterations\" : 2,\n",
    "    \"experiment_timeout_hours\" : 0.25,\n",
    "    \"primary_metric\" : 'AUC_weighted'\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             path = '.',\n",
    "                             debug_log = 'automated_ml_errors.log',\n",
    "                             compute_target = compute_target,\n",
    "                             run_configuration = aml_run_config,\n",
    "                             featurization = 'auto',\n",
    "                             training_data = prepped_data,\n",
    "                             label_column_name = 'Survived',\n",
    "                             **automl_settings)\n",
    "\n",
    "train_step = AutoMLStep(name='AutoML_Classification',\n",
    "    automl_config=automl_config,\n",
    "    passthru_automl_config=False,\n",
    "    outputs=[metrics_data,model_data],\n",
    "    allow_reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snippet shows an idiom commonly used with `AutoMLConfig`. Arguments that are more fluid (hyperparameter-ish) are specified in a separate dictionary while the values less likely to change are specified directly in the `AutoMLConfig` constructor. In this case, the `automl_settings` specify a brief run: the run will stop after only 2 iterations or 15 minutes, whichever comes first.\n",
    "\n",
    "The `automl_settings` dictionary is passed to the `AutoMLConfig` constructor as kwargs. The other parameters aren't complex:\n",
    "\n",
    "- `task` is set to `classification` for this example. Other valid values are `regression` and `forecasting`\n",
    "- `path` and `debug_log` describe the path to the project and a local file to which debug information will be written \n",
    "- `compute_target` is the previously defined `compute_target` that, in this example, is an inexpensive CPU-based machine. If you're using AutoML's Deep Learning facilities, you would want to change the compute target to be GPU-based\n",
    "- `featurization` is set to `auto`. More details can be found in the [Data Featurization](https://docs.microsoft.com/azure/machine-learning/how-to-configure-auto-train#data-featurization) section of the automated ML configuration document \n",
    "- `training_data` is set to the `PipelineOutputTabularDataset` objects made from the outputs of the data preparation step \n",
    "- `label_column_name` indicates which column we are interested in predicting \n",
    "\n",
    "The `AutoMLStep` itself takes the `AutoMLConfig` and has, as outputs, the `PipelineData` objects created to hold the metrics and model data. \n",
    "\n",
    ">[!Important]\n",
    "> You must set `passthru_automl_config` to `False` if your `AutoMLStep` is using `PipelineOutputTabularDataset` objects for input.\n",
    "\n",
    "In this example, the automated ML process will perform cross-validations on the `training_data`. You can control the number of cross-validations with the `n_cross_validations` argument. If you've already split your training data as part of your data preparation steps, you can set `validation_data` to its own `Dataset`.\n",
    "\n",
    "You might occasionally see the use `X` for data features and `y` for data labels. This technique is deprecated and you should use `training_data` for input. \n",
    "\n",
    "## Register the model generated by automated ML \n",
    "\n",
    "The last step in a basic ML pipeline is registering the created model. By adding the model to the workspace's model registry, it will be available in the portal and can be versioned. To register the model, write another `PythonScriptStep` that takes the `model_data` output of the `AutoMLStep`.\n",
    "\n",
    "### Write the code to register the model\n",
    "\n",
    "A model is registered in a `Workspace`. You're probably familiar with using `Workspace.from_config()` to log on to your workspace on your local machine, but there's another way to get the workspace from within a running ML pipeline. The `Run.get_context()` retrieves the active `Run`. This `run` object provides access to many important objects, including the `Workspace` used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting register_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile register_model.py\n",
    "from azureml.core.model import Model, Dataset\n",
    "from azureml.core.run import Run, _OfflineRun\n",
    "from azureml.core import Workspace\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_name\", required=True)\n",
    "parser.add_argument(\"--model_path\", required=True)\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(f\"model_name : {args.model_name}\")\n",
    "print(f\"model_path: {args.model_path}\")\n",
    "\n",
    "run = Run.get_context()\n",
    "ws = Workspace.from_config() if type(run) == _OfflineRun else run.experiment.workspace\n",
    "\n",
    "model = Model.register(workspace=ws,\n",
    "                       model_path=args.model_path,\n",
    "                       model_name=args.model_name)\n",
    "\n",
    "print(\"Registered version {0} of model {1}\".format(model.version, model.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the PythonScriptStep code\n",
    "\n",
    "The model-registering `PythonScriptStep` uses a `PipelineParameter` for one of its arguments. Pipeline parameters are arguments to pipelines that can be easily set at run-submission time. Once declared, they're passed as normal arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "\n",
    "# The model name with which to register the trained model in the workspace.\n",
    "model_name = PipelineParameter(\"model_name\", default_value=\"TitanicSurvivalInitial\")\n",
    "\n",
    "register_step = PythonScriptStep(script_name=\"register_model.py\",\n",
    "                                       name=\"register_model\",\n",
    "                                       allow_reuse=False,\n",
    "                                       arguments=[\"--model_name\", model_name, \"--model_path\", model_data],\n",
    "                                       inputs=[model_data],\n",
    "                                       compute_target=compute_target,\n",
    "                                       runconfig=aml_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run your automated ML pipeline\n",
    "\n",
    "Creating and running a pipeline that contains an `AutoMLStep` is no different than a normal pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step dataprep [535fdcb1][6acdb23b-bba1-442d-bc41-99a37d43a304], (This step will run and generate new outputs)Created step AutoML_Classification [c29ef81e][371e2f74-f181-495f-8f12-2cee917ba054], (This step will run and generate new outputs)\n",
      "\n",
      "Created step register_model [35832e40][aaee60ca-1f20-4d11-8588-1d04101ed48f], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 3b6e6d42-a2bb-41bb-9a44-aba546e3acb4\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/3b6e6d42-a2bb-41bb-9a44-aba546e3acb4?wsid=/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourcegroups/laobri-ml/workspaces/pipelines\n",
      "PipelineRunId: 3b6e6d42-a2bb-41bb-9a44-aba546e3acb4\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/3b6e6d42-a2bb-41bb-9a44-aba546e3acb4?wsid=/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourcegroups/laobri-ml/workspaces/pipelines\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: cef54e28-eb18-4777-b8e3-4bd91e9e8be3\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/cef54e28-eb18-4777-b8e3-4bd91e9e8be3?wsid=/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourcegroups/laobri-ml/workspaces/pipelines\n",
      "StepRun( dataprep ) Status: NotStarted\n",
      "StepRun( dataprep ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2020/04/30 19:30:18 Downloading source code...\n",
      "2020/04/30 19:30:19 Finished downloading source code\n",
      "2020/04/30 19:30:20 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2020/04/30 19:30:20 Successfully set up Docker network: acb_default_network\n",
      "2020/04/30 19:30:20 Setting up Docker configuration...\n",
      "2020/04/30 19:30:21 Successfully set up Docker configuration\n",
      "2020/04/30 19:30:21 Logging in to registry: pipelines5112a485.azurecr.io\n",
      "2020/04/30 19:30:22 Successfully logged into pipelines5112a485.azurecr.io\n",
      "2020/04/30 19:30:22 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/04/30 19:30:22 Scanning for dependencies...\n",
      "2020/04/30 19:30:23 Successfully scanned dependencies\n",
      "2020/04/30 19:30:23 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  60.93kB\n",
      "\n",
      "Step 1/15 : FROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05: Pulling from azureml/base\n",
      "Digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      " ---> 93a72e6bd1ce\n",
      "Step 2/15 : USER root\n",
      " ---> Running in 62d9cbf222e8\n",
      "Removing intermediate container 62d9cbf222e8\n",
      " ---> aa6074f3543b\n",
      "Step 3/15 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 5e6aa6d47b8a\n",
      "Removing intermediate container 5e6aa6d47b8a\n",
      " ---> e399807845c4\n",
      "Step 4/15 : WORKDIR /\n",
      " ---> Running in 4e27355faf4d\n",
      "Removing intermediate container 4e27355faf4d\n",
      " ---> a2279ce91818\n",
      "Step 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> ace1215e2571\n",
      "Step 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in c2f682d453b6\n",
      "Removing intermediate container c2f682d453b6\n",
      " ---> 6378156a1e95\n",
      "Step 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> fe12a19814ac\n",
      "Step 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_a202ddab594f378a0a5fa176c4dadf6e -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in d4491a4d25a6\n",
      "Solving environment: ...working... \n",
      "done\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "setuptools-46.1.3    | 663 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "setuptools-46.1.3    | 663 KB    | #####9     |  60% \u001b[0m\u001b[91m\n",
      "setuptools-46.1.3    | 663 KB    | ########   |  80% \u001b[0m\u001b[91m\n",
      "setuptools-46.1.3    | 663 KB    | #########8 |  99% \u001b[0m\u001b[91m\n",
      "setuptools-46.1.3    | 663 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pandas-1.0.3         | 11.1 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "pandas-1.0.3         | 11.1 MB   | ##6        |  26% \u001b[0m\u001b[91m\n",
      "pandas-1.0.3         | 11.1 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "pandas-1.0.3         | 11.1 MB   | ########9  |  90% \u001b[0m\u001b[91m\n",
      "pandas-1.0.3         | 11.1 MB   | #########9 | 100% \u001b[0m\u001b[91m\n",
      "pandas-1.0.3         | 11.1 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "intel-openmp-2020.0  | 916 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "intel-openmp-2020.0  | 916 KB    | ########1  |  82% \u001b[0m\u001b[91m\n",
      "intel-openmp-2020.0  | 916 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "xz-5.2.5             | 438 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "xz-5.2.5             | 438 KB    | #########  |  90% \u001b[0m\u001b[91m\n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "tk-8.6.8             | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #######6   |  77% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #########9 |  99% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | #######6   |  76% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | #########4 |  94% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "six-1.14.0           | 27 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "six-1.14.0           | 27 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pip-20.0.2           | 1.9 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "pip-20.0.2           | 1.9 MB    | #######8   |  78% \u001b[0m\u001b[91m\n",
      "pip-20.0.2           | 1.9 MB    | #########3 |  93% \u001b[0m\u001b[91m\n",
      "pip-20.0.2           | 1.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl-2019.4           | 204.1 MB  |            |   0% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | 2          |   2% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | 4          |   4% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | 8          |   8% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #2         |  12% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #5         |  15% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #7         |  18% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ##         |  21% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ##3        |  23% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ##7        |  27% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ###        |  30% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ###2       |  33% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ###6       |  36% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ###8       |  39% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ####2      |  42% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ####4      |  45% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ####7      |  48% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #####      |  50% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #####3     |  53% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #####6     |  56% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #####9     |  59% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ######2    |  62% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ######5    |  66% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ######9    |  69% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #######3   |  73% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #######6   |  76% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #######8   |  79% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########   |  80% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########1  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########2  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########3  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########3  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########3  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########4  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########4  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########4  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########4  |  85% \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\n",
      "\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 387 KB    | #########1 |  91% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 387 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "blas-1.0             | 6 KB      |            |   0% \u001b[0m\u001b[91m\n",
      "blas-1.0             | 6 KB      | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | #######9   |  79% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | #########  |  90% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | #######6   |  77% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | #########4 |  95% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl-service-2.3.0    | 208 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "mkl-service-2.3.0    | 208 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ##3        |  23% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #######5   |  76% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #########  |  91% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl_random-1.1.0     | 369 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "mkl_random-1.1.0     | 369 KB    | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl_random-1.1.0     | 369 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "wheel-0.34.2         | 49 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "wheel-0.34.2         | 49 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | #######9   |  79% \u001b[0m\u001b[91m\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "libedit-3.1          | 171 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python-dateutil-2.8. | 224 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "python-dateutil-2.8. | 224 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "joblib-0.14.1        | 202 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "joblib-0.14.1        | 202 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "scipy-1.4.1          | 18.9 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | ##3        |  24% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | ######5    |  65% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | ########2  |  83% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | #########5 |  96% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl_fft-1.0.15       | 173 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "mkl_fft-1.0.15       | 173 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "scikit-learn-0.22.1  | 7.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.22.1  | 7.1 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.22.1  | 7.1 MB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.22.1  | 7.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "numpy-1.18.1         | 5 KB      |            |   0% \u001b[0m\u001b[91m\n",
      "numpy-1.18.1         | 5 KB      | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ca-certificates-2020 | 132 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ca-certificates-2020 | 132 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libffi-3.2.1         | 43 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "libffi-3.2.1         | 43 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pytz-2019.3          | 231 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "pytz-2019.3          | 231 KB    | #########  |  91% \u001b[0m\u001b[91m\n",
      "pytz-2019.3          | 231 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | 9          |   9% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ###        |  30% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #####4     |  55% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########6  |  87% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #########5 |  95% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | #######9   |  80% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "certifi-2020.4.5.1   | 159 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "certifi-2020.4.5.1   | 159 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "numpy-base-1.18.1    | 5.2 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "numpy-base-1.18.1    | 5.2 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "numpy-base-1.18.1    | 5.2 MB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "numpy-base-1.18.1    | 5.2 MB    | ########## | 100% \u001b[0m\n",
      "Downloading and Extracting Packages\n",
      "Preparing transaction: ...working... done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting azureml-sdk[automl,explain]\n",
      "  Downloading azureml_sdk-1.4.0-py3-none-any.whl (4.6 kB)\n",
      "Collecting azureml-dataprep[fuse,pandas]\n",
      "  Downloading azureml_dataprep-1.4.6-py3-none-any.whl (26.7 MB)\n",
      "Collecting azureml-train-automl-client~=1.4.0\n",
      "  Downloading azureml_train_automl_client-1.4.0-py3-none-any.whl (81 kB)\n",
      "Collecting azureml-train~=1.4.0\n",
      "  Downloading azureml_train-1.4.0-py3-none-any.whl (3.2 kB)\n",
      "Collecting azureml-pipeline~=1.4.0\n",
      "  Downloading azureml_pipeline-1.4.0-py3-none-any.whl (3.7 kB)\n",
      "Collecting azureml-core~=1.4.0\n",
      "  Downloading azureml_core-1.4.0.post1-py3-none-any.whl (1.3 MB)\n",
      "Collecting azureml-train-automl~=1.4.0; extra == \"automl\"\n",
      "  Downloading azureml_train_automl-1.4.0-py3-none-any.whl (3.4 kB)\n",
      "Collecting azureml-explain-model~=1.4.0; extra == \"explain\"\n",
      "  Downloading azureml_explain_model-1.4.0-py3-none-any.whl (22 kB)\n",
      "Collecting azureml-dataprep-native<15.0.0,>=14.1.0\n",
      "  Downloading azureml_dataprep_native-14.1.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting cloudpickle>=1.1.0\n",
      "  Downloading cloudpickle-1.4.1-py3-none-any.whl (26 kB)\n",
      "Collecting dotnetcore2>=2.1.13\n",
      "  Downloading dotnetcore2-2.1.13-py3-none-manylinux1_x86_64.whl (29.3 MB)\n",
      "Collecting azure-identity<1.3.0,>=1.2.0\n",
      "  Downloading azure_identity-1.2.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting fusepy>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0; extra == \"pandas\" in /azureml-envs/azureml_a202ddab594f378a0a5fa176c4dadf6e/lib/python3.6/site-packages (from azureml-dataprep[fuse,pandas]->-r /azureml-environment-setup/condaenv.x8e9k06a.requirements.txt (line 2)) (1.18.1)\n",
      "Requirement already satisfied: pandas>=0.23.4; extra == \"pandas\" in /azureml-envs/azureml_a202ddab594f378a0a5fa176c4dadf6e/lib/python3.6/site-packages (from azureml-dataprep[fuse,pandas]->-r /azureml-environment-setup/condaenv.x8e9k06a.requirements.txt (line 2)) (1.0.3)\n",
      "Collecting pyarrow>=0.15.*; extra == \"pandas\"\n",
      "  Downloading pyarrow-0.17.0-cp36-cp36m-manylinux2014_x86_64.whl (63.8 MB)\n",
      "Requirement already satisfied: pytz in /azureml-envs/azureml_a202ddab594f378a0a5fa176c4dadf6e/lib/python3.6/site-packages (from azureml-train-automl-client~=1.4.0->azureml-sdk[automl,explain]->-r /azureml-environment-setup/condaenv.x8e9k06a.requirements.txt (line 1)) (2019.3)\n",
      "Collecting azureml-automl-core~=1.4.0\n",
      "  Downloading azureml_automl_core-1.4.0-py3-none-any.whl (111 kB)\n",
      "Collecting azureml-telemetry~=1.4.0\n",
      "  Downloading azureml_telemetry-1.4.0-py3-none-any.whl (29 kB)\n",
      "Collecting azureml-train-core~=1.4.0\n",
      "  Downloading azureml_train_core-1.4.0-py3-none-any.whl (8.6 MB)\n",
      "Collecting azureml-pipeline-core~=1.4.0\n",
      "  Downloading azureml_pipeline_core-1.4.0-py3-none-any.whl (272 kB)\n",
      "Collecting azureml-pipeline-steps~=1.4.0\n",
      "  Downloading azureml_pipeline_steps-1.4.0-py3-none-any.whl (49 kB)\n",
      "Collecting pathspec\n",
      "  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting azure-graphrbac>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting requests>=2.19.1\n",
      "  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting SecretStorage\n",
      "  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting azure-mgmt-storage>=1.5.0\n",
      "  Downloading azure_mgmt_storage-9.0.0-py2.py3-none-any.whl (525 kB)\n",
      "Collecting ruamel.yaml<=0.15.89,>=0.15.35\n",
      "  Downloading ruamel.yaml-0.15.89-cp36-cp36m-manylinux1_x86_64.whl (651 kB)\n",
      "Collecting azure-mgmt-resource>=1.2.1\n",
      "  Downloading azure_mgmt_resource-9.0.0-py2.py3-none-any.whl (807 kB)\n",
      "Collecting adal>=1.2.0\n",
      "  Downloading adal-1.2.2-py2.py3-none-any.whl (53 kB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting azure-common>=1.1.12\n",
      "  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /azureml-envs/azureml_a202ddab594f378a0a5fa176c4dadf6e/lib/python3.6/site-packages (from azureml-core~=1.4.0->azureml-sdk[automl,explain]->-r /azureml-environment-setup/condaenv.x8e9k06a.requirements.txt (line 1)) (2.8.1)\n",
      "Collecting azure-mgmt-keyvault>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.25.9-py2.py3-none-any.whl (126 kB)\n",
      "Collecting pyopenssl\n",
      "  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting PyJWT\n",
      "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting azure-mgmt-authorization>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.60.0-py2.py3-none-any.whl (82 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-0.9.5-py2.py3-none-any.whl (24 kB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.3-py2.py3-none-any.whl (40 kB)\n",
      "Collecting docker\n",
      "  Downloading docker-4.2.0-py2.py3-none-any.whl (143 kB)\n",
      "Collecting msrest>=0.5.1\n",
      "  Downloading msrest-0.6.13-py2.py3-none-any.whl (83 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n",
      "  Downloading cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7 MB)\n",
      "Collecting azureml-train-automl-runtime~=1.4.0\n",
      "  Downloading azureml_train_automl_runtime-1.4.0.post1-py3-none-any.whl (81 kB)\n",
      "Collecting azureml-automl-runtime~=1.4.0\n",
      "  Downloading azureml_automl_runtime-1.4.0.post1-py3-none-any.whl (2.0 MB)\n",
      "Collecting azureml-interpret~=1.4.0\n",
      "  Downloading azureml_interpret-1.4.0-py3-none-any.whl (45 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.4.0-py2.py3-none-any.whl (114 kB)\n",
      "Requirement already satisfied: six>=1.6 in /azureml-envs/azureml_a202ddab594f378a0a5fa176c4dadf6e/lib/python3.6/site-packages (from azure-identity<1.3.0,>=1.2.0->azureml-dataprep[fuse,pandas]->-r /azureml-environment-setup/condaenv.x8e9k06a.requirements.txt (line 2)) (1.14.0)\n",
      "Collecting msal<2.0.0,>=1.0.0\n",
      "  Downloading msal-1.2.0-py2.py3-none-any.whl (46 kB)\n",
      "Collecting msal-extensions~=0.1.3\n",
      "  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting applicationinsights\n",
      "  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting azureml-train-restclients-hyperdrive~=1.4.0\n",
      "  Downloading azureml_train_restclients_hyperdrive-1.4.0-py3-none-any.whl (18 kB)\n",
      "Collecting flake8<=3.7.9,>=3.1.0; python_version >= \"3.6\"\n",
      "  Downloading flake8-3.7.9-py2.py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_a202ddab594f378a0a5fa176c4dadf6e/lib/python3.6/site-packages (from requests>=2.19.1->azureml-core~=1.4.0->azureml-sdk[automl,explain]->-r /azureml-environment-setup/condaenv.x8e9k06a.requirements.txt (line 1)) (2020.4.5.1)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting jeepney>=0.4.2\n",
      "  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-1.6.0-py2.py3-none-any.whl (30 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (399 kB)\n",
      "Collecting statsmodels<=0.10.2,>=0.9.0\n",
      "  Downloading statsmodels-0.10.2-cp36-cp36m-manylinux1_x86_64.whl (8.1 MB)\n",
      "Collecting smart-open<=1.9.0\n",
      "  Downloading smart_open-1.9.0.tar.gz (70 kB)\n",
      "Collecting scipy<=1.1.0,>=1.0.0\n",
      "  Downloading scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2 MB)\n",
      "Collecting dill>=0.2.8\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "Collecting scikit-learn<=0.20.3,>=0.19.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading scikit_learn-0.20.3-cp36-cp36m-manylinux1_x86_64.whl (5.4 MB)\n",
      "Collecting onnxmltools==1.4.1\n",
      "  Downloading onnxmltools-1.4.1-py2.py3-none-any.whl (371 kB)\n",
      "Collecting onnxruntime==1.0.0\n",
      "  Downloading onnxruntime-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (3.4 MB)\n",
      "Collecting lightgbm<=2.3.0,>=2.0.11\n",
      "  Downloading lightgbm-2.3.0-py2.py3-none-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting onnx<=1.6.0,>=1.5.0\n",
      "  Downloading onnx-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (4.8 MB)\n",
      "Collecting patsy>=0.5.1\n",
      "  Downloading patsy-0.5.1-py2.py3-none-any.whl (231 kB)\n",
      "Collecting wheel==0.30.0\n",
      "  Downloading wheel-0.30.0-py2.py3-none-any.whl (49 kB)\n",
      "Collecting sklearn-pandas<=1.7.0,>=1.4.0\n",
      "  Downloading sklearn_pandas-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting onnxconverter-common<=1.6.0,>=1.4.2\n",
      "  Downloading onnxconverter_common-1.6.0-py2.py3-none-any.whl (43 kB)\n",
      "Collecting skl2onnx==1.4.9\n",
      "  Downloading skl2onnx-1.4.9-py2.py3-none-any.whl (114 kB)\n",
      "Collecting azureml-defaults~=1.4.0\n",
      "  Downloading azureml_defaults-1.4.0-py3-none-any.whl (3.0 kB)\n",
      "Collecting resource>=0.1.8\n",
      "  Downloading Resource-0.2.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting gensim\n",
      "  Downloading gensim-3.8.2-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\n",
      "Collecting pmdarima==1.1.1\n",
      "  Downloading pmdarima-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (682 kB)\n",
      "Collecting psutil<6.0.0,>=5.2.2\n",
      "  Downloading psutil-5.7.0.tar.gz (449 kB)\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py-cpuinfo-5.0.0.tar.gz (82 kB)\n",
      "Collecting nimbusml>=1.5.0\n",
      "  Downloading nimbusml-1.7.0-cp36-none-manylinux1_x86_64.whl (116.2 MB)\n",
      "Collecting interpret-community==0.10.*\n",
      "  Downloading interpret_community-0.10.2-py3-none-any.whl (5.4 MB)\n",
      "Collecting portalocker~=1.0\n",
      "  Downloading portalocker-1.7.0-py2.py3-none-any.whl (14 kB)\n",
      "Collecting pyflakes<2.2.0,>=2.1.0\n",
      "  Downloading pyflakes-2.1.1-py2.py3-none-any.whl (59 kB)\n",
      "Collecting entrypoints<0.4.0,>=0.3.0\n",
      "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pycodestyle<2.6.0,>=2.5.0\n",
      "  Downloading pycodestyle-2.5.0-py2.py3-none-any.whl (51 kB)\n",
      "Collecting mccabe<0.7.0,>=0.6.0\n",
      "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting boto>=2.32\n",
      "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.13.0-py2.py3-none-any.whl (128 kB)\n",
      "Collecting keras2onnx\n",
      "  Downloading keras2onnx-1.6.1-py3-none-any.whl (220 kB)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting typing-extensions>=3.6.2.1\n",
      "  Downloading typing_extensions-3.7.4.2-py3-none-any.whl (22 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting gunicorn==19.9.0\n",
      "  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\n",
      "Collecting werkzeug==0.16.1\n",
      "  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\n",
      "Collecting JsonForm>=0.0.2\n",
      "  Downloading JsonForm-0.0.2.tar.gz (2.4 kB)\n",
      "Collecting python-easyconfig>=0.1.0\n",
      "  Downloading Python_EasyConfig-0.1.7-py2.py3-none-any.whl (5.4 kB)\n",
      "Collecting JsonSir>=0.0.2\n",
      "  Downloading JsonSir-0.0.2.tar.gz (2.2 kB)\n",
      "Collecting Cython>=0.29\n",
      "  Downloading Cython-0.29.17-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\n",
      "Collecting shap<=0.34.0,>=0.20.0\n",
      "  Downloading shap-0.34.0.tar.gz (264 kB)\n",
      "Collecting packaging\n",
      "  Downloading packaging-20.3-py2.py3-none-any.whl (37 kB)\n",
      "Collecting interpret-core[required]<=0.1.21,>=0.1.20\n",
      "  Downloading interpret_core-0.1.21-py3-none-any.whl (8.3 MB)\n",
      "Collecting botocore<1.17.0,>=1.16.0\n",
      "  Downloading botocore-1.16.0-py2.py3-none-any.whl (6.2 MB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Collecting fire\n",
      "  Downloading fire-0.3.1.tar.gz (81 kB)\n",
      "Requirement already satisfied: setuptools in /azureml-envs/azureml_a202ddab594f378a0a5fa176c4dadf6e/lib/python3.6/site-packages (from protobuf->onnxmltools==1.4.1->azureml-train-automl-runtime~=1.4.0->azureml-train-automl~=1.4.0; extra == \"automl\"->azureml-sdk[automl,explain]->-r /azureml-environment-setup/condaenv.x8e9k06a.requirements.txt (line 1)) (46.1.3.post20200330)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Downloading liac-arff-2.4.0.tar.gz (15 kB)\n",
      "Collecting jsonschema\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting PyYAML\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "Collecting tqdm>4.25.0\n",
      "  Downloading tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: joblib>=0.11; extra == \"required\" in /azureml-envs/azureml_a202ddab594f378a0a5fa176c4dadf6e/lib/python3.6/site-packages (from interpret-core[required]<=0.1.21,>=0.1.20->interpret-community==0.10.*->azureml-interpret~=1.4.0->azureml-explain-model~=1.4.0; extra == \"explain\"->azureml-sdk[automl,explain]->-r /azureml-environment-setup/condaenv.x8e9k06a.requirements.txt (line 1)) (0.14.1)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.16.0.tar.gz (108 kB)\n",
      "Collecting attrs>=17.4.0\n",
      "  Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
      "Building wheels for collected packages: fusepy, smart-open, dill, psutil, py-cpuinfo, json-logging-py, JsonForm, JsonSir, shap, fire, liac-arff, PyYAML, termcolor, pyrsistent\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=93dd1864221d8e6c7dd514cba111ed35f27e70a879f891936491e7afb66ed364\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "  Building wheel for smart-open (setup.py): started\n",
      "  Building wheel for smart-open (setup.py): finished with status 'done'\n",
      "  Created wheel for smart-open: filename=smart_open-1.9.0-py3-none-any.whl size=73085 sha256=5baa824cd45732d18a25ea0504f47ba4afecb4067ea4fd66eb0277f9e8cd6e42\n",
      "  Stored in directory: /root/.cache/pip/wheels/8e/9f/cd/dbf5c1362c59abb699a218c1151679033b8ccb5b6db559d512\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78530 sha256=6cb2e79942206eeaa60dc6428423be65bcbbf3202dfb4be512525fda4321598c\n",
      "  Stored in directory: /root/.cache/pip/wheels/09/84/74/d2b4feb9ac9488bc83c475cb2cbe8e8b7d9cea8320d32f3787\n",
      "  Building wheel for psutil (setup.py): started\n",
      "  Building wheel for psutil (setup.py): finished with status 'done'\n",
      "  Created wheel for psutil: filename=psutil-5.7.0-cp36-cp36m-linux_x86_64.whl size=260180 sha256=c1e686a945b011e08f1b4b28fddf9b596939370d57c3b3889d0e6c92a996d3cb\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/d9/f2/b5620c01e9b3e858c6877b1045fda5b115cf7df6490f883382\n",
      "  Building wheel for py-cpuinfo (setup.py): started\n",
      "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
      "  Created wheel for py-cpuinfo: filename=py_cpuinfo-5.0.0-py3-none-any.whl size=18682 sha256=2c1da027c7a35193b38af6eb61487969204806b695a926ff3c05a3c8d07be2fe\n",
      "  Stored in directory: /root/.cache/pip/wheels/e6/54/db/65176a1697a583d8ec5f90510f6faab11cda739d0e4f0ba2ea\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3923 sha256=9f0a2893ba9e3f0c2721859455906466d2140056cb31c01663ce45d1a286f8db\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for JsonForm (setup.py): started\n",
      "  Building wheel for JsonForm (setup.py): finished with status 'done'\n",
      "  Created wheel for JsonForm: filename=JsonForm-0.0.2-py3-none-any.whl size=3325 sha256=4b60247412cb48424b2e7028a5b45626765088b8ff4f4b792e4a7360cd500feb\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/f9/2d/61747ec74e70a079a428c54fc1167b03a4198a2e2ac4be5f07\n",
      "  Building wheel for JsonSir (setup.py): started\n",
      "  Building wheel for JsonSir (setup.py): finished with status 'done'\n",
      "  Created wheel for JsonSir: filename=JsonSir-0.0.2-py3-none-any.whl size=4774 sha256=c2123c6ec56e77c5f2f6af781c4cba23237517d78421df4ae3306d38f790455a\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/42/c2/d3cd8ea9f896260294ea5fbeb985905e81654b670d7753a419\n",
      "  Building wheel for shap (setup.py): started\n",
      "  Building wheel for shap (setup.py): finished with status 'done'\n",
      "  Created wheel for shap: filename=shap-0.34.0-cp36-cp36m-linux_x86_64.whl size=387820 sha256=a874eeb8007b7486c923c9a6f14f10aff615438e2e8973ee22a355cbe793f831\n",
      "  Stored in directory: /root/.cache/pip/wheels/88/56/c6/630b200696678c506f3057a1e7573c086e50d59fdcffcbfd04\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=4960d66e1ee7c9ed451e1870cf46632c14a2849c2354a970fb283978e884957f\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/38/8f/e5bd4465e4b72c8e4d1530ac46e1a42e1d2495f8c93242d5f1\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.4.0-py3-none-any.whl size=13333 sha256=a5f3714e16200c6d4424b5cf6c617c4eb5dd17e64a25339bbbdc830cb6b8e739\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/2a/e1/6f7be2e2ea150e2486bff64fd6f0670f4f35f4c8f31c819fb8\n",
      "  Building wheel for PyYAML (setup.py): started\n",
      "  Building wheel for PyYAML (setup.py): finished with status 'done'\n",
      "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=172d2ac1ac45eff5d4528dd9d91c676ab2f3444860f2df8c3b2f6ceed698e81a\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/9d/ad/2ee53cf262cba1ffd8afe1487eef788ea3f260b7e6232a80fc\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=4b88509ab508a8a4c22c89a9c5af7ce20f96c7f0ac62eb2fe26d5f1e675c0a20\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for pyrsistent (setup.py): started\n",
      "  Building wheel for pyrsistent (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created wheel for pyrsistent: filename=pyrsistent-0.16.0-cp36-cp36m-linux_x86_64.whl size=113431 sha256=733135b68b1cf3b7a6c8833ff12e2694b791226351c0418e5d51ab2a57b5627b\n",
      "  Stored in directory: /root/.cache/pip/wheels/d1/8a/1c/32ab9017418a2c64e4fbaf503c08648bed2f8eb311b869a464\n",
      "Successfully built fusepy smart-open dill psutil py-cpuinfo json-logging-py JsonForm JsonSir shap fire liac-arff PyYAML termcolor pyrsistent\n",
      "\u001b[91mERROR: azureml-automl-runtime 1.4.0.post1 has requirement numpy<=1.16.2,>=1.16.0, but you'll have numpy 1.18.1 which is incompatible.\n",
      "\u001b[0m\u001b[91mERROR: azureml-automl-runtime 1.4.0.post1 has requirement pandas<=0.23.4,>=0.21.0, but you'll have pandas 1.0.3 which is incompatible.\n",
      "ERROR: azureml-train-automl-runtime 1.4.0.post1 has requirement numpy<=1.16.2,>=1.16.0, but you'll have numpy 1.18.1 which is incompatible.\n",
      "\u001b[0m\u001b[91mERROR: azureml-train-automl-runtime 1.4.0.post1 has requirement pandas<=0.23.4,>=0.21.0, but you'll have pandas 1.0.3 which is incompatible.\n",
      "\u001b[0mInstalling collected packages: azureml-dataprep-native, cloudpickle, distro, dotnetcore2, urllib3, chardet, idna, requests, azure-core, pycparser, cffi, cryptography, PyJWT, msal, portalocker, msal-extensions, azure-identity, fusepy, pyarrow, azureml-dataprep, azureml-automl-core, applicationinsights, pathspec, oauthlib, requests-oauthlib, isodate, msrest, adal, msrestazure, azure-common, azure-graphrbac, jeepney, SecretStorage, azure-mgmt-storage, ruamel.yaml, azure-mgmt-resource, zipp, importlib-metadata, jsonpickle, contextlib2, azure-mgmt-keyvault, backports.weakref, backports.tempfile, azure-mgmt-containerregistry, pyopenssl, azure-mgmt-authorization, pyasn1, ndg-httpsclient, jmespath, websocket-client, docker, azureml-core, azureml-telemetry, azureml-train-automl-client, azureml-train-restclients-hyperdrive, pyflakes, entrypoints, pycodestyle, mccabe, flake8, azureml-train-core, azureml-train, azureml-pipeline-core, azureml-pipeline-steps, azureml-pipeline, scipy, patsy, statsmodels, boto, docutils, botocore, s3transfer, boto3, smart-open, dill, scikit-learn, typing-extensions, protobuf, onnx, onnxconverter-common, termcolor, fire, keras2onnx, skl2onnx, onnxmltools, onnxruntime, lightgbm, Cython, pmdarima, psutil, wheel, sklearn-pandas, gensim, pyrsistent, attrs, jsonschema, JsonForm, PyYAML, python-easyconfig, JsonSir, resource, py-cpuinfo, nimbusml, azureml-automl-runtime, tqdm, shap, pyparsing, packaging, interpret-core, interpret-community, azureml-interpret, azureml-explain-model, click, MarkupSafe, Jinja2, itsdangerous, werkzeug, flask, configparser, json-logging-py, liac-arff, azureml-model-management-sdk, gunicorn, azureml-defaults, azureml-train-automl-runtime, azureml-train-automl, azureml-sdk\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "Successfully installed Cython-0.29.17 Jinja2-2.11.2 JsonForm-0.0.2 JsonSir-0.0.2 MarkupSafe-1.1.1 PyJWT-1.7.1 PyYAML-5.3.1 SecretStorage-3.1.2 adal-1.2.2 applicationinsights-0.11.9 attrs-19.3.0 azure-common-1.1.25 azure-core-1.4.0 azure-graphrbac-0.61.1 azure-identity-1.2.0 azure-mgmt-authorization-0.60.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-9.0.0 azure-mgmt-storage-9.0.0 azureml-automl-core-1.4.0 azureml-automl-runtime-1.4.0.post1 azureml-core-1.4.0.post1 azureml-dataprep-1.4.6 azureml-dataprep-native-14.1.0 azureml-defaults-1.4.0 azureml-explain-model-1.4.0 azureml-interpret-1.4.0 azureml-model-management-sdk-1.0.1b6.post1 azureml-pipeline-1.4.0 azureml-pipeline-core-1.4.0 azureml-pipeline-steps-1.4.0 azureml-sdk-1.4.0 azureml-telemetry-1.4.0 azureml-train-1.4.0 azureml-train-automl-1.4.0 azureml-train-automl-client-1.4.0 azureml-train-automl-runtime-1.4.0.post1 azureml-train-core-1.4.0 azureml-train-restclients-hyperdrive-1.4.0 backports.tempfile-1.0 backports.weakref-1.0.post1 boto-2.49.0 boto3-1.13.0 botocore-1.16.0 cffi-1.14.0 chardet-3.0.4 click-7.1.2 cloudpickle-1.4.1 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-2.9.2 dill-0.3.1.1 distro-1.5.0 docker-4.2.0 docutils-0.15.2 dotnetcore2-2.1.13 entrypoints-0.3 fire-0.3.1 flake8-3.7.9 flask-1.0.3 fusepy-3.0.1 gensim-3.8.2 gunicorn-19.9.0 idna-2.9 importlib-metadata-1.6.0 interpret-community-0.10.2 interpret-core-0.1.21 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.4.3 jmespath-0.9.5 json-logging-py-0.2 jsonpickle-1.4.1 jsonschema-3.2.0 keras2onnx-1.6.1 liac-arff-2.4.0 lightgbm-2.3.0 mccabe-0.6.1 msal-1.2.0 msal-extensions-0.1.3 msrest-0.6.13 msrestazure-0.6.3 ndg-httpsclient-0.5.1 nimbusml-1.7.0 oauthlib-3.1.0 onnx-1.6.0 onnxconverter-common-1.6.0 onnxmltools-1.4.1 onnxruntime-1.0.0 packaging-20.3 pathspec-0.8.0 patsy-0.5.1 pmdarima-1.1.1 portalocker-1.7.0 protobuf-3.11.3 psutil-5.7.0 py-cpuinfo-5.0.0 pyarrow-0.17.0 pyasn1-0.4.8 pycodestyle-2.5.0 pycparser-2.20 pyflakes-2.1.1 pyopenssl-19.1.0 pyparsing-2.4.7 pyrsistent-0.16.0 python-easyconfig-0.1.7 requests-2.23.0 requests-oauthlib-1.3.0 resource-0.2.1 ruamel.yaml-0.15.89 s3transfer-0.3.3 scikit-learn-0.20.3 scipy-1.1.0 shap-0.34.0 skl2onnx-1.4.9 sklearn-pandas-1.7.0 smart-open-1.9.0 statsmodels-0.10.2 termcolor-1.1.0 tqdm-4.45.0 typing-extensions-3.7.4.2 urllib3-1.25.9 websocket-client-0.57.0 werkzeug-0.16.1 wheel-0.30.0 zipp-3.1.0\n",
      "\u001b[91m\n",
      "\u001b[0m#\n",
      "# To activate this environment, use:\n",
      "# > source activate /azureml-envs/azureml_a202ddab594f378a0a5fa176c4dadf6e\n",
      "#\n",
      "# To deactivate an active environment, use:\n",
      "# > source deactivate\n",
      "#\n",
      "\n",
      "\n",
      "Removing intermediate container d4491a4d25a6\n",
      " ---> 81a3b8e861e4\n",
      "Step 9/15 : ENV PATH /azureml-envs/azureml_a202ddab594f378a0a5fa176c4dadf6e/bin:$PATH\n",
      " ---> Running in 835eed7d9840\n",
      "Removing intermediate container 835eed7d9840\n",
      " ---> a34620859bc4\n",
      "Step 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_a202ddab594f378a0a5fa176c4dadf6e\n",
      " ---> Running in 72c399921f84\n",
      "Removing intermediate container 72c399921f84\n",
      " ---> b1877a75855c\n",
      "Step 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_a202ddab594f378a0a5fa176c4dadf6e/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 14c5b39c5410\n",
      "Removing intermediate container 14c5b39c5410\n",
      " ---> 1ca5db20f2df\n",
      "Step 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 30e9a08327f6\n",
      "Step 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit \"--repositories\" \"[]\" /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 978fa87fec81\n",
      "Removing intermediate container 978fa87fec81\n",
      " ---> 490179b1a0bb\n",
      "Step 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 075f83ddfda4\n",
      "Removing intermediate container 075f83ddfda4\n",
      " ---> 44d2a766a6f1\n",
      "Step 15/15 : CMD [\"bash\"]\n",
      " ---> Running in ab700bf36414\n",
      "Removing intermediate container ab700bf36414\n",
      " ---> 210e19492b08\n",
      "Successfully built 210e19492b08\n",
      "Successfully tagged pipelines5112a485.azurecr.io/azureml/azureml_9e6164fd71967baaa1312ba8f229b985:latest\n",
      "2020/04/30 19:36:31 Successfully executed container: acb_step_0\n",
      "2020/04/30 19:36:31 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/04/30 19:36:31 Pushing image: pipelines5112a485.azurecr.io/azureml/azureml_9e6164fd71967baaa1312ba8f229b985:latest, attempt 1\n",
      "The push refers to repository [pipelines5112a485.azurecr.io/azureml/azureml_9e6164fd71967baaa1312ba8f229b985]\n",
      "2b2f7be18b78: Preparing\n",
      "2521d52a0016: Preparing\n",
      "852cc6284e59: Preparing\n",
      "2c7111af506a: Preparing\n",
      "54f92714d9d2: Preparing\n",
      "99f969179b35: Preparing\n",
      "e1171d4d60ca: Preparing\n",
      "6ef1a8ae63b7: Preparing\n",
      "85389f9ead9e: Preparing\n",
      "f2608f66a0e3: Preparing\n",
      "0e259b09e5f4: Preparing\n",
      "340dc32eb998: Preparing\n",
      "df18b66efaa6: Preparing\n",
      "ccdb13a20bf2: Preparing\n",
      "9513cdf4e497: Preparing\n",
      "7f083f9454c0: Preparing\n",
      "29f36b5893dc: Preparing\n",
      "99f969179b35: Waiting\n",
      "e1171d4d60ca: Waiting\n",
      "6ef1a8ae63b7: Waiting\n",
      "85389f9ead9e: Waiting\n",
      "f2608f66a0e3: Waiting\n",
      "0e259b09e5f4: Waiting\n",
      "340dc32eb998: Waiting\n",
      "df18b66efaa6: Waiting\n",
      "ccdb13a20bf2: Waiting\n",
      "9513cdf4e497: Waiting\n",
      "7f083f9454c0: Waiting\n",
      "29f36b5893dc: Waiting\n",
      "2b2f7be18b78: Pushed\n",
      "852cc6284e59: Pushed\n",
      "54f92714d9d2: Pushed\n",
      "2c7111af506a: Pushed\n",
      "99f969179b35: Pushed\n",
      "e1171d4d60ca: Pushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6ef1a8ae63b7: Pushed\n",
      "\n",
      "340dc32eb998: Pushed\n",
      "0e259b09e5f4: Pushed\n",
      "f2608f66a0e3: Pushed\n",
      "ccdb13a20bf2: Pushed\n",
      "85389f9ead9e: Pushed\n",
      "7f083f9454c0: Pushed\n",
      "9513cdf4e497: Pushed\n",
      "\n",
      "df18b66efaa6: Pushed\n",
      "29f36b5893dc: Pushed\n",
      "\n",
      "2521d52a0016: Pushed\n",
      "latest: digest: sha256:5b004cd97a92a3162bda4fa8ed9e229951c729356e3cb18932f1056d7c5b76b9 size: 3883\n",
      "2020/04/30 19:40:01 Successfully pushed image: pipelines5112a485.azurecr.io/azureml/azureml_9e6164fd71967baaa1312ba8f229b985:latest\n",
      "2020/04/30 19:40:01 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 368.984865)\n",
      "2020/04/30 19:40:01 Populating digests for step ID: acb_step_0...\n",
      "2020/04/30 19:40:07 Successfully populated digests for step ID: acb_step_0\n",
      "2020/04/30 19:40:07 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 210.356309)\n",
      "2020/04/30 19:40:07 The following dependencies were found:\n",
      "2020/04/30 19:40:07 \n",
      "- image:\n",
      "    registry: pipelines5112a485.azurecr.io\n",
      "    repository: azureml/azureml_9e6164fd71967baaa1312ba8f229b985\n",
      "    tag: latest\n",
      "    digest: sha256:5b004cd97a92a3162bda4fa8ed9e229951c729356e3cb18932f1056d7c5b76b9\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/base\n",
      "    tag: intelmpi2018.3-ubuntu16.04\n",
      "    digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "  git: {}\n",
      "\n",
      "Run ID: cf10 was successful after 9m51s\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_f0d520f7639287c602de235af131aca33db2ce9dc4f743c012d7737c12923ad3_d.txt\n",
      "========================================================================================================================\n",
      "2020-04-30T19:43:48Z Starting output-watcher...\n",
      "2020-04-30T19:43:48Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_9e6164fd71967baaa1312ba8f229b985\n",
      "a1298f4ce990: Pulling fs layer\n",
      "04a3282d9c4b: Pulling fs layer\n",
      "9b0d3db6dc03: Pulling fs layer\n",
      "8269c605f3f1: Pulling fs layer\n",
      "6504d449e70c: Pulling fs layer\n",
      "4e38f320d0d4: Pulling fs layer\n",
      "b0a763e8ee03: Pulling fs layer\n",
      "11917a028ca4: Pulling fs layer\n",
      "a6c378d11cbf: Pulling fs layer\n",
      "6cc007ad9140: Pulling fs layer\n",
      "6c1698a608f3: Pulling fs layer\n",
      "4b7ba328fa59: Pulling fs layer\n",
      "4a5d4845a6f1: Pulling fs layer\n",
      "e668bdd76b0b: Pulling fs layer\n",
      "0d343adad32a: Pulling fs layer\n",
      "3d345b71059d: Pulling fs layer\n",
      "274f64fcccf7: Pulling fs layer\n",
      "8269c605f3f1: Waiting\n",
      "6504d449e70c: Waiting\n",
      "4e38f320d0d4: Waiting\n",
      "b0a763e8ee03: Waiting\n",
      "11917a028ca4: Waiting\n",
      "a6c378d11cbf: Waiting\n",
      "6cc007ad9140: Waiting\n",
      "6c1698a608f3: Waiting\n",
      "4b7ba328fa59: Waiting\n",
      "4a5d4845a6f1: Waiting\n",
      "e668bdd76b0b: Waiting\n",
      "0d343adad32a: Waiting\n",
      "3d345b71059d: Waiting\n",
      "274f64fcccf7: Waiting\n",
      "04a3282d9c4b: Verifying Checksum\n",
      "04a3282d9c4b: Download complete\n",
      "9b0d3db6dc03: Download complete\n",
      "8269c605f3f1: Verifying Checksum\n",
      "8269c605f3f1: Download complete\n",
      "a1298f4ce990: Verifying Checksum\n",
      "a1298f4ce990: Download complete\n",
      "4e38f320d0d4: Verifying Checksum\n",
      "4e38f320d0d4: Download complete\n",
      "6504d449e70c: Verifying Checksum\n",
      "6504d449e70c: Download complete\n",
      "b0a763e8ee03: Verifying Checksum\n",
      "b0a763e8ee03: Download complete\n",
      "6cc007ad9140: Verifying Checksum\n",
      "6cc007ad9140: Download complete\n",
      "6c1698a608f3: Verifying Checksum\n",
      "6c1698a608f3: Download complete\n",
      "a6c378d11cbf: Verifying Checksum\n",
      "a6c378d11cbf: Download complete\n",
      "11917a028ca4: Verifying Checksum\n",
      "11917a028ca4: Download complete\n",
      "4b7ba328fa59: Verifying Checksum\n",
      "4b7ba328fa59: Download complete\n",
      "4a5d4845a6f1: Verifying Checksum\n",
      "4a5d4845a6f1: Download complete\n",
      "0d343adad32a: Verifying Checksum\n",
      "0d343adad32a: Download complete\n",
      "e668bdd76b0b: Verifying Checksum\n",
      "e668bdd76b0b: Download complete\n",
      "a1298f4ce990: Pull complete\n",
      "04a3282d9c4b: Pull complete\n",
      "274f64fcccf7: Verifying Checksum\n",
      "274f64fcccf7: Download complete\n",
      "9b0d3db6dc03: Pull complete\n",
      "8269c605f3f1: Pull complete\n",
      "3d345b71059d: Verifying Checksum\n",
      "3d345b71059d: Download complete\n",
      "6504d449e70c: Pull complete\n",
      "4e38f320d0d4: Pull complete\n",
      "b0a763e8ee03: Pull complete\n",
      "11917a028ca4: Pull complete\n",
      "a6c378d11cbf: Pull complete\n",
      "6cc007ad9140: Pull complete\n",
      "6c1698a608f3: Pull complete\n",
      "4b7ba328fa59: Pull complete\n",
      "4a5d4845a6f1: Pull complete\n",
      "e668bdd76b0b: Pull complete\n",
      "0d343adad32a: Pull complete\n",
      "3d345b71059d: Pull complete\n",
      "274f64fcccf7: Pull complete\n",
      "Digest: sha256:5b004cd97a92a3162bda4fa8ed9e229951c729356e3cb18932f1056d7c5b76b9\n",
      "Status: Downloaded newer image for pipelines5112a485.azurecr.io/azureml/azureml_9e6164fd71967baaa1312ba8f229b985:latest\n",
      "3517d844590da5f050f3124827e0a51ff8f4903112dcb324ab72e72fb081aa26\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_f0d520f7639287c602de235af131aca33db2ce9dc4f743c012d7737c12923ad3_d.txt\n",
      "===============================================================================================================\n",
      "Starting job_prep.py script\n",
      "Starting job preparation. Current time:2020-04-30T19:47:23.966593\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: 8aa37e12-63a8-4e4f-a3cd-6233ed3c9285\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 76\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "Download from datastores if requested.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 135\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ dataprep.py ] with arguments: ['--output_path', '/mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/cef54e28-eb18-4777-b8e3-4bd91e9e8be3/mounts/workspaceblobstore/azureml/cef54e28-eb18-4777-b8e3-4bd91e9e8be3/titanic_train']\n",
      "After variable expansion, calling script [ dataprep.py ] with arguments: ['--output_path', '/mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/cef54e28-eb18-4777-b8e3-4bd91e9e8be3/mounts/workspaceblobstore/azureml/cef54e28-eb18-4777-b8e3-4bd91e9e8be3/titanic_train']\n",
      "\n",
      "Wrote test to /mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/cef54e28-eb18-4777-b8e3-4bd91e9e8be3/mounts/workspaceblobstore/azureml/cef54e28-eb18-4777-b8e3-4bd91e9e8be3/titanic_train and train to /mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/cef54e28-eb18-4777-b8e3-4bd91e9e8be3/mounts/workspaceblobstore/azureml/cef54e28-eb18-4777-b8e3-4bd91e9e8be3/titanic_train\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.12626338005065918 seconds\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 135\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_f0d520f7639287c602de235af131aca33db2ce9dc4f743c012d7737c12923ad3_d.txt\n",
      "===============================================================================================================\n",
      "Starting job release. Current time:2020-04-30T19:47:59.723144\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 341\n",
      "Job release is complete. Current time:2020-04-30T19:48:03.810672\n",
      "\n",
      "StepRun(dataprep) Execution Summary\n",
      "====================================\n",
      "StepRun( dataprep ) Status: Finished\n",
      "\n",
      "Warnings:\n",
      "This compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\n",
      "Please enable Docker in the environment section of your run configuration to stop seeing this warning message.\n",
      "{'runId': 'cef54e28-eb18-4777-b8e3-4bd91e9e8be3', 'target': 'cpu-compute3', 'status': 'Completed', 'startTimeUtc': '2020-04-30T19:43:47.49464Z', 'endTimeUtc': '2020-04-30T19:48:05.912774Z', 'warnings': [{'message': \"This compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\\nPlease enable Docker in the environment section of your run configuration to stop seeing this warning message.\"}], 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '8aa37e12-63a8-4e4f-a3cd-6233ed3c9285', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': '3b6e6d42-a2bb-41bb-9a44-aba546e3acb4', '_azureml.ComputeTargetType': 'amlcompute', 'AzureML.DerivedImageName': 'azureml/azureml_9e6164fd71967baaa1312ba8f229b985', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'bcd89377-bc03-4552-a733-4eeb452ecb29'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'titanic_ds', 'mechanism': 'Direct'}}], 'runDefinition': {'script': 'dataprep.py', 'useAbsolutePath': False, 'arguments': ['--output_path', '$AZUREML_DATAREFERENCE_titanic_train'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpu-compute3', 'dataReferences': {'titanic_train': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/cef54e28-eb18-4777-b8e3-4bd91e9e8be3/titanic_train', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'titanic_ds': {'dataLocation': {'dataset': {'id': 'bcd89377-bc03-4552-a733-4eeb452ecb29'}, 'dataPath': None}, 'createOutputDirectories': False, 'mechanism': 'Direct', 'environmentVariableName': 'titanic_ds', 'pathOnCompute': None, 'overwrite': False}}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment titanic_automl Environment', 'version': 'Autosave_2020-04-30T19:29:58Z_dc97ffbf', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk[automl,explain]', 'azureml-dataprep[fuse,pandas]']}, 'pandas', 'scikit-learn'], 'name': 'azureml_a202ddab594f378a0a5fa176c4dadf6e'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.cef54e28-eb18-4777-b8e3-4bd91e9e8be3/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=l2OJ1ve1WlCRh7BHAqaUyaM2xo6WK8d3cvb4o1uzL0E%3D&st=2020-04-30T19%3A38%3A15Z&se=2020-05-01T03%3A48%3A15Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_f0d520f7639287c602de235af131aca33db2ce9dc4f743c012d7737c12923ad3_d.txt': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.cef54e28-eb18-4777-b8e3-4bd91e9e8be3/azureml-logs/55_azureml-execution-tvmps_f0d520f7639287c602de235af131aca33db2ce9dc4f743c012d7737c12923ad3_d.txt?sv=2019-02-02&sr=b&sig=%2B9QbvpeD5EbPX1vueGbfVjTehQL9A1NqMb2UaMszmSc%3D&st=2020-04-30T19%3A38%3A15Z&se=2020-05-01T03%3A48%3A15Z&sp=r', 'azureml-logs/65_job_prep-tvmps_f0d520f7639287c602de235af131aca33db2ce9dc4f743c012d7737c12923ad3_d.txt': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.cef54e28-eb18-4777-b8e3-4bd91e9e8be3/azureml-logs/65_job_prep-tvmps_f0d520f7639287c602de235af131aca33db2ce9dc4f743c012d7737c12923ad3_d.txt?sv=2019-02-02&sr=b&sig=30ZJ86gphald0ta8CIMoETsETDEAVs1Q%2F2JwHkvFnP0%3D&st=2020-04-30T19%3A38%3A15Z&se=2020-05-01T03%3A48%3A15Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.cef54e28-eb18-4777-b8e3-4bd91e9e8be3/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=oVpcAMtJv3pRg5rjfJA2upslYZhnxMTnD6sZ6w4BD3A%3D&st=2020-04-30T19%3A38%3A15Z&se=2020-05-01T03%3A48%3A15Z&sp=r', 'azureml-logs/75_job_post-tvmps_f0d520f7639287c602de235af131aca33db2ce9dc4f743c012d7737c12923ad3_d.txt': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.cef54e28-eb18-4777-b8e3-4bd91e9e8be3/azureml-logs/75_job_post-tvmps_f0d520f7639287c602de235af131aca33db2ce9dc4f743c012d7737c12923ad3_d.txt?sv=2019-02-02&sr=b&sig=suHV%2F2%2F%2F7LK6d7oTOT%2BiB2HK31VxYCvtIastAYXum3Q%3D&st=2020-04-30T19%3A38%3A15Z&se=2020-05-01T03%3A48%3A15Z&sp=r', 'azureml-logs/process_info.json': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.cef54e28-eb18-4777-b8e3-4bd91e9e8be3/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=F6xMZ%2FBIVuFotXgMqipX4UoVWSOJg4tLLf8jQfYe7bE%3D&st=2020-04-30T19%3A38%3A15Z&se=2020-05-01T03%3A48%3A15Z&sp=r', 'azureml-logs/process_status.json': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.cef54e28-eb18-4777-b8e3-4bd91e9e8be3/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=dlWB%2FiY3fX1Wn2stv2u1vDH6XYlonFKtLR1gfLyqPPA%3D&st=2020-04-30T19%3A38%3A15Z&se=2020-05-01T03%3A48%3A15Z&sp=r', 'logs/azureml/135_azureml.log': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.cef54e28-eb18-4777-b8e3-4bd91e9e8be3/logs/azureml/135_azureml.log?sv=2019-02-02&sr=b&sig=briGFOXqlL6daUmdIkLtTWHbBEF818SJ4LR9hdz95Gk%3D&st=2020-04-30T19%3A38%3A15Z&se=2020-05-01T03%3A48%3A15Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.cef54e28-eb18-4777-b8e3-4bd91e9e8be3/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=YU52%2FYGuwY27HEwZbeawP6nlDPCmuda%2FrjtXi2NZN0I%3D&st=2020-04-30T19%3A38%3A15Z&se=2020-05-01T03%3A48%3A15Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.cef54e28-eb18-4777-b8e3-4bd91e9e8be3/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=0vh0tjK6%2Fy8Dt6wjy0VtCZ5egqArwHgww9CygE15RJs%3D&st=2020-04-30T19%3A38%3A15Z&se=2020-05-01T03%3A48%3A15Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.cef54e28-eb18-4777-b8e3-4bd91e9e8be3/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=QxUG9eJWWfLFiWe%2F48%2BRDqF0wq%2FBMd10BgxEscdzlsg%3D&st=2020-04-30T19%3A38%3A15Z&se=2020-05-01T03%3A48%3A15Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.cef54e28-eb18-4777-b8e3-4bd91e9e8be3/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=k6Rt0G5zNi5CBOjanV5u%2FLawGUBj%2B1ukBseuteKLNy0%3D&st=2020-04-30T19%3A38%3A15Z&se=2020-05-01T03%3A48%3A15Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.cef54e28-eb18-4777-b8e3-4bd91e9e8be3/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=k22oCiy4NKjv1AzCGWEiR5VRrTsgBzem1tVAGtSeIwk%3D&st=2020-04-30T19%3A38%3A15Z&se=2020-05-01T03%3A48%3A15Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 82f527a1-02b0-490c-8bbe-19541159a73c\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/82f527a1-02b0-490c-8bbe-19541159a73c?wsid=/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourcegroups/laobri-ml/workspaces/pipelines\n",
      "StepRun( AutoML_Classification ) Status: Running\n",
      "\n",
      "StepRun(AutoML_Classification) Execution Summary\n",
      "=================================================\n",
      "StepRun( AutoML_Classification ) Status: Finished\n",
      "{'runId': '82f527a1-02b0-490c-8bbe-19541159a73c', 'target': 'cpu-compute3', 'status': 'Completed', 'startTimeUtc': '2020-04-30T20:12:24.249965Z', 'endTimeUtc': '2020-04-30T20:16:42.292654Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '8aa37e12-63a8-4e4f-a3cd-6233ed3c9285', 'StepType': 'AutoMLStep', 'azureml.pipelinerunid': '3b6e6d42-a2bb-41bb-9a44-aba546e3acb4', 'num_iterations': '2', 'training_type': 'TrainFull', 'acquisition_function': 'EI', 'metrics': 'accuracy', 'primary_metric': 'AUC_weighted', 'train_split': '0', 'MaxTimeSeconds': '600', 'acquisition_parameter': '0', 'num_cross_validation': None, 'target': 'cpu-compute3', 'RawAMLSettingsString': \"{'name':'titanic_automl','subscription_id':'65a1016d-0f67-45d2-b838-b8f373d6d52e','resource_group':'laobri-ml','workspace_name':'pipelines','path':'.','iterations':2,'data_script':None,'primary_metric':'AUC_weighted','task_type':'classification','compute_target':'cpu-compute3','spark_context':None,'validation_size':0.0,'n_cross_validations':None,'y_min':None,'y_max':None,'num_classes':None,'preprocess':True,'lag_length':0,'max_cores_per_iteration':1,'max_concurrent_iterations':1,'iteration_timeout_minutes':10,'mem_in_mb':None,'enforce_time_on_windows':False,'experiment_timeout_minutes':15,'experiment_exit_score':None,'blacklist_models':None,'blacklist_algos':['[\\\\'XGBoostClassifier\\\\']'],'whitelist_models':None,'auto_blacklist':True,'exclude_nan_labels':True,'verbosity':20,'debug_log':'automated_ml_errors.log','debug_flag':None,'enable_ensembling':False,'ensemble_iterations':None,'model_explainability':True,'enable_tf':False,'enable_cache':True,'enable_subsampling':False,'subsample_seed':None,'cost_mode':1,'is_timeseries':False,'metric_operation':'maximize','time_column_name':None,'grain_column_names':None,'drop_column_names':None,'group':None,'target_lags':None,'target_rolling_window_size':None,'max_horizon':None,'country_or_region':None,'seasonality':None,'use_stl':None,'season_trend':None,'season':None,'intermediate_datasets':'training_data','training_data':None,'validation_data':None,'label_column_name':'Survived','weight_column_name':None,'X':None,'y':None,'X_valid':None,'y_valid':None}\", 'AMLSettingsJsonString': '{\"name\":\"titanic_automl\",\"subscription_id\":\"65a1016d-0f67-45d2-b838-b8f373d6d52e\",\"resource_group\":\"laobri-ml\",\"workspace_name\":\"pipelines\",\"path\":\".\",\"iterations\":2,\"data_script\":null,\"primary_metric\":\"AUC_weighted\",\"task_type\":\"classification\",\"compute_target\":\"cpu-compute3\",\"spark_context\":null,\"validation_size\":0.0,\"n_cross_validations\":null,\"y_min\":null,\"y_max\":null,\"num_classes\":null,\"preprocess\":true,\"lag_length\":0,\"max_cores_per_iteration\":1,\"max_concurrent_iterations\":1,\"iteration_timeout_minutes\":10,\"mem_in_mb\":null,\"enforce_time_on_windows\":false,\"experiment_timeout_minutes\":15,\"experiment_exit_score\":null,\"blacklist_models\":null,\"blacklist_algos\":[\"[\\'XGBoostClassifier\\']\"],\"whitelist_models\":null,\"auto_blacklist\":true,\"exclude_nan_labels\":true,\"verbosity\":20,\"debug_log\":\"automated_ml_errors.log\",\"debug_flag\":null,\"enable_ensembling\":false,\"ensemble_iterations\":null,\"model_explainability\":true,\"enable_tf\":false,\"enable_cache\":true,\"enable_subsampling\":false,\"subsample_seed\":null,\"cost_mode\":1,\"is_timeseries\":false,\"metric_operation\":\"maximize\",\"time_column_name\":null,\"grain_column_names\":null,\"drop_column_names\":null,\"group\":null,\"target_lags\":null,\"target_rolling_window_size\":null,\"max_horizon\":null,\"country_or_region\":null,\"seasonality\":null,\"use_stl\":null,\"season_trend\":null,\"season\":null,\"intermediate_datasets\":\"training_data\",\"training_data\":null,\"validation_data\":null,\"label_column_name\":\"Survived\",\"weight_column_name\":null,\"X\":null,\"y\":null,\"X_valid\":null,\"y_valid\":null}', 'DataPrepJsonString': '{\\\\\"training_data\\\\\":\\\\\"{\\\\\\\\n  \\\\\\\\\\\\\"blocks\\\\\\\\\\\\\": [\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"9907687b-9bd3-4eb0-a780-32708d9fa620\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.GetDatastoreFilesBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"datastores\\\\\\\\\\\\\": [\\\\\\\\n          {\\\\\\\\n            \\\\\\\\\\\\\"datastoreName\\\\\\\\\\\\\": \\\\\\\\\\\\\"workspaceblobstore\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"path\\\\\\\\\\\\\": \\\\\\\\\\\\\"azureml/cef54e28-eb18-4777-b8e3-4bd91e9e8be3/titanic_train\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"resourceGroup\\\\\\\\\\\\\": \\\\\\\\\\\\\"laobri-ml\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"subscription\\\\\\\\\\\\\": \\\\\\\\\\\\\"65a1016d-0f67-45d2-b838-b8f373d6d52e\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"workspaceName\\\\\\\\\\\\\": \\\\\\\\\\\\\"pipelines\\\\\\\\\\\\\"\\\\\\\\n          }\\\\\\\\n        ]\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"76a7c4cf-7856-46e3-b5c4-feaa0285261a\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.ReadParquetFileBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"preview\\\\\\\\\\\\\": false\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"e1238181-bf40-4a44-b712-f3e0781ad135\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.DropColumnsBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"columns\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\"type\\\\\\\\\\\\\": 0,\\\\\\\\n          \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\n            \\\\\\\\\\\\\"selectedColumns\\\\\\\\\\\\\": [\\\\\\\\n              \\\\\\\\\\\\\"Path\\\\\\\\\\\\\"\\\\\\\\n            ]\\\\\\\\n          }\\\\\\\\n        }\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    }\\\\\\\\n  ],\\\\\\\\n  \\\\\\\\\\\\\"inspectors\\\\\\\\\\\\\": [],\\\\\\\\n  \\\\\\\\\\\\\"meta\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\"savedDatasetId\\\\\\\\\\\\\": \\\\\\\\\\\\\"5f2bb5c9-62ca-45fc-b2d3-71deb5aef7be\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"datasetType\\\\\\\\\\\\\": \\\\\\\\\\\\\"tabular\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"subscriptionId\\\\\\\\\\\\\": \\\\\\\\\\\\\"65a1016d-0f67-45d2-b838-b8f373d6d52e\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"workspaceId\\\\\\\\\\\\\": \\\\\\\\\\\\\"20d3af82-566b-4384-a537-49042a17fcfa\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"workspaceLocation\\\\\\\\\\\\\": \\\\\\\\\\\\\"westus\\\\\\\\\\\\\"\\\\\\\\n  }\\\\\\\\n}\\\\\",\\\\\"activities\\\\\":\\\\\"0\\\\\"}', 'EnableSubsampling': 'False', 'runTemplate': 'AutoML', 'Orchestrator': 'automl', 'ClientType': 'Others', 'SetupRunId': '82f527a1-02b0-490c-8bbe-19541159a73c_setup', 'SetupRunContainerId': 'dcid.82f527a1-02b0-490c-8bbe-19541159a73c_setup', 'ClientSdkVersion': '1.4.0', 'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": true, \"subsampling\": false, \"dataset_classes\": 2, \"dataset_features\": 34, \"dataset_samples\": 1782, \"single_frequency_class_detected\": false}', 'ModelExplainRunId': '82f527a1-02b0-490c-8bbe-19541159a73c_ModelExplain'}, 'inputDatasets': [{'dataset': {'id': '5f2bb5c9-62ca-45fc-b2d3-71deb5aef7be'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.82f527a1-02b0-490c-8bbe-19541159a73c/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=lQ6AKDlW5sctZ9JdC4ssZpFZx3MEo634W5zO3FLzTJQ%3D&st=2020-04-30T20%3A06%3A54Z&se=2020-05-01T04%3A16%3A54Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.82f527a1-02b0-490c-8bbe-19541159a73c/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=NiMnr8r8iOLsVALI%2BnFkTxMvn3cQ27x6AdAJKlA%2F8e4%3D&st=2020-04-30T20%3A06%3A54Z&se=2020-05-01T04%3A16%3A54Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://pipelines8090722083.blob.core.windows.net/azureml/ExperimentRun/dcid.82f527a1-02b0-490c-8bbe-19541159a73c/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=qy84AVyn%2FasHP0Y0qduNp80LW31YMc%2F5Bt5CyaRZzaw%3D&st=2020-04-30T20%3A06%3A54Z&se=2020-05-01T04%3A16%3A54Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: e575afeb-aff4-4b37-8b7d-6bd8fbbdcc5f\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/e575afeb-aff4-4b37-8b7d-6bd8fbbdcc5f?wsid=/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourcegroups/laobri-ml/workspaces/pipelines\n",
      "StepRun( register_model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2020/04/30 20:17:10 Downloading source code...\n",
      "2020/04/30 20:17:11 Finished downloading source code\n",
      "2020/04/30 20:17:12 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2020/04/30 20:17:13 Successfully set up Docker network: acb_default_network\n",
      "2020/04/30 20:17:13 Setting up Docker configuration...\n",
      "2020/04/30 20:17:14 Successfully set up Docker configuration\n",
      "2020/04/30 20:17:14 Logging in to registry: pipelines5112a485.azurecr.io\n",
      "2020/04/30 20:17:15 Successfully logged into pipelines5112a485.azurecr.io\n",
      "2020/04/30 20:17:15 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/04/30 20:17:15 Scanning for dependencies...\n",
      "2020/04/30 20:17:16 Successfully scanned dependencies\n",
      "2020/04/30 20:17:16 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  60.93kB\n",
      "\n",
      "Step 1/15 : FROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05: Pulling from azureml/base\n",
      "Digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      " ---> 93a72e6bd1ce\n",
      "Step 2/15 : USER root\n",
      " ---> Running in cd2bfd36e941\n",
      "Removing intermediate container cd2bfd36e941\n",
      " ---> 335755acdf3a\n",
      "Step 3/15 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 00fe39ec6c16\n",
      "Removing intermediate container 00fe39ec6c16\n",
      " ---> e45cb606d563\n",
      "Step 4/15 : WORKDIR /\n",
      " ---> Running in 2ef10c4033ca\n",
      "Removing intermediate container 2ef10c4033ca\n",
      " ---> 9fc256d41f43\n",
      "Step 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 342e141f4589\n",
      "Step 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 5e76483fb605\n",
      "Removing intermediate container 5e76483fb605\n",
      " ---> e371efbf1d9c\n",
      "Step 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> f9fa163a2521\n",
      "Step 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_fb099990cc95c5127ccd5b5aee9008eb -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 0933dcfbc791\n",
      "Solving environment: ...working... \n",
      "done\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "sip-4.19.13          | 293 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "sip-4.19.13          | 293 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "gstreamer-1.14.0     | 3.8 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "gstreamer-1.14.0     | 3.8 MB    | #######6   |  76% \u001b[0m\u001b[91m\n",
      "gstreamer-1.14.0     | 3.8 MB    | #########  |  91% \u001b[0m\u001b[91m\n",
      "gstreamer-1.14.0     | 3.8 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "cycler-0.10.0        | 13 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "cycler-0.10.0        | 13 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "setuptools-46.1.3    | 663 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "setuptools-46.1.3    | 663 KB    | ########4  |  85% \u001b[0m\u001b[91m\n",
      "setuptools-46.1.3    | 663 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "blas-1.0             | 6 KB      |            |   0% \u001b[0m\u001b[91m\n",
      "blas-1.0             | 6 KB      | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "gcc_linux-64-7.3.0   | 25 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "gcc_linux-64-7.3.0   | 25 KB     | ####8      |  49% \u001b[0m\u001b[91m\n",
      "gcc_linux-64-7.3.0   | 25 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "dbus-1.13.12         | 611 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "dbus-1.13.12         | 611 KB    | #########1 |  91% \u001b[0m\u001b[91m\n",
      "dbus-1.13.12         | 611 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "gst-plugins-base-1.1 | 6.3 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "gst-plugins-base-1.1 | 6.3 MB    | #####9     |  60% \u001b[0m\u001b[91m\n",
      "gst-plugins-base-1.1 | 6.3 MB    | #######7   |  78% \u001b[0m\u001b[91m\n",
      "gst-plugins-base-1.1 | 6.3 MB    | #########3 |  93% \u001b[0m\u001b[91m\n",
      "gst-plugins-base-1.1 | 6.3 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "gcc_impl_linux-64-7. | 73.2 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "gcc_impl_linux-64-7. | 73.2 MB   | 6          |   7% \u001b[0m\u001b[91m\n",
      "gcc_impl_linux-64-7. | 73.2 MB   | #6         |  17% \u001b[0m\u001b[91m\n",
      "gcc_impl_linux-64-7. | 73.2 MB   | ##7        |  28% \u001b[0m\u001b[91m\n",
      "gcc_impl_linux-64-7. | 73.2 MB   | ###8       |  39% \u001b[0m\u001b[91m\n",
      "gcc_impl_linux-64-7. | 73.2 MB   | #####      |  51% \u001b[0m\u001b[91m\n",
      "gcc_impl_linux-64-7. | 73.2 MB   | ######2    |  62% \u001b[0m\u001b[91m\n",
      "gcc_impl_linux-64-7. | 73.2 MB   | #######4   |  74% \u001b[0m\u001b[91m\n",
      "gcc_impl_linux-64-7. | 73.2 MB   | ########5  |  85% \u001b[0m\u001b[91m\n",
      "gcc_impl_linux-64-7. | 73.2 MB   | #########2 |  92% \u001b[0m\u001b[91m\n",
      "gcc_impl_linux-64-7. | 73.2 MB   | #########7 |  98% \u001b[0m\u001b[91m\n",
      "gcc_impl_linux-64-7. | 73.2 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pandas-0.23.4        | 10.1 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "pandas-0.23.4        | 10.1 MB   | ####3      |  43% \u001b[0m\u001b[91m\n",
      "pandas-0.23.4        | 10.1 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "pandas-0.23.4        | 10.1 MB   | ########9  |  90% \u001b[0m\u001b[91m\n",
      "pandas-0.23.4        | 10.1 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "binutils_impl_linux- | 16.5 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "binutils_impl_linux- | 16.5 MB   | ###4       |  35% \u001b[0m\u001b[91m\n",
      "binutils_impl_linux- | 16.5 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "binutils_impl_linux- | 16.5 MB   | ########6  |  86% \u001b[0m\u001b[91m\n",
      "binutils_impl_linux- | 16.5 MB   | #########3 |  94% \u001b[0m\u001b[91m\n",
      "binutils_impl_linux- | 16.5 MB   | #########9 | 100% \u001b[0m\u001b[91m\n",
      "binutils_impl_linux- | 16.5 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "_py-xgboost-mutex-2. | 9 KB      |            |   0% \u001b[0m\u001b[91m\n",
      "_py-xgboost-mutex-2. | 9 KB      | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pcre-8.43            | 260 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "pcre-8.43            | 260 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "holidays-0.9.11      | 39 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "holidays-0.9.11      | 39 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "fbprophet-0.5        | 631 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "fbprophet-0.5        | 631 KB    | #########7 |  97% \u001b[0m\u001b[91m\n",
      "fbprophet-0.5        | 631 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl_fft-1.0.15       | 173 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "mkl_fft-1.0.15       | 173 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 387 KB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 387 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | #######9   |  79% \u001b[0m\u001b[91m\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "gxx_impl_linux-64-7. | 18.7 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "gxx_impl_linux-64-7. | 18.7 MB   | ##8        |  28% \u001b[0m\u001b[91m\n",
      "gxx_impl_linux-64-7. | 18.7 MB   | #######    |  71% \u001b[0m\u001b[91m\n",
      "gxx_impl_linux-64-7. | 18.7 MB   | ########9  |  90% \u001b[0m\u001b[91m\n",
      "gxx_impl_linux-64-7. | 18.7 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "fontconfig-2.13.0    | 291 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "fontconfig-2.13.0    | 291 KB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "fontconfig-2.13.0    | 291 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pip-20.0.2           | 1.9 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "pip-20.0.2           | 1.9 MB    | #######8   |  78% \u001b[0m\u001b[91m\n",
      "pip-20.0.2           | 1.9 MB    | #########3 |  93% \u001b[0m\u001b[91m\n",
      "pip-20.0.2           | 1.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "tk-8.6.8             | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #######6   |  77% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | ########8  |  88% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ephem-3.7.7.0        | 761 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ephem-3.7.7.0        | 761 KB    | ########8  |  89% \u001b[0m\u001b[91m\n",
      "ephem-3.7.7.0        | 761 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "tornado-6.0.4        | 650 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "tornado-6.0.4        | 650 KB    | ########4  |  85% \u001b[0m\u001b[91m\n",
      "tornado-6.0.4        | 650 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python-dateutil-2.8. | 224 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "python-dateutil-2.8. | 224 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl_random-1.1.0     | 369 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "mkl_random-1.1.0     | 369 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "matplotlib-3.1.3     | 21 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "matplotlib-3.1.3     | 21 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pystan-2.19.0.0      | 16.6 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "pystan-2.19.0.0      | 16.6 MB   | #8         |  18% \u001b[0m\u001b[91m\n",
      "pystan-2.19.0.0      | 16.6 MB   | ####9      |  50% \u001b[0m\u001b[91m\n",
      "pystan-2.19.0.0      | 16.6 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "pystan-2.19.0.0      | 16.6 MB   | #########1 |  91% \u001b[0m\n",
      "\u001b[91m\n",
      "pystan-2.19.0.0      | 16.6 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "cython-0.29.15       | 2.2 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "cython-0.29.15       | 2.2 MB    | #######6   |  77% \u001b[0m\u001b[91m\n",
      "cython-0.29.15       | 2.2 MB    | #########9 | 100% \u001b[0m\u001b[91m\n",
      "cython-0.29.15       | 2.2 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "xz-5.2.5             | 438 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "xz-5.2.5             | 438 KB    | #########  |  90% \u001b[0m\u001b[91m\n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "freetype-2.9.1       | 822 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "freetype-2.9.1       | 822 KB    | ########   |  81% \u001b[0m\u001b[91m\n",
      "freetype-2.9.1       | 822 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "icu-58.2             | 22.5 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "icu-58.2             | 22.5 MB   | #2         |  12% \u001b[0m\u001b[91m\n",
      "icu-58.2             | 22.5 MB   | ####7      |  47% \u001b[0m\u001b[91m\n",
      "icu-58.2             | 22.5 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "icu-58.2             | 22.5 MB   | #########2 |  93% \u001b[0m\u001b[91m\n",
      "icu-58.2             | 22.5 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #9         |  20% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #####      |  51% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########8  |  88% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #########7 |  97% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "numpy-base-1.16.2    | 4.4 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "numpy-base-1.16.2    | 4.4 MB    | #######6   |  76% \u001b[0m\u001b[91m\n",
      "numpy-base-1.16.2    | 4.4 MB    | #########3 |  94% \u001b[0m\u001b[91m\n",
      "numpy-base-1.16.2    | 4.4 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "scipy-1.4.1          | 18.9 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | ###        |  31% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | #########4 |  95% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libuuid-1.0.3        | 16 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "libuuid-1.0.3        | 16 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | #######6   |  76% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | #########4 |  95% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "six-1.14.0           | 27 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "six-1.14.0           | 27 KB     | ########## | 100% \n",
      "\n",
      "mkl-2019.4           | 204.1 MB  |            |   0% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | 2          |   2% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | 5          |   6% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | 8          |   9% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #1         |  12% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #5         |  15% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #9         |  19% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ##2        |  23% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ##6        |  27% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ###        |  31% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ###5       |  35% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ###9       |  39% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ####3      |  43% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ####6      |  47% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #####      |  51% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #####4     |  55% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #####8     |  59% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ######2    |  62% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ######6    |  66% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #######    |  71% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #######5   |  75% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #######9   |  79% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########1  |  82% \u001b[0m\n",
      "\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########3  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\n",
      "\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "jpeg-9b              | 247 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "jpeg-9b              | 247 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libffi-3.2.1         | 43 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "libffi-3.2.1         | 43 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | #######9   |  79% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | #########  |  90% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "intel-openmp-2020.0  | 916 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "intel-openmp-2020.0  | 916 KB    | ########6  |  87% \u001b[0m\u001b[91m\n",
      "intel-openmp-2020.0  | 916 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl-service-2.3.0    | 208 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "mkl-service-2.3.0    | 208 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pyqt-5.9.2           | 5.6 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "pyqt-5.9.2           | 5.6 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "pyqt-5.9.2           | 5.6 MB    | ########6  |  86% \u001b[0m\u001b[91m\n",
      "pyqt-5.9.2           | 5.6 MB    | #########4 |  94% \u001b[0m\u001b[91m\n",
      "pyqt-5.9.2           | 5.6 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "py-xgboost-0.80      | 1.7 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "py-xgboost-0.80      | 1.7 MB    | #######7   |  77% \u001b[0m\u001b[91m\n",
      "py-xgboost-0.80      | 1.7 MB    | #########9 |  99% \u001b[0m\u001b[91m\n",
      "py-xgboost-0.80      | 1.7 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pytz-2019.3          | 231 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "pytz-2019.3          | 231 KB    | #########  |  91% \u001b[0m\u001b[91m\n",
      "pytz-2019.3          | 231 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libxml2-2.9.9        | 2.0 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libxml2-2.9.9        | 2.0 MB    | #######6   |  76% \u001b[0m\u001b[91m\n",
      "libxml2-2.9.9        | 2.0 MB    | #########6 |  97% \u001b[0m\u001b[91m\n",
      "libxml2-2.9.9        | 2.0 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | #######6   |  76% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | #########9 |  99% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "glib-2.56.2          | 5.0 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "glib-2.56.2          | 5.0 MB    | #######5   |  76% \u001b[0m\u001b[91m\n",
      "glib-2.56.2          | 5.0 MB    | #########8 |  98% \u001b[0m\u001b[91m\n",
      "glib-2.56.2          | 5.0 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "numpy-1.16.2         | 49 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "numpy-1.16.2         | 49 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "wheel-0.34.2         | 49 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "wheel-0.34.2         | 49 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pyparsing-2.4.6      | 64 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "pyparsing-2.4.6      | 64 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "convertdate-2.1.3    | 30 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "convertdate-2.1.3    | 30 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "certifi-2020.4.5.1   | 159 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "certifi-2020.4.5.1   | 159 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "binutils_linux-64-2. | 24 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "binutils_linux-64-2. | 24 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "lunardate-0.2.0      | 21 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "lunardate-0.2.0      | 21 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "kiwisolver-1.1.0     | 90 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "kiwisolver-1.1.0     | 90 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libxcb-1.13          | 502 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "libxcb-1.13          | 502 KB    | ########   |  81% \u001b[0m\u001b[91m\n",
      "libxcb-1.13          | 502 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "qt-5.9.6             | 86.7 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | 6          |   7% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #5         |  15% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | ##4        |  24% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | ###3       |  33% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | ####2      |  42% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #####      |  50% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #####9     |  59% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | ######7    |  67% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | ########   |  81% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | ########4  |  85% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | ########7  |  88% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | ########9  |  90% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########1 |  91% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########2 |  93% \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########3 |  93% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########4 |  94% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########4 |  95% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########4 |  95% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########5 |  95% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########5 |  96% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########5 |  96% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########6 |  96% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########6 |  96% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########6 |  96% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########6 |  97% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########6 |  97% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########7 |  97% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########7 |  97% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########7 |  97% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########7 |  98% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########7 |  98% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########8 |  98% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########8 |  98% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########8 |  98% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########8 |  99% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########8 |  99% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########9 |  99% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########9 |  99% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########9 |  99% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########9 | 100% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | #########9 | 100% \u001b[0m\u001b[91m\n",
      "qt-5.9.6             | 86.7 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | #######9   |  80% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | #########8 |  99% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "setuptools-git-1.2   | 12 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "setuptools-git-1.2   | 12 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libpng-1.6.37        | 364 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "libpng-1.6.37        | 364 KB    | #########5 |  95% \u001b[0m\u001b[91m\n",
      "libpng-1.6.37        | 364 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libxgboost-0.80      | 3.7 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libxgboost-0.80      | 3.7 MB    | #######6   |  76% \u001b[0m\u001b[91m\n",
      "libxgboost-0.80      | 3.7 MB    | #########8 |  98% \u001b[0m\u001b[91m\n",
      "libxgboost-0.80      | 3.7 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "libedit-3.1          | 171 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "gxx_linux-64-7.3.0   | 24 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "gxx_linux-64-7.3.0   | 24 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ca-certificates-2020 | 132 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ca-certificates-2020 | 132 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "expat-2.2.6          | 187 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "expat-2.2.6          | 187 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "matplotlib-base-3.1. | 6.6 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "matplotlib-base-3.1. | 6.6 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "matplotlib-base-3.1. | 6.6 MB    | #########7 |  97% \u001b[0m\u001b[91m\n",
      "matplotlib-base-3.1. | 6.6 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "scikit-learn-0.20.3  | 5.7 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.20.3  | 5.7 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.20.3  | 5.7 MB    | #########7 |  97% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.20.3  | 5.7 MB    | ########## | 100% \u001b[0m\n",
      "Downloading and Extracting Packages\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... \n",
      "done\n",
      "Executing transaction: ...working... done\n",
      "Collecting azureml-sdk[automl,explain]\n",
      "  Downloading azureml_sdk-1.4.0-py3-none-any.whl (4.6 kB)\n",
      "Collecting azureml-dataprep[fuse,pandas]\n",
      "  Downloading azureml_dataprep-1.4.6-py3-none-any.whl (26.7 MB)\n",
      "Collecting inference-schema\n",
      "  Downloading inference_schema-1.0.2-py3-none-any.whl (19 kB)\n",
      "Collecting azureml-train~=1.4.0\n",
      "  Downloading azureml_train-1.4.0-py3-none-any.whl (3.2 kB)\n",
      "Collecting azureml-core~=1.4.0\n",
      "  Downloading azureml_core-1.4.0.post1-py3-none-any.whl (1.3 MB)\n",
      "Collecting azureml-train-automl-client~=1.4.0\n",
      "  Downloading azureml_train_automl_client-1.4.0-py3-none-any.whl (81 kB)\n",
      "Collecting azureml-pipeline~=1.4.0\n",
      "  Downloading azureml_pipeline-1.4.0-py3-none-any.whl (3.7 kB)\n",
      "Collecting azureml-train-automl~=1.4.0; extra == \"automl\"\n",
      "  Downloading azureml_train_automl-1.4.0-py3-none-any.whl (3.4 kB)\n",
      "Collecting azureml-explain-model~=1.4.0; extra == \"explain\"\n",
      "  Downloading azureml_explain_model-1.4.0-py3-none-any.whl (22 kB)\n",
      "Collecting cloudpickle>=1.1.0\n",
      "  Downloading cloudpickle-1.4.1-py3-none-any.whl (26 kB)\n",
      "Collecting azureml-dataprep-native<15.0.0,>=14.1.0\n",
      "  Downloading azureml_dataprep_native-14.1.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting dotnetcore2>=2.1.13\n",
      "  Downloading dotnetcore2-2.1.13-py3-none-manylinux1_x86_64.whl (29.3 MB)\n",
      "Collecting azure-identity<1.3.0,>=1.2.0\n",
      "  Downloading azure_identity-1.2.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting fusepy>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting pyarrow>=0.15.*; extra == \"pandas\"\n",
      "  Downloading pyarrow-0.17.0-cp36-cp36m-manylinux2014_x86_64.whl (63.8 MB)\n",
      "Requirement already satisfied: numpy>=1.14.0; extra == \"pandas\" in /azureml-envs/azureml_fb099990cc95c5127ccd5b5aee9008eb/lib/python3.6/site-packages (from azureml-dataprep[fuse,pandas]->-r /azureml-environment-setup/condaenv.dzrvoirl.requirements.txt (line 2)) (1.16.2)\n",
      "Requirement already satisfied: pandas>=0.23.4; extra == \"pandas\" in /azureml-envs/azureml_fb099990cc95c5127ccd5b5aee9008eb/lib/python3.6/site-packages (from azureml-dataprep[fuse,pandas]->-r /azureml-environment-setup/condaenv.dzrvoirl.requirements.txt (line 2)) (0.23.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /azureml-envs/azureml_fb099990cc95c5127ccd5b5aee9008eb/lib/python3.6/site-packages (from inference-schema->-r /azureml-environment-setup/condaenv.dzrvoirl.requirements.txt (line 3)) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /azureml-envs/azureml_fb099990cc95c5127ccd5b5aee9008eb/lib/python3.6/site-packages (from inference-schema->-r /azureml-environment-setup/condaenv.dzrvoirl.requirements.txt (line 3)) (2.8.1)\n",
      "Collecting wrapt==1.11.1\n",
      "  Downloading wrapt-1.11.1.tar.gz (27 kB)\n",
      "Collecting azureml-train-core~=1.4.0\n",
      "  Downloading azureml_train_core-1.4.0-py3-none-any.whl (8.6 MB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.3-py2.py3-none-any.whl (40 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting PyJWT\n",
      "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting docker\n",
      "  Downloading docker-4.2.0-py2.py3-none-any.whl (143 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-0.9.5-py2.py3-none-any.whl (24 kB)\n",
      "Collecting msrest>=0.5.1\n",
      "  Downloading msrest-0.6.13-py2.py3-none-any.whl (83 kB)\n",
      "Collecting azure-common>=1.1.12\n",
      "  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\n",
      "Collecting azure-mgmt-authorization>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.60.0-py2.py3-none-any.whl (82 kB)\n",
      "Collecting pathspec\n",
      "  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.25.9-py2.py3-none-any.whl (126 kB)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting SecretStorage\n",
      "  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting ruamel.yaml<=0.15.89,>=0.15.35\n",
      "  Downloading ruamel.yaml-0.15.89-cp36-cp36m-manylinux1_x86_64.whl (651 kB)\n",
      "Collecting azure-graphrbac>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting pyopenssl\n",
      "  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting requests>=2.19.1\n",
      "  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting azure-mgmt-storage>=1.5.0\n",
      "  Downloading azure_mgmt_storage-9.0.0-py2.py3-none-any.whl (525 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n",
      "  Downloading cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7 MB)\n",
      "Collecting azure-mgmt-resource>=1.2.1\n",
      "  Downloading azure_mgmt_resource-9.0.0-py2.py3-none-any.whl (807 kB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\n",
      "Collecting adal>=1.2.0\n",
      "  Downloading adal-1.2.2-py2.py3-none-any.whl (53 kB)\n",
      "Collecting azure-mgmt-keyvault>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting azureml-automl-core~=1.4.0\n",
      "  Downloading azureml_automl_core-1.4.0-py3-none-any.whl (111 kB)\n",
      "Collecting azureml-telemetry~=1.4.0\n",
      "  Downloading azureml_telemetry-1.4.0-py3-none-any.whl (29 kB)\n",
      "Collecting azureml-pipeline-core~=1.4.0\n",
      "  Downloading azureml_pipeline_core-1.4.0-py3-none-any.whl (272 kB)\n",
      "Collecting azureml-pipeline-steps~=1.4.0\n",
      "  Downloading azureml_pipeline_steps-1.4.0-py3-none-any.whl (49 kB)\n",
      "Collecting azureml-train-automl-runtime~=1.4.0\n",
      "  Downloading azureml_train_automl_runtime-1.4.0.post1-py3-none-any.whl (81 kB)\n",
      "Collecting azureml-automl-runtime~=1.4.0\n",
      "  Downloading azureml_automl_runtime-1.4.0.post1-py3-none-any.whl (2.0 MB)\n",
      "Collecting azureml-interpret~=1.4.0\n",
      "  Downloading azureml_interpret-1.4.0-py3-none-any.whl (45 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting msal-extensions~=0.1.3\n",
      "  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.4.0-py2.py3-none-any.whl (114 kB)\n",
      "Requirement already satisfied: six>=1.6 in /azureml-envs/azureml_fb099990cc95c5127ccd5b5aee9008eb/lib/python3.6/site-packages (from azure-identity<1.3.0,>=1.2.0->azureml-dataprep[fuse,pandas]->-r /azureml-environment-setup/condaenv.dzrvoirl.requirements.txt (line 2)) (1.14.0)\n",
      "Collecting msal<2.0.0,>=1.0.0\n",
      "  Downloading msal-1.2.0-py2.py3-none-any.whl (46 kB)\n",
      "Collecting azureml-train-restclients-hyperdrive~=1.4.0\n",
      "  Downloading azureml_train_restclients_hyperdrive-1.4.0-py3-none-any.whl (18 kB)\n",
      "Collecting flake8<=3.7.9,>=3.1.0; python_version >= \"3.6\"\n",
      "  Downloading flake8-3.7.9-py2.py3-none-any.whl (69 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_fb099990cc95c5127ccd5b5aee9008eb/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core~=1.4.0->azureml-sdk[automl,explain]->-r /azureml-environment-setup/condaenv.dzrvoirl.requirements.txt (line 1)) (2020.4.5.1)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting jeepney>=0.4.2\n",
      "  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (399 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-1.6.0-py2.py3-none-any.whl (30 kB)\n",
      "Collecting applicationinsights\n",
      "  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting wheel==0.30.0\n",
      "  Downloading wheel-0.30.0-py2.py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: scikit-learn<=0.20.3,>=0.19.0 in /azureml-envs/azureml_fb099990cc95c5127ccd5b5aee9008eb/lib/python3.6/site-packages (from azureml-train-automl-runtime~=1.4.0->azureml-train-automl~=1.4.0; extra == \"automl\"->azureml-sdk[automl,explain]->-r /azureml-environment-setup/condaenv.dzrvoirl.requirements.txt (line 1)) (0.20.3)\n",
      "Collecting statsmodels<=0.10.2,>=0.9.0\n",
      "  Downloading statsmodels-0.10.2-cp36-cp36m-manylinux1_x86_64.whl (8.1 MB)\n",
      "Collecting scipy<=1.1.0,>=1.0.0\n",
      "  Downloading scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2 MB)\n",
      "Collecting resource>=0.1.8\n",
      "  Downloading Resource-0.2.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting onnxruntime==1.0.0\n",
      "  Downloading onnxruntime-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (3.4 MB)\n",
      "Collecting onnxmltools==1.4.1\n",
      "  Downloading onnxmltools-1.4.1-py2.py3-none-any.whl (371 kB)\n",
      "Collecting lightgbm<=2.3.0,>=2.0.11\n",
      "  Downloading lightgbm-2.3.0-py2.py3-none-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting sklearn-pandas<=1.7.0,>=1.4.0\n",
      "  Downloading sklearn_pandas-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting gensim\n",
      "  Downloading gensim-3.8.2-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\n",
      "Collecting dill>=0.2.8\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "Collecting smart-open<=1.9.0\n",
      "  Downloading smart_open-1.9.0.tar.gz (70 kB)\n",
      "Collecting patsy>=0.5.1\n",
      "  Downloading patsy-0.5.1-py2.py3-none-any.whl (231 kB)\n",
      "Collecting onnx<=1.6.0,>=1.5.0\n",
      "  Downloading onnx-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (4.8 MB)\n",
      "Collecting azureml-defaults~=1.4.0\n",
      "  Downloading azureml_defaults-1.4.0-py3-none-any.whl (3.0 kB)\n",
      "Collecting skl2onnx==1.4.9\n",
      "  Downloading skl2onnx-1.4.9-py2.py3-none-any.whl (114 kB)\n",
      "Collecting onnxconverter-common<=1.6.0,>=1.4.2\n",
      "  Downloading onnxconverter_common-1.6.0-py2.py3-none-any.whl (43 kB)\n",
      "Collecting nimbusml>=1.5.0\n",
      "  Downloading nimbusml-1.7.0-cp36-none-manylinux1_x86_64.whl (116.2 MB)\n",
      "Collecting pmdarima==1.1.1\n",
      "  Downloading pmdarima-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (682 kB)\n",
      "Collecting psutil<6.0.0,>=5.2.2\n",
      "  Downloading psutil-5.7.0.tar.gz (449 kB)\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py-cpuinfo-5.0.0.tar.gz (82 kB)\n",
      "Collecting interpret-community==0.10.*\n",
      "  Downloading interpret_community-0.10.2-py3-none-any.whl (5.4 MB)\n",
      "Collecting portalocker~=1.0\n",
      "  Downloading portalocker-1.7.0-py2.py3-none-any.whl (14 kB)\n",
      "Collecting mccabe<0.7.0,>=0.6.0\n",
      "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Collecting pyflakes<2.2.0,>=2.1.0\n",
      "  Downloading pyflakes-2.1.1-py2.py3-none-any.whl (59 kB)\n",
      "Collecting pycodestyle<2.6.0,>=2.5.0\n",
      "  Downloading pycodestyle-2.5.0-py2.py3-none-any.whl (51 kB)\n",
      "Collecting entrypoints<0.4.0,>=0.3.0\n",
      "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "Collecting JsonSir>=0.0.2\n",
      "  Downloading JsonSir-0.0.2.tar.gz (2.2 kB)\n",
      "Collecting python-easyconfig>=0.1.0\n",
      "  Downloading Python_EasyConfig-0.1.7-py2.py3-none-any.whl (5.4 kB)\n",
      "Collecting JsonForm>=0.0.2\n",
      "  Downloading JsonForm-0.0.2.tar.gz (2.4 kB)\n",
      "Collecting keras2onnx\n",
      "  Downloading keras2onnx-1.6.1-py3-none-any.whl (220 kB)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting boto>=2.32\n",
      "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.13.0-py2.py3-none-any.whl (128 kB)\n",
      "Collecting typing-extensions>=3.6.2.1\n",
      "  Downloading typing_extensions-3.7.4.2-py3-none-any.whl (22 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting gunicorn==19.9.0\n",
      "  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting werkzeug==0.16.1\n",
      "  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Requirement already satisfied: Cython>=0.29 in /azureml-envs/azureml_fb099990cc95c5127ccd5b5aee9008eb/lib/python3.6/site-packages (from pmdarima==1.1.1->azureml-automl-runtime~=1.4.0->azureml-train-automl~=1.4.0; extra == \"automl\"->azureml-sdk[automl,explain]->-r /azureml-environment-setup/condaenv.dzrvoirl.requirements.txt (line 1)) (0.29.15)\n",
      "Collecting shap<=0.34.0,>=0.20.0\n",
      "  Downloading shap-0.34.0.tar.gz (264 kB)\n",
      "Collecting interpret-core[required]<=0.1.21,>=0.1.20\n",
      "  Downloading interpret_core-0.1.21-py3-none-any.whl (8.3 MB)\n",
      "Collecting packaging\n",
      "  Downloading packaging-20.3-py2.py3-none-any.whl (37 kB)\n",
      "Collecting PyYAML\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "Collecting jsonschema\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting fire\n",
      "  Downloading fire-0.3.1.tar.gz (81 kB)\n",
      "Requirement already satisfied: setuptools in /azureml-envs/azureml_fb099990cc95c5127ccd5b5aee9008eb/lib/python3.6/site-packages (from protobuf->onnxmltools==1.4.1->azureml-train-automl-runtime~=1.4.0->azureml-train-automl~=1.4.0; extra == \"automl\"->azureml-sdk[automl,explain]->-r /azureml-environment-setup/condaenv.dzrvoirl.requirements.txt (line 1)) (46.1.3.post20200330)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Collecting botocore<1.17.0,>=1.16.0\n",
      "  Downloading botocore-1.16.0-py2.py3-none-any.whl (6.2 MB)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Downloading liac-arff-2.4.0.tar.gz (15 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tqdm>4.25.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\n",
      "Collecting joblib>=0.11; extra == \"required\"\n",
      "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /azureml-envs/azureml_fb099990cc95c5127ccd5b5aee9008eb/lib/python3.6/site-packages (from packaging->interpret-community==0.10.*->azureml-interpret~=1.4.0->azureml-explain-model~=1.4.0; extra == \"explain\"->azureml-sdk[automl,explain]->-r /azureml-environment-setup/condaenv.dzrvoirl.requirements.txt (line 1)) (2.4.6)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.16.0.tar.gz (108 kB)\n",
      "Collecting attrs>=17.4.0\n",
      "  Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\n",
      "Building wheels for collected packages: fusepy, wrapt, dill, smart-open, psutil, py-cpuinfo, JsonSir, JsonForm, json-logging-py, shap, PyYAML, fire, liac-arff, pyrsistent, termcolor\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=368d988ca3995b1186af75a6eafa59861ff1b800360c3a69b9659efb2cefd3c1\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.11.1-cp36-cp36m-linux_x86_64.whl size=66711 sha256=8b9678f271932678a71f0dc7f9da858772da8e166cd41428d4e062be4782bce0\n",
      "  Stored in directory: /root/.cache/pip/wheels/94/0f/ec/66085641573800014bb0c8b657f3366eff641c42df79abbfe9\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78530 sha256=7e2eae01601e6ee97b03c84d199a52c297c6747bd1c3a409c067ef8564e395a7\n",
      "  Stored in directory: /root/.cache/pip/wheels/09/84/74/d2b4feb9ac9488bc83c475cb2cbe8e8b7d9cea8320d32f3787\n",
      "  Building wheel for smart-open (setup.py): started\n",
      "  Building wheel for smart-open (setup.py): finished with status 'done'\n",
      "  Created wheel for smart-open: filename=smart_open-1.9.0-py3-none-any.whl size=73085 sha256=ab67eacd5e88ef6417a87036216c054c194bdbf815d391b32254b730a2db3fec\n",
      "  Stored in directory: /root/.cache/pip/wheels/8e/9f/cd/dbf5c1362c59abb699a218c1151679033b8ccb5b6db559d512\n",
      "  Building wheel for psutil (setup.py): started\n",
      "  Building wheel for psutil (setup.py): finished with status 'done'\n",
      "  Created wheel for psutil: filename=psutil-5.7.0-cp36-cp36m-linux_x86_64.whl size=260178 sha256=29308e8d563945c42ad053bdcfb6daa8a96d479e4e29d838ae8fb929abe0e3de\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/d9/f2/b5620c01e9b3e858c6877b1045fda5b115cf7df6490f883382\n",
      "  Building wheel for py-cpuinfo (setup.py): started\n",
      "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
      "  Created wheel for py-cpuinfo: filename=py_cpuinfo-5.0.0-py3-none-any.whl size=18682 sha256=5917337ee48482cfbd90258c7341c844911ed84aed44ccb973f32b19c5bc9e7c\n",
      "  Stored in directory: /root/.cache/pip/wheels/e6/54/db/65176a1697a583d8ec5f90510f6faab11cda739d0e4f0ba2ea\n",
      "  Building wheel for JsonSir (setup.py): started\n",
      "  Building wheel for JsonSir (setup.py): finished with status 'done'\n",
      "  Created wheel for JsonSir: filename=JsonSir-0.0.2-py3-none-any.whl size=4774 sha256=6540c8223222ff8b984a14beda5782a648da172d29458ffc87d7f8ffab2ae719\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/42/c2/d3cd8ea9f896260294ea5fbeb985905e81654b670d7753a419\n",
      "  Building wheel for JsonForm (setup.py): started\n",
      "  Building wheel for JsonForm (setup.py): finished with status 'done'\n",
      "  Created wheel for JsonForm: filename=JsonForm-0.0.2-py3-none-any.whl size=3325 sha256=1a4d4e468e5c23f40c227b5797e2b08f193f41fe07b08eb0190b02688dc5e923\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/f9/2d/61747ec74e70a079a428c54fc1167b03a4198a2e2ac4be5f07\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3923 sha256=424fd8cc3a898d33db42b190f241461b6f4626d011038f773fab90ebe08445da\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for shap (setup.py): started\n",
      "  Building wheel for shap (setup.py): finished with status 'done'\n",
      "  Created wheel for shap: filename=shap-0.34.0-cp36-cp36m-linux_x86_64.whl size=387802 sha256=c9cce773b31391d70dfd7891c50a147960e637a708a8f168c75df9c1211ce33e\n",
      "  Stored in directory: /root/.cache/pip/wheels/88/56/c6/630b200696678c506f3057a1e7573c086e50d59fdcffcbfd04\n",
      "  Building wheel for PyYAML (setup.py): started\n",
      "  Building wheel for PyYAML (setup.py): finished with status 'done'\n",
      "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=18a2aeb8f249ab24ad10796705bccf1ad3139cdc324f6df249c4517fbd6c2a00\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/9d/ad/2ee53cf262cba1ffd8afe1487eef788ea3f260b7e6232a80fc\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=00cda33f62fcacc589403aa17b7ce0e70385e6e57100b60c6143d6318194ff7c\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/38/8f/e5bd4465e4b72c8e4d1530ac46e1a42e1d2495f8c93242d5f1\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.4.0-py3-none-any.whl size=13333 sha256=07abc80af1656f97015b4ae91add555abf069aaeff783324e3108419014f1683\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/2a/e1/6f7be2e2ea150e2486bff64fd6f0670f4f35f4c8f31c819fb8\n",
      "  Building wheel for pyrsistent (setup.py): started\n",
      "  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.16.0-cp36-cp36m-linux_x86_64.whl size=113428 sha256=9e2058498ea9a8ccf692dc6f4b8508d4b7994399e2d2d3913fd7c28112a9c4e1\n",
      "  Stored in directory: /root/.cache/pip/wheels/d1/8a/1c/32ab9017418a2c64e4fbaf503c08648bed2f8eb311b869a464\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=0199c688258fc8248d87404d37fc2ba8c42de89cadc32536a04708cc3f7e0e32\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "Successfully built fusepy wrapt dill smart-open psutil py-cpuinfo JsonSir JsonForm json-logging-py shap PyYAML fire liac-arff pyrsistent termcolor\n",
      "Installing collected packages: chardet, urllib3, idna, requests, isodate, oauthlib, requests-oauthlib, msrest, pycparser, cffi, cryptography, PyJWT, adal, msrestazure, azureml-train-restclients-hyperdrive, backports.weakref, backports.tempfile, azure-common, azure-mgmt-containerregistry, pyopenssl, pyasn1, ndg-httpsclient, websocket-client, docker, jmespath, azure-mgmt-authorization, pathspec, contextlib2, jeepney, SecretStorage, ruamel.yaml, azure-graphrbac, azure-mgmt-storage, azure-mgmt-resource, zipp, importlib-metadata, jsonpickle, azure-mgmt-keyvault, azureml-core, applicationinsights, azureml-telemetry, mccabe, pyflakes, pycodestyle, entrypoints, flake8, azureml-train-core, azureml-train, cloudpickle, azureml-dataprep-native, distro, dotnetcore2, msal, portalocker, msal-extensions, azure-core, azure-identity, fusepy, pyarrow, azureml-dataprep, azureml-automl-core, azureml-train-automl-client, azureml-pipeline-core, azureml-pipeline-steps, azureml-pipeline, wheel, scipy, patsy, statsmodels, JsonSir, PyYAML, python-easyconfig, pyrsistent, attrs, jsonschema, JsonForm, resource, tqdm, shap, joblib, interpret-core, packaging, interpret-community, azureml-interpret, azureml-explain-model, onnxruntime, termcolor, fire, protobuf, typing-extensions, onnx, onnxconverter-common, keras2onnx, skl2onnx, onnxmltools, nimbusml, pmdarima, psutil, lightgbm, sklearn-pandas, boto, docutils, botocore, s3transfer, boto3, smart-open, gensim, dill, py-cpuinfo, azureml-automl-runtime, configparser, liac-arff, azureml-model-management-sdk, gunicorn, MarkupSafe, Jinja2, click, itsdangerous, werkzeug, flask, json-logging-py, azureml-defaults, azureml-train-automl-runtime, azureml-train-automl, azureml-sdk, wrapt, inference-schema\n",
      "  Attempting uninstall: wheel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "\n",
      "Successfully installed Jinja2-2.11.2 JsonForm-0.0.2 JsonSir-0.0.2 MarkupSafe-1.1.1 PyJWT-1.7.1 PyYAML-5.3.1 SecretStorage-3.1.2 adal-1.2.2 applicationinsights-0.11.9 attrs-19.3.0 azure-common-1.1.25 azure-core-1.4.0 azure-graphrbac-0.61.1 azure-identity-1.2.0 azure-mgmt-authorization-0.60.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-9.0.0 azure-mgmt-storage-9.0.0 azureml-automl-core-1.4.0 azureml-automl-runtime-1.4.0.post1 azureml-core-1.4.0.post1 azureml-dataprep-1.4.6 azureml-dataprep-native-14.1.0 azureml-defaults-1.4.0 azureml-explain-model-1.4.0 azureml-interpret-1.4.0 azureml-model-management-sdk-1.0.1b6.post1 azureml-pipeline-1.4.0 azureml-pipeline-core-1.4.0 azureml-pipeline-steps-1.4.0 azureml-sdk-1.4.0 azureml-telemetry-1.4.0 azureml-train-1.4.0 azureml-train-automl-1.4.0 azureml-train-automl-client-1.4.0 azureml-train-automl-runtime-1.4.0.post1 azureml-train-core-1.4.0 azureml-train-restclients-hyperdrive-1.4.0 backports.tempfile-1.0 backports.weakref-1.0.post1 boto-2.49.0 boto3-1.13.0 botocore-1.16.0 cffi-1.14.0 chardet-3.0.4 click-7.1.2 cloudpickle-1.4.1 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-2.9.2 dill-0.3.1.1 distro-1.5.0 docker-4.2.0 docutils-0.15.2 dotnetcore2-2.1.13 entrypoints-0.3 fire-0.3.1 flake8-3.7.9 flask-1.0.3 fusepy-3.0.1 gensim-3.8.2 gunicorn-19.9.0 idna-2.9 importlib-metadata-1.6.0 inference-schema-1.0.2 interpret-community-0.10.2 interpret-core-0.1.21 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.4.3 jmespath-0.9.5 joblib-0.14.1 json-logging-py-0.2 jsonpickle-1.4.1 jsonschema-3.2.0 keras2onnx-1.6.1 liac-arff-2.4.0 lightgbm-2.3.0 mccabe-0.6.1 msal-1.2.0 msal-extensions-0.1.3 msrest-0.6.13 msrestazure-0.6.3 ndg-httpsclient-0.5.1 nimbusml-1.7.0 oauthlib-3.1.0 onnx-1.6.0 onnxconverter-common-1.6.0 onnxmltools-1.4.1 onnxruntime-1.0.0 packaging-20.3 pathspec-0.8.0 patsy-0.5.1 pmdarima-1.1.1 portalocker-1.7.0 protobuf-3.11.3 psutil-5.7.0 py-cpuinfo-5.0.0 pyarrow-0.17.0 pyasn1-0.4.8 pycodestyle-2.5.0 pycparser-2.20 pyflakes-2.1.1 pyopenssl-19.1.0 pyrsistent-0.16.0 python-easyconfig-0.1.7 requests-2.23.0 requests-oauthlib-1.3.0 resource-0.2.1 ruamel.yaml-0.15.89 s3transfer-0.3.3 scipy-1.1.0 shap-0.34.0 skl2onnx-1.4.9 sklearn-pandas-1.7.0 smart-open-1.9.0 statsmodels-0.10.2 termcolor-1.1.0 tqdm-4.45.0 typing-extensions-3.7.4.2 urllib3-1.25.9 websocket-client-0.57.0 werkzeug-0.16.1 wheel-0.30.0 wrapt-1.11.1 zipp-3.1.0\n",
      "\u001b[91m\n",
      "\u001b[0m#\n",
      "# To activate this environment, use:\n",
      "# > source activate /azureml-envs/azureml_fb099990cc95c5127ccd5b5aee9008eb\n",
      "#\n",
      "# To deactivate an active environment, use:\n",
      "# > source deactivate\n",
      "#\n",
      "\n",
      "\n",
      "Removing intermediate container 0933dcfbc791\n",
      " ---> 8d2ff2678464\n",
      "Step 9/15 : ENV PATH /azureml-envs/azureml_fb099990cc95c5127ccd5b5aee9008eb/bin:$PATH\n",
      " ---> Running in a36a1b61c4eb\n",
      "Removing intermediate container a36a1b61c4eb\n",
      " ---> 734739ce551f\n",
      "Step 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_fb099990cc95c5127ccd5b5aee9008eb\n",
      " ---> Running in d8a8f75b2d1a\n",
      "Removing intermediate container d8a8f75b2d1a\n",
      " ---> 704f8ada58cb\n",
      "Step 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_fb099990cc95c5127ccd5b5aee9008eb/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 88c6773bdadc\n",
      "Removing intermediate container 88c6773bdadc\n",
      " ---> b740278f972e\n",
      "Step 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 97e9f5d40742\n",
      "Step 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit \"--repositories\" \"[]\" /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 1cb1c1a34c25\n",
      "Removing intermediate container 1cb1c1a34c25\n",
      " ---> 92a273224905\n",
      "Step 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 47c4887a3ab9\n",
      "Removing intermediate container 47c4887a3ab9\n",
      " ---> 68b2bf044d23\n",
      "Step 15/15 : CMD [\"bash\"]\n",
      " ---> Running in 3ac36c928513\n",
      "Removing intermediate container 3ac36c928513\n",
      " ---> 3ca2a8bad37e\n",
      "Successfully built 3ca2a8bad37e\n",
      "Successfully tagged pipelines5112a485.azurecr.io/azureml/azureml_4d2abf2a4d077fa8b64770f2e645d085:latest\n",
      "2020/04/30 20:27:08 Successfully executed container: acb_step_0\n",
      "2020/04/30 20:27:08 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/04/30 20:27:08 Pushing image: pipelines5112a485.azurecr.io/azureml/azureml_4d2abf2a4d077fa8b64770f2e645d085:latest, attempt 1\n",
      "The push refers to repository [pipelines5112a485.azurecr.io/azureml/azureml_4d2abf2a4d077fa8b64770f2e645d085]\n",
      "a4e06d2bb623: Preparing\n",
      "583678a5f4da: Preparing\n",
      "d26d3924a2b5: Preparing\n",
      "c91deb4027b3: Preparing\n",
      "0e19eb12cecc: Preparing\n",
      "69ad73078021: Preparing\n",
      "e1171d4d60ca: Preparing\n",
      "6ef1a8ae63b7: Preparing\n",
      "85389f9ead9e: Preparing\n",
      "f2608f66a0e3: Preparing\n",
      "0e259b09e5f4: Preparing\n",
      "340dc32eb998: Preparing\n",
      "df18b66efaa6: Preparing\n",
      "ccdb13a20bf2: Preparing\n",
      "9513cdf4e497: Preparing\n",
      "7f083f9454c0: Preparing\n",
      "29f36b5893dc: Preparing\n",
      "f2608f66a0e3: Waiting\n",
      "0e259b09e5f4: Waiting\n",
      "340dc32eb998: Waiting\n",
      "df18b66efaa6: Waiting\n",
      "ccdb13a20bf2: Waiting\n",
      "9513cdf4e497: Waiting\n",
      "7f083f9454c0: Waiting\n",
      "29f36b5893dc: Waiting\n",
      "69ad73078021: Waiting\n",
      "e1171d4d60ca: Waiting\n",
      "6ef1a8ae63b7: Waiting\n",
      "85389f9ead9e: Waiting\n",
      "a4e06d2bb623: Pushed\n",
      "0e19eb12cecc: Pushed\n",
      "d26d3924a2b5: Pushed\n",
      "69ad73078021: Pushed\n",
      "e1171d4d60ca: Pushed\n",
      "6ef1a8ae63b7: Pushed\n",
      "c91deb4027b3: Pushed\n",
      "340dc32eb998: Pushed\n",
      "85389f9ead9e: Pushed\n",
      "ccdb13a20bf2: Pushed\n",
      "0e259b09e5f4: Pushed\n",
      "f2608f66a0e3: Pushed\n",
      "9513cdf4e497: Pushed\n",
      "7f083f9454c0: Pushed\n",
      "29f36b5893dc: Pushed\n",
      "df18b66efaa6: Pushed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core import Experiment\n",
    "\n",
    "pipeline = Pipeline(ws, [dataprep_step, train_step, register_step])\n",
    "\n",
    "experiment = Experiment(workspace=ws, name='titanic_automl')\n",
    "\n",
    "run = experiment.submit(pipeline, show_output=True)\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above combines the data preparation, automated ML, and model-registering steps into a `Pipeline` object. It then creates an `Experiment` object. The `Experiment` constructor will retrieve the named experiment if it exists or create it if necessary. It submits the `Pipeline` to the `Experiment`, creating a `Run` object that will asynchronously run the pipeline. The `wait_for_completion()` function blocks until the run completes.\n",
    "\n",
    "### Download the results of an automated ML run \n",
    "\n",
    "While the `run` object in the code above is from the actively running context, you can also retrieve completed `Run` objects from the `Workspace` by way of an `Experiment` object.\n",
    "\n",
    "The workspace contains a complete record of all your experiments and runs. You can either use the portal to find and download the outputs of experiments or use code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on local machine\n",
    "experiment = ws.experiments['titanic_automl']\n",
    "run = next(run for run in ex.get_runs() if run.id == 'aaaaaaaa-bbbb-cccc-dddd-0123456789AB')\n",
    "automl_run = next(r for r in run.get_children() if r.name == 'AutoML_Classification')\n",
    "outputs = automl_run.get_outputs()\n",
    "metrics = outputs['default_metrics_AutoML_Classification']\n",
    "model = outputs['default_model_AutoML_Classification']\n",
    "\n",
    "metrics.get_port_data_reference().download('.')\n",
    "model.get_port_data_reference().download('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above snippet would run on your local machine. First, it logs on to the workspace. It retrieves the `Experiment` named `titanic_automl` and from that `Experiment`, the `Run` in which you're interested. Notice that you'd set the value being compared to `run.id` to that of the run in which you're interested.\n",
    "\n",
    "Each `Run` object contains `StepRun` objects that contain information about the individual pipeline step run. The `run` is searched for the `StepRun` object for the `AutoMLStep`. The outputs are retrieved using their default names, which are available even if you don't pass `PipelineData` objects to the `outputs` parameter of the `AutoMLStep`. \n",
    "\n",
    "Finally, the actual metrics and model are downloaded to your local machine for further processing.\n",
    "\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Run this Jupyter notebook showing a [complete example of automated ML in a pipeline](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/nyc-taxi-data-regression-model-building/nyc-taxi-data-regression-model-building.ipynb) that uses regression to predict taxi fares\n",
    "- [Create automated ML experiments without writing code](how-to-use-automated-ml-for-ml-models.md)\n",
    "- Explore a variety of [Jupyter notebooks demonstrating automated ML](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/automated-machine-learning)\n",
    "- Read about integrating your pipeline in to [End-to-end MLOps](https://docs.microsoft.com/azure/machine-learning/concept-model-management-and-deployment#automate-the-ml-lifecycle) or investigate the [MLOps Github repository](https://github.com/Microsoft/MLOpspython)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
