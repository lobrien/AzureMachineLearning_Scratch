{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='pipelines', subscription_id='65a1016d-0f67-45d2-b838-b8f373d6d52e', resource_group='laobri-ml')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core import Workspace \n",
    "import os \n",
    "\n",
    "ws = Workspace.from_config(auth=InteractiveLoginAuthentication(tenant_id=os.environ[\"AML_TENANT_ID\"]))\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "\n",
    "\n",
    "compute_name = \"cpu-compute3\"\n",
    "if not compute_name in ws.compute_targets :\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\n",
    "                                                                min_nodes=0,\n",
    "                                                                max_nodes=1)\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # Show the result\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmlCompute(workspace=Workspace.create(name='pipelines', subscription_id='65a1016d-0f67-45d2-b838-b8f373d6d52e', resource_group='laobri-ml'), name=cpu-compute3, id=/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourceGroups/laobri-ml/providers/Microsoft.MachineLearningServices/workspaces/pipelines/computes/cpu-compute3, type=AmlCompute, provisioning_state=Succeeded, location=westus, tags=None)\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute \n",
    "\n",
    "compute_target = AmlCompute(ws, compute_name)\n",
    "print(compute_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "datastore = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ws.environments['AzureML-Tutorial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "azureml.core.environment.Environment"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azureml-core==1.7.0',\n",
       " 'azureml-defaults==1.7.0',\n",
       " 'azureml-telemetry==1.7.0',\n",
       " 'azureml-train-restclients-hyperdrive==1.7.0',\n",
       " 'azureml-train-core==1.7.0',\n",
       " 'azureml-widgets==1.7.0',\n",
       " 'azureml-pipeline-core==1.7.0.post1',\n",
       " 'azureml-pipeline-steps==1.7.0',\n",
       " 'azureml-opendatasets==1.7.0.post1',\n",
       " 'azureml-automl-core==1.7.0.post1',\n",
       " 'azureml-automl-runtime==1.7.0.post1',\n",
       " 'azureml-train-automl-client==1.7.0.post1',\n",
       " 'azureml-train-automl-runtime==1.7.0.post1',\n",
       " 'azureml-train-automl==1.7.0',\n",
       " 'azureml-train==1.7.0',\n",
       " 'azureml-sdk==1.7.0.post1',\n",
       " 'azureml-interpret==1.7.0.post1',\n",
       " 'azureml-tensorboard==1.7.0',\n",
       " 'azureml-mlflow==1.7.0',\n",
       " 'mlflow',\n",
       " 'sklearn-pandas']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in e.python.conda_dependencies.pip_packages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True if the dependencies include that string at least once\n",
    "True in ('sklearn' in p for p in e.python.conda_dependencies.pip_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "builtin_function_or_method"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ws.environments.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AzureML-TensorFlow-2.0-CPU',\n",
       " 'AzureML-Chainer-5.1.0-GPU',\n",
       " 'AzureML-TensorFlow-1.12-CPU',\n",
       " 'AzureML-TensorFlow-2.0-GPU',\n",
       " 'AzureML-PyTorch-1.1-CPU',\n",
       " 'AzureML-PyTorch-1.1-GPU',\n",
       " 'AzureML-PyTorch-1.2-CPU',\n",
       " 'AzureML-Minimal',\n",
       " 'AzureML-TensorFlow-1.10-CPU',\n",
       " 'AzureML-PyTorch-1.3-CPU',\n",
       " 'AzureML-PyTorch-1.0-CPU',\n",
       " 'AzureML-Tutorial',\n",
       " 'AzureML-PyTorch-1.2-GPU',\n",
       " 'AzureML-Scikit-learn-0.20.3',\n",
       " 'AzureML-AutoML',\n",
       " 'AzureML-TensorFlow-1.13-CPU',\n",
       " 'AzureML-TensorFlow-1.12-GPU',\n",
       " 'AzureML-PyTorch-1.3-GPU',\n",
       " 'AzureML-PyTorch-1.0-GPU',\n",
       " 'AzureML-Chainer-5.1.0-CPU',\n",
       " 'AzureML-PyTorch-1.4-GPU',\n",
       " 'AzureML-TensorFlow-1.13-GPU',\n",
       " 'AzureML-TensorFlow-1.10-GPU',\n",
       " 'AzureML-PySpark-MmlSpark-0.15',\n",
       " 'AzureML-Dask-CPU',\n",
       " 'AzureML-Dask-GPU',\n",
       " 'AzureML-PyTorch-1.5-CPU',\n",
       " 'AzureML-PyTorch-1.5-GPU',\n",
       " 'AzureML-Sidecar',\n",
       " 'AzureML-Designer-CV-Transform',\n",
       " 'AzureML-Designer-Score',\n",
       " 'AzureML-Designer-PyTorch',\n",
       " 'AzureML-Designer-CV',\n",
       " 'AzureML-TensorFlow-2.1-GPU',\n",
       " 'AzureML-TensorFlow-2.1-CPU',\n",
       " 'AzureML-VowpalWabbit-8.8.0',\n",
       " 'AzureML-Hyperdrive-ForecastDNN',\n",
       " 'AzureML-PyTorch-1.4-CPU',\n",
       " 'AzureML-AutoML-DNN',\n",
       " 'AzureML-AutoML-DNN-GPU',\n",
       " 'AzureML-Designer-Transform',\n",
       " 'AzureML-Designer',\n",
       " 'AzureML-AutoML-GPU',\n",
       " 'AzureML-Designer-IO',\n",
       " 'AzureML-Designer-NLP',\n",
       " 'AzureML-Designer-R',\n",
       " 'AzureML-Designer-Recommender']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def env_contains(e, deps) : \n",
    "    def env_contains_single(e, dep) : \n",
    "        conda_dependencies = e.python.conda_dependencies\n",
    "        # Return True if pip-installed (`p` contains version, e.g., azureml-core==1.7.0.post1,  so can't just `dep in pip_packages`)\n",
    "        if (dep in p for p in conda_dependencies.pip_packages) :\n",
    "            return True\n",
    "        # Return True if conda-installled\n",
    "        if dep in conda_dependencies.conda_packages :\n",
    "            return True\n",
    "        return False\n",
    "    return not (False in (env_contains_single(e, dep) for dep in deps))\n",
    "\n",
    "def envs_containing(deps) : \n",
    "    for name in ws.environments :\n",
    "        if env_contains(ws.environments[name], deps) : \n",
    "            yield name\n",
    "\n",
    "list(envs_containing(['automl']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Is a little better but still insufficient, as it seems to miss transient packages. For instance, the pipeline developed below relies on `pyarrow`, but you won't see that in the list below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"AzureML-Tutorial\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-core==1.7.0\",\n",
       "                        \"azureml-defaults==1.7.0\",\n",
       "                        \"azureml-telemetry==1.7.0\",\n",
       "                        \"azureml-train-restclients-hyperdrive==1.7.0\",\n",
       "                        \"azureml-train-core==1.7.0\",\n",
       "                        \"azureml-widgets==1.7.0\",\n",
       "                        \"azureml-pipeline-core==1.7.0.post1\",\n",
       "                        \"azureml-pipeline-steps==1.7.0\",\n",
       "                        \"azureml-opendatasets==1.7.0.post1\",\n",
       "                        \"azureml-automl-core==1.7.0.post1\",\n",
       "                        \"azureml-automl-runtime==1.7.0.post1\",\n",
       "                        \"azureml-train-automl-client==1.7.0.post1\",\n",
       "                        \"azureml-train-automl-runtime==1.7.0.post1\",\n",
       "                        \"azureml-train-automl==1.7.0\",\n",
       "                        \"azureml-train==1.7.0\",\n",
       "                        \"azureml-sdk==1.7.0.post1\",\n",
       "                        \"azureml-interpret==1.7.0.post1\",\n",
       "                        \"azureml-tensorboard==1.7.0\",\n",
       "                        \"azureml-mlflow==1.7.0\",\n",
       "                        \"mlflow\",\n",
       "                        \"sklearn-pandas\"\n",
       "                    ]\n",
       "                },\n",
       "                \"pandas\",\n",
       "                \"numpy\",\n",
       "                \"tqdm\",\n",
       "                \"scikit-learn\",\n",
       "                \"matplotlib\"\n",
       "            ],\n",
       "            \"name\": \"azureml_60d4a818af98d09929892610b12943cb\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"36\"\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.environments['AzureML-Tutorial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "aml_run_config = RunConfiguration()\n",
    "aml_run_config.target = compute_target\n",
    "from azureml.core import Environment\n",
    "\n",
    "# Get curated environment\n",
    "curated_environment = Environment.get(workspace=ws, name=\"AutoML-Tutorial\")\n",
    "\n",
    "USE_CURATED_ENV = True\n",
    "if USE_CURATED_ENV :\n",
    "    aml_run_config.environment = curated_environment\n",
    "else:\n",
    "    #Use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "    aml_run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "    #Specify CondaDependencies obj, add necessary packages\n",
    "    aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "        conda_packages=['pandas','scikit-learn', 'pyarrow'], \n",
    "        pip_packages=['azureml-sdk[automl,explain]', 'azureml-dataprep[fuse,pandas]'], \n",
    "        pin_sdk_version=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Grab an open dataset and register it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is baseline data. If the `Dataset` does not exist, create and register it. Not a part of the Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "if not 'titanic_ds' in ws.datasets.keys() :\n",
    "    # create a TabularDataset from Titanic training data\n",
    "    web_paths = ['https://dprepdata.blob.core.windows.net/demo/Titanic.csv',\n",
    "                 'https://dprepdata.blob.core.windows.net/demo/Titanic2.csv']\n",
    "    titanic_ds = Dataset.Tabular.from_delimited_files(path=web_paths)\n",
    "\n",
    "    titanic_ds.register(workspace = ws,\n",
    "                                     name = 'titanic_ds',\n",
    "                                     description = 'new titanic training data',\n",
    "                                     create_new_version = True)\n",
    "\n",
    "titanic_ds = Dataset.get_by_name(ws, 'titanic_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "azureml.data.tabular_dataset.TabularDataset"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(titanic_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataprep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataprep.py\n",
    "from azureml.core import Run\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "\n",
    "RANDOM_SEED=42\n",
    "\n",
    "def prepare_age(df):\n",
    "    # Fill in missing Age values from distribution of present Age values \n",
    "    mean = df[\"Age\"].mean()\n",
    "    std = df[\"Age\"].std()\n",
    "    is_null = df[\"Age\"].isnull().sum()\n",
    "    # compute enough (== is_null().sum()) random numbers between the mean, std\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    # fill NaN values in Age column with random values generated\n",
    "    age_slice = df[\"Age\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    df[\"Age\"] = age_slice\n",
    "    df[\"Age\"] = df[\"Age\"].astype(int)\n",
    "    \n",
    "    # Quantize age into 5 classes\n",
    "    df['Age_Group'] = pd.qcut(df['Age'],5, labels=False)\n",
    "    df.drop(['Age'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def prepare_fare(df):\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    df['Fare_Group'] = pd.qcut(df['Fare'],5,labels=False)\n",
    "    df.drop(['Fare'], axis=1, inplace=True)\n",
    "    return df \n",
    "\n",
    "def prepare_genders(df):\n",
    "    genders = {\"male\": 0, \"female\": 1, \"unknown\": 2}\n",
    "    df['Sex'] = df['Sex'].map(genders)\n",
    "    df['Sex'].fillna(2, inplace=True)\n",
    "    df['Sex'] = df['Sex'].astype(int)\n",
    "    return df\n",
    "\n",
    "def prepare_embarked(df):\n",
    "    df['Embarked'].replace('', 'U', inplace=True)\n",
    "    df['Embarked'].fillna('U', inplace=True)\n",
    "    ports = {\"S\": 0, \"C\": 1, \"Q\": 2, \"U\": 3}\n",
    "    df['Embarked'] = df['Embarked'].map(ports)\n",
    "    return df\n",
    "    \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_path', dest='output_path', required=True)\n",
    "args = parser.parse_args()\n",
    "    \n",
    "titanic_ds = Run.get_context().input_datasets['titanic_ds']\n",
    "df = titanic_ds.to_pandas_dataframe().drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "df = prepare_embarked(prepare_genders(prepare_fare(prepare_age(df))))\n",
    "\n",
    "os.makedirs(os.path.dirname(args.output_path), exist_ok=True)\n",
    "pq.write_table(pa.Table.from_pandas(df), args.output_path)\n",
    "\n",
    "print(f\"Wrote test to {args.output_path} and train to {args.output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "prepped_data_path = PipelineData(\"titanic_train\", datastore).as_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "dataprep_step = PythonScriptStep(\n",
    "    name=\"dataprep\", \n",
    "    script_name=\"dataprep.py\", \n",
    "    compute_target=compute_target, \n",
    "    runconfig=aml_run_config,\n",
    "    arguments=[\"--output_path\", prepped_data_path],\n",
    "    inputs=[titanic_ds.as_named_input(\"titanic_ds\")],\n",
    "    outputs=[prepped_data_path],\n",
    "    allow_reuse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train with AutoMLStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML config created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "prepped_data_potds = prepped_data_path.parse_parquet_files(file_extension=None)\n",
    "\n",
    "# Change iterations to a reasonable number (50) to get better accuracy\n",
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\" : 10,\n",
    "    \"iterations\" : 10,\n",
    "    #\"experiment_timeout_hours\" : .1,\n",
    "    \"primary_metric\" : 'AUC_weighted'\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             path = '.',\n",
    "                             debug_log = 'automated_ml_errors.log',\n",
    "                             compute_target = compute_target,\n",
    "                             run_configuration = aml_run_config,\n",
    "                             featurization = 'auto',\n",
    "                             training_data = prepped_data_potds,\n",
    "                             label_column_name = 'Survived',\n",
    "                             **automl_settings)\n",
    "                             \n",
    "print(\"AutoML config created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_step created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import TrainingOutput\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                           datastore=datastore,\n",
    "                           pipeline_output_name='metrics_output',\n",
    "                           training_output=TrainingOutput(type='Metrics'))\n",
    "model_data = PipelineData(name='best_model_data',\n",
    "                           datastore=datastore,\n",
    "                           pipeline_output_name='model_output',\n",
    "                           training_output=TrainingOutput(type='Model'))\n",
    "\n",
    "\n",
    "train_step = AutoMLStep(name='AutoML_Classification',\n",
    "                                 automl_config=automl_config,\n",
    "                                 passthru_automl_config=False,\n",
    "                                 outputs=[metrics_data,model_data],\n",
    "                                 allow_reuse=True)\n",
    "print(\"train_step created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting register_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile register_model.py\n",
    "from azureml.core.model import Model, Dataset\n",
    "from azureml.core.run import Run, _OfflineRun\n",
    "from azureml.core import Workspace\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_name\", required=True)\n",
    "parser.add_argument(\"--model_path\", required=True)\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(f\"model_name : {args.model_name}\")\n",
    "print(f\"model_path: {args.model_path}\")\n",
    "\n",
    "run = Run.get_context()\n",
    "ws = Workspace.from_config() if type(run) == _OfflineRun else run.experiment.workspace\n",
    "\n",
    "model = Model.register(workspace=ws,\n",
    "                       model_path=args.model_path,\n",
    "                       model_name=args.model_name)\n",
    "\n",
    "print(\"Registered version {0} of model {1}\".format(model.version, model.name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "\n",
    "# The model name with which to register the trained model in the workspace.\n",
    "model_name = PipelineParameter(\"model_name\", default_value=\"TitanicSurvival\")\n",
    "\n",
    "register_step = PythonScriptStep(script_name=\"register_model.py\",\n",
    "                                       name=\"register_model\",\n",
    "                                       allow_reuse=False,\n",
    "                                       arguments=[\"--model_name\", model_name, \"--model_path\", model_data],\n",
    "                                       inputs=[model_data],\n",
    "                                       compute_target=compute_target,\n",
    "                                       runconfig=aml_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "if not 'titanic_automl' in ws.experiments.keys() :\n",
    "    Experiment(ws, 'titanic_automl')\n",
    "experiment = ws.experiments['titanic_automl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(ws, [dataprep_step, train_step, register_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step dataprep [f8a165bc][854ee7a9-c85b-4a9d-9872-b8af61e18ea4], (This step will run and generate new outputs)\n",
      "Created step AutoML_Classification [4c048bc8][c7b9d2c3-b5a4-4eff-8904-aee65b1676bd], (This step will run and generate new outputs)\n",
      "Created step register_model [b468f480][579f3abc-bf4f-46c7-a749-500e218c28b6], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun b07848c5-644c-41f5-be07-1de561a4c836\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/b07848c5-644c-41f5-be07-1de561a4c836?wsid=/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourcegroups/laobri-ml/workspaces/pipelines\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(pipeline, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: b07848c5-644c-41f5-be07-1de561a4c836\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/b07848c5-644c-41f5-be07-1de561a4c836?wsid=/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourcegroups/laobri-ml/workspaces/pipelines\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 4e8dd414-da72-49da-85ef-b3f21506ba81\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/4e8dd414-da72-49da-85ef-b3f21506ba81?wsid=/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourcegroups/laobri-ml/workspaces/pipelines\n",
      "StepRun( dataprep ) Status: NotStarted\n",
      "StepRun( dataprep ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=2, read=3, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x110f99650>: Failed to establish a new connection: [Errno 60] Operation timed out')': /history/v1.0/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourceGroups/laobri-ml/providers/Microsoft.MachineLearningServices/workspaces/pipelines/experiments/titanic_automl/runs/4e8dd414-da72-49da-85ef-b3f21506ba81/details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/06/12 22:39:47 Downloading source code...\n",
      "2020/06/12 22:39:49 Finished downloading source code\n",
      "2020/06/12 22:39:49 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2020/06/12 22:39:49 Successfully set up Docker network: acb_default_network\n",
      "2020/06/12 22:39:49 Setting up Docker configuration...\n",
      "2020/06/12 22:39:50 Successfully set up Docker configuration\n",
      "2020/06/12 22:39:50 Logging in to registry: pipelines5112a485.azurecr.io\n",
      "2020/06/12 22:39:51 Successfully logged into pipelines5112a485.azurecr.io\n",
      "2020/06/12 22:39:51 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/06/12 22:39:51 Scanning for dependencies...\n",
      "2020/06/12 22:39:52 Successfully scanned dependencies\n",
      "2020/06/12 22:39:52 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  60.93kB\n",
      "\n",
      "Step 1/15 : FROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05: Pulling from azureml/base\n",
      "Digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      " ---> 93a72e6bd1ce\n",
      "Step 2/15 : USER root\n",
      " ---> Running in cae4d5063336\n",
      "Removing intermediate container cae4d5063336\n",
      " ---> 8da2ad75f7f4\n",
      "Step 3/15 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in bff5d34c4646\n",
      "Removing intermediate container bff5d34c4646\n",
      " ---> a70de746c2bb\n",
      "Step 4/15 : WORKDIR /\n",
      " ---> Running in 751e8dcc8e7b\n",
      "Removing intermediate container 751e8dcc8e7b\n",
      " ---> c3041c9a207d\n",
      "Step 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> a0bc64596f2c\n",
      "Step 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in b3ff2a3ef529\n",
      "Removing intermediate container b3ff2a3ef529\n",
      " ---> 36759e01f0e6\n",
      "Step 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> 28c3e84e3a95\n",
      "Step 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 193aa5e238fe\n",
      "Solving environment: ...working... \n",
      "done\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "libgomp-9.2.0        | 816 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgomp-9.2.0        | 816 KB    | #########5 |  95% \u001b[0m\u001b[91m\n",
      "libgomp-9.2.0        | 816 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "tk-8.5.19            | 1.9 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "tk-8.5.19            | 1.9 MB    | #######7   |  78% \u001b[0m\u001b[91m\n",
      "tk-8.5.19            | 1.9 MB    | #########1 |  91% \u001b[0m\u001b[91m\n",
      "tk-8.5.19            | 1.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "_openmp_mutex-4.5    | 435 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "_openmp_mutex-4.5    | 435 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pip-20.1.1           | 1.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "pip-20.1.1           | 1.1 MB    | ########   |  81% \u001b[0m\u001b[91m\n",
      "pip-20.1.1           | 1.1 MB    | #########9 |  99% \u001b[0m\u001b[91m\n",
      "pip-20.1.1           | 1.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "setuptools-47.1.1    | 642 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "setuptools-47.1.1    | 642 KB    | ########7  |  88% \u001b[0m\u001b[91m\n",
      "setuptools-47.1.1    | 642 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "zlib-1.2.11          | 105 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "zlib-1.2.11          | 105 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ca-certificates-2020 | 147 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ca-certificates-2020 | 147 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python_abi-3.6       | 4 KB      |            |   0% \u001b[0m\u001b[91m\n",
      "python_abi-3.6       | 4 KB      | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "certifi-2020.4.5.2   | 152 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "certifi-2020.4.5.2   | 152 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "readline-6.2         | 713 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "readline-6.2         | 713 KB    | #########1 |  92% \u001b[0m\u001b[91m\n",
      "readline-6.2         | 713 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "xz-5.2.5             | 430 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "xz-5.2.5             | 430 KB    | #########8 |  99% \u001b[0m\u001b[91m\n",
      "xz-5.2.5             | 430 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "sqlite-3.13.0        | 4.9 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "sqlite-3.13.0        | 4.9 MB    | #######6   |  77% \u001b[0m\u001b[91m\n",
      "sqlite-3.13.0        | 4.9 MB    | #########5 |  96% \u001b[0m\u001b[91m\n",
      "sqlite-3.13.0        | 4.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ncurses-5.9          | 1.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "ncurses-5.9          | 1.1 MB    | #######8   |  79% \u001b[0m\u001b[91m\n",
      "ncurses-5.9          | 1.1 MB    | #########1 |  91% \u001b[0m\u001b[91m\n",
      "ncurses-5.9          | 1.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgcc-ng-9.2.0      | 8.2 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.2.0      | 8.2 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.2.0      | 8.2 MB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.2.0      | 8.2 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python-3.6.2         | 19.0 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 19.0 MB   | ###1       |  31% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 19.0 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 19.0 MB   | #########4 |  95% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 19.0 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "openssl-1.0.2u       | 3.2 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.2 MB    | #######6   |  76% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.2 MB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.2 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "wheel-0.34.2         | 24 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "wheel-0.34.2         | 24 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "_libgcc_mutex-0.1    | 3 KB      |            |   0% \u001b[0m\u001b[91m\n",
      "_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \u001b[0m\n",
      "Downloading and Extracting Packages\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... \n",
      "done\n",
      "Collecting azureml-core==1.7.0\n",
      "  Downloading azureml_core-1.7.0-py3-none-any.whl (1.4 MB)\n",
      "Collecting azureml-defaults==1.7.0\n",
      "  Downloading azureml_defaults-1.7.0-py3-none-any.whl (3.0 kB)\n",
      "Collecting SecretStorage\n",
      "  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\n",
      "Collecting PyJWT\n",
      "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.3-py2.py3-none-any.whl (40 kB)\n",
      "Collecting azure-mgmt-keyvault>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting azure-mgmt-resource>=1.2.1\n",
      "  Downloading azure_mgmt_resource-10.0.0-py2.py3-none-any.whl (809 kB)\n",
      "Collecting docker\n",
      "  Downloading docker-4.2.1-py2.py3-none-any.whl (143 kB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting msrest>=0.5.1\n",
      "  Downloading msrest-0.6.16-py2.py3-none-any.whl (84 kB)\n",
      "Collecting adal>=1.2.0\n",
      "  Downloading adal-1.2.4-py2.py3-none-any.whl (55 kB)\n",
      "Collecting requests>=2.19.1\n",
      "  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting azure-graphrbac>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pyopenssl\n",
      "  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting azure-common>=1.1.12\n",
      "  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\n",
      "Collecting azure-mgmt-network~=10.0\n",
      "  Downloading azure_mgmt_network-10.2.0-py2.py3-none-any.whl (8.6 MB)\n",
      "Collecting azure-mgmt-storage>=1.5.0\n",
      "  Downloading azure_mgmt_storage-10.0.0-py2.py3-none-any.whl (532 kB)\n",
      "Collecting ruamel.yaml>0.16.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading ruamel.yaml-0.16.10-py2.py3-none-any.whl (111 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.25.9-py2.py3-none-any.whl (126 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting azure-mgmt-authorization>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.60.0-py2.py3-none-any.whl (82 kB)\n",
      "Collecting pathspec\n",
      "  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n",
      "  Downloading cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7 MB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting gunicorn==19.9.0\n",
      "  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\n",
      "Collecting azureml-dataprep[fuse]<1.8.0a,>=1.7.0a\n",
      "  Downloading azureml_dataprep-1.7.0-py3-none-any.whl (27.6 MB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting werkzeug==0.16.1\n",
      "  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting jeepney>=0.4.2\n",
      "  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-1.6.1-py2.py3-none-any.whl (31 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting six>=1.4.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core==1.7.0->-r /azureml-environment-setup/condaenv.le0o9pdg.requirements.txt (line 1)) (2020.4.5.2)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n",
      "  Downloading ruamel.yaml.clib-0.2.0-cp36-cp36m-manylinux1_x86_64.whl (548 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (399 kB)\n",
      "Collecting dill>=0.2.7.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "Collecting pandas>=0.20.2\n",
      "  Downloading pandas-1.0.4-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Downloading liac-arff-2.4.0.tar.gz (15 kB)\n",
      "Collecting numpy>=1.13.0\n",
      "  Downloading numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n",
      "Collecting cloudpickle>=1.1.0\n",
      "  Downloading cloudpickle-1.4.1-py3-none-any.whl (26 kB)\n",
      "Collecting dotnetcore2>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.14-py3-none-manylinux1_x86_64.whl (29.3 MB)\n",
      "Collecting azure-identity<1.3.0,>=1.2.0\n",
      "  Downloading azure_identity-1.2.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting azureml-dataprep-native<15.0.0,>=14.2.0\n",
      "  Downloading azureml_dataprep_native-14.2.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting fusepy>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.6.0-py2.py3-none-any.whl (120 kB)\n",
      "Collecting msal-extensions~=0.1.3\n",
      "  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting msal<2.0.0,>=1.0.0\n",
      "  Downloading msal-1.3.0-py2.py3-none-any.whl (48 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\n",
      "Collecting portalocker~=1.0\n",
      "  Downloading portalocker-1.7.0-py2.py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: json-logging-py, dill, liac-arff, fusepy\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3923 sha256=a03a989eb596bc7269c4bdb6572d86e1b95f513da74f43f95acfacc9b9786baf\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78530 sha256=547742b0d0436bc31f964dd0564a33a4a238bada6767d989ed80b508fa3d9b95\n",
      "  Stored in directory: /root/.cache/pip/wheels/09/84/74/d2b4feb9ac9488bc83c475cb2cbe8e8b7d9cea8320d32f3787\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.4.0-py3-none-any.whl size=13333 sha256=34ab84b378959fba64722cba99f0e2f345f9764cc978a78e7e61d710b98c7509\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/2a/e1/6f7be2e2ea150e2486bff64fd6f0670f4f35f4c8f31c819fb8\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=092b8347044a9334228f8eb8f477793dfcf735a2568eea1766569748231b534e\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "Successfully built json-logging-py dill liac-arff fusepy\n",
      "Installing collected packages: six, pycparser, cffi, cryptography, jeepney, SecretStorage, zipp, importlib-metadata, jsonpickle, PyJWT, chardet, idna, urllib3, requests, oauthlib, requests-oauthlib, isodate, msrest, python-dateutil, adal, msrestazure, azure-common, azure-mgmt-keyvault, azure-mgmt-resource, websocket-client, docker, pytz, contextlib2, azure-graphrbac, pyopenssl, azure-mgmt-network, azure-mgmt-storage, ruamel.yaml.clib, ruamel.yaml, pyasn1, ndg-httpsclient, azure-mgmt-authorization, pathspec, backports.weakref, backports.tempfile, jmespath, azure-mgmt-containerregistry, azureml-core, dill, numpy, pandas, liac-arff, azureml-model-management-sdk, gunicorn, cloudpickle, distro, dotnetcore2, azure-core, portalocker, msal, msal-extensions, azure-identity, azureml-dataprep-native, fusepy, azureml-dataprep, applicationinsights, werkzeug, configparser, json-logging-py, MarkupSafe, Jinja2, itsdangerous, click, flask, azureml-defaults\n",
      "Successfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.1.2 adal-1.2.4 applicationinsights-0.11.9 azure-common-1.1.25 azure-core-1.6.0 azure-graphrbac-0.61.1 azure-identity-1.2.0 azure-mgmt-authorization-0.60.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-network-10.2.0 azure-mgmt-resource-10.0.0 azure-mgmt-storage-10.0.0 azureml-core-1.7.0 azureml-dataprep-1.7.0 azureml-dataprep-native-14.2.0 azureml-defaults-1.7.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.0 chardet-3.0.4 click-7.1.2 cloudpickle-1.4.1 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-2.9.2 dill-0.3.1.1 distro-1.5.0 docker-4.2.1 dotnetcore2-2.1.14 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.9 importlib-metadata-1.6.1 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.4.3 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-1.4.1 liac-arff-2.4.0 msal-1.3.0 msal-extensions-0.1.3 msrest-0.6.16 msrestazure-0.6.3 ndg-httpsclient-0.5.1 numpy-1.18.5 oauthlib-3.1.0 pandas-1.0.4 pathspec-0.8.0 portalocker-1.7.0 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 python-dateutil-2.8.1 pytz-2020.1 requests-2.23.0 requests-oauthlib-1.3.0 ruamel.yaml-0.16.10 ruamel.yaml.clib-0.2.0 six-1.15.0 urllib3-1.25.9 websocket-client-0.57.0 werkzeug-0.16.1 zipp-3.1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\n",
      "\u001b[0m#\n",
      "# To activate this environment, use:\n",
      "# > source activate /azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb\n",
      "#\n",
      "# To deactivate an active environment, use:\n",
      "# > source deactivate\n",
      "#\n",
      "\n",
      "\n",
      "Removing intermediate container 193aa5e238fe\n",
      " ---> af809a2eed2c\n",
      "Step 9/15 : ENV PATH /azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/bin:$PATH\n",
      " ---> Running in 2d055ce5607c\n",
      "Removing intermediate container 2d055ce5607c\n",
      " ---> 9cee76c9b4c2\n",
      "Step 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb\n",
      " ---> Running in 9ab2da76f2c4\n",
      "Removing intermediate container 9ab2da76f2c4\n",
      " ---> 118e89cf72e9\n",
      "Step 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 00587600357f\n",
      "Removing intermediate container 00587600357f\n",
      " ---> d87d2957734c\n",
      "Step 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 330d1505ef8b\n",
      "Step 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit \"--repositories\" \"[]\" /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in c43851a811f1\n",
      "Removing intermediate container c43851a811f1\n",
      " ---> 23b0272c0a86\n",
      "Step 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 5c9fd33974bc\n",
      "Removing intermediate container 5c9fd33974bc\n",
      " ---> f5662be014b6\n",
      "Step 15/15 : CMD [\"bash\"]\n",
      " ---> Running in cce98d82dd75\n",
      "Removing intermediate container cce98d82dd75\n",
      " ---> eff0a51009fd\n",
      "Successfully built eff0a51009fd\n",
      "Successfully tagged pipelines5112a485.azurecr.io/azureml/azureml_080bb68af85f96b85eb7cff522629683:latest\n",
      "2020/06/12 22:42:29 Successfully executed container: acb_step_0\n",
      "2020/06/12 22:42:29 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/06/12 22:42:29 Pushing image: pipelines5112a485.azurecr.io/azureml/azureml_080bb68af85f96b85eb7cff522629683:latest, attempt 1\n",
      "The push refers to repository [pipelines5112a485.azurecr.io/azureml/azureml_080bb68af85f96b85eb7cff522629683]\n",
      "2d0230c8b407: Preparing\n",
      "386cf93d7bad: Preparing\n",
      "af0ddd9866d6: Preparing\n",
      "186b321cf3f2: Preparing\n",
      "ddadbb84c4b6: Preparing\n",
      "ff2f25206584: Preparing\n",
      "e1171d4d60ca: Preparing\n",
      "6ef1a8ae63b7: Preparing\n",
      "85389f9ead9e: Preparing\n",
      "f2608f66a0e3: Preparing\n",
      "0e259b09e5f4: Preparing\n",
      "340dc32eb998: Preparing\n",
      "df18b66efaa6: Preparing\n",
      "ccdb13a20bf2: Preparing\n",
      "9513cdf4e497: Preparing\n",
      "7f083f9454c0: Preparing\n",
      "29f36b5893dc: Preparing\n",
      "ff2f25206584: Waiting\n",
      "e1171d4d60ca: Waiting\n",
      "6ef1a8ae63b7: Waiting\n",
      "85389f9ead9e: Waiting\n",
      "f2608f66a0e3: Waiting\n",
      "0e259b09e5f4: Waiting\n",
      "340dc32eb998: Waiting\n",
      "df18b66efaa6: Waiting\n",
      "ccdb13a20bf2: Waiting\n",
      "9513cdf4e497: Waiting\n",
      "7f083f9454c0: Waiting\n",
      "29f36b5893dc: Waiting\n",
      "186b321cf3f2: Pushed\n",
      "ddadbb84c4b6: Pushed\n",
      "af0ddd9866d6: Pushed\n",
      "2d0230c8b407: Pushed\n",
      "ff2f25206584: Pushed\n",
      "e1171d4d60ca: Pushed\n",
      "6ef1a8ae63b7: Pushed\n",
      "340dc32eb998: Pushed\n",
      "0e259b09e5f4: Pushed\n",
      "85389f9ead9e: Pushed\n",
      "ccdb13a20bf2: Pushed\n",
      "9513cdf4e497: Pushed\n",
      "7f083f9454c0: Pushed\n",
      "\n",
      "f2608f66a0e3: Pushed\n",
      "\n",
      "29f36b5893dc: Pushed\n",
      "df18b66efaa6: Pushed\n",
      "386cf93d7bad: Pushed\n",
      "latest: digest: sha256:0075a1dc7e0a80914a0d9bec230bb483e0e90197efa7ec684aa3b2f3073c6848 size: 3883\n",
      "2020/06/12 22:43:48 Successfully pushed image: pipelines5112a485.azurecr.io/azureml/azureml_080bb68af85f96b85eb7cff522629683:latest\n",
      "2020/06/12 22:43:48 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 157.556324)\n",
      "2020/06/12 22:43:48 Populating digests for step ID: acb_step_0...\n",
      "2020/06/12 22:43:50 Successfully populated digests for step ID: acb_step_0\n",
      "2020/06/12 22:43:50 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 79.429389)\n",
      "2020/06/12 22:43:50 The following dependencies were found:\n",
      "2020/06/12 22:43:50 \n",
      "- image:\n",
      "    registry: pipelines5112a485.azurecr.io\n",
      "    repository: azureml/azureml_080bb68af85f96b85eb7cff522629683\n",
      "    tag: latest\n",
      "    digest: sha256:0075a1dc7e0a80914a0d9bec230bb483e0e90197efa7ec684aa3b2f3073c6848\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/base\n",
      "    tag: intelmpi2018.3-ubuntu16.04\n",
      "    digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "  git: {}\n",
      "\n",
      "Run ID: cf1b was successful after 4m4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(60, 'ETIMEDOUT')\"))': /azureml/ExperimentRun/dcid.4e8dd414-da72-49da-85ef-b3f21506ba81/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=wQdISSxudyRccBgnjQqHhMPoPDG5wCPEfEBDblzItfo%3D&st=2020-06-12T22%3A35%3A59Z&se=2020-06-13T06%3A45%3A59Z&sp=r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_3e11f9e75c8a8d7bc0659f3abd4c450373af1d0600864c784b3c97723b044749_d.txt\n",
      "========================================================================================================================\n",
      "2020-06-12T22:46:35Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2020-06-12T22:46:35Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      "2020-06-12T22:46:35Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2020-06-12T22:46:35Z Starting output-watcher...\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_080bb68af85f96b85eb7cff522629683\n",
      "a1298f4ce990: Pulling fs layer\n",
      "04a3282d9c4b: Pulling fs layer\n",
      "9b0d3db6dc03: Pulling fs layer\n",
      "8269c605f3f1: Pulling fs layer\n",
      "6504d449e70c: Pulling fs layer\n",
      "4e38f320d0d4: Pulling fs layer\n",
      "b0a763e8ee03: Pulling fs layer\n",
      "11917a028ca4: Pulling fs layer\n",
      "a6c378d11cbf: Pulling fs layer\n",
      "6cc007ad9140: Pulling fs layer\n",
      "6c1698a608f3: Pulling fs layer\n",
      "c7c110b9ca73: Pulling fs layer\n",
      "a1eed15b592d: Pulling fs layer\n",
      "412964b3befe: Pulling fs layer\n",
      "f9efed77ad39: Pulling fs layer\n",
      "81a9cedab415: Pulling fs layer\n",
      "e18cf287723f: Pulling fs layer\n",
      "6cc007ad9140: Waiting\n",
      "6c1698a608f3: Waiting\n",
      "c7c110b9ca73: Waiting\n",
      "a1eed15b592d: Waiting\n",
      "412964b3befe: Waiting\n",
      "f9efed77ad39: Waiting\n",
      "81a9cedab415: Waiting\n",
      "e18cf287723f: Waiting\n",
      "4e38f320d0d4: Waiting\n",
      "8269c605f3f1: Waiting\n",
      "6504d449e70c: Waiting\n",
      "11917a028ca4: Waiting\n",
      "a6c378d11cbf: Waiting\n",
      "b0a763e8ee03: Waiting\n",
      "9b0d3db6dc03: Verifying Checksum\n",
      "9b0d3db6dc03: Download complete\n",
      "04a3282d9c4b: Verifying Checksum\n",
      "04a3282d9c4b: Download complete\n",
      "8269c605f3f1: Verifying Checksum\n",
      "8269c605f3f1: Download complete\n",
      "4e38f320d0d4: Verifying Checksum\n",
      "4e38f320d0d4: Download complete\n",
      "a1298f4ce990: Verifying Checksum\n",
      "a1298f4ce990: Download complete\n",
      "b0a763e8ee03: Verifying Checksum\n",
      "b0a763e8ee03: Download complete\n",
      "6504d449e70c: Verifying Checksum\n",
      "6504d449e70c: Download complete\n",
      "11917a028ca4: Verifying Checksum\n",
      "11917a028ca4: Download complete\n",
      "6cc007ad9140: Verifying Checksum\n",
      "6cc007ad9140: Download complete\n",
      "6c1698a608f3: Verifying Checksum\n",
      "6c1698a608f3: Download complete\n",
      "c7c110b9ca73: Verifying Checksum\n",
      "c7c110b9ca73: Download complete\n",
      "a1eed15b592d: Verifying Checksum\n",
      "a1eed15b592d: Download complete\n",
      "a6c378d11cbf: Verifying Checksum\n",
      "a6c378d11cbf: Download complete\n",
      "412964b3befe: Verifying Checksum\n",
      "412964b3befe: Download complete\n",
      "f9efed77ad39: Verifying Checksum\n",
      "f9efed77ad39: Download complete\n",
      "e18cf287723f: Verifying Checksum\n",
      "e18cf287723f: Download complete\n",
      "81a9cedab415: Verifying Checksum\n",
      "81a9cedab415: Download complete\n",
      "a1298f4ce990: Pull complete\n",
      "04a3282d9c4b: Pull complete\n",
      "9b0d3db6dc03: Pull complete\n",
      "8269c605f3f1: Pull complete\n",
      "6504d449e70c: Pull complete\n",
      "4e38f320d0d4: Pull complete\n",
      "b0a763e8ee03: Pull complete\n",
      "11917a028ca4: Pull complete\n",
      "a6c378d11cbf: Pull complete\n",
      "6cc007ad9140: Pull complete\n",
      "6c1698a608f3: Pull complete\n",
      "c7c110b9ca73: Pull complete\n",
      "a1eed15b592d: Pull complete\n",
      "412964b3befe: Pull complete\n",
      "f9efed77ad39: Pull complete\n",
      "81a9cedab415: Pull complete\n",
      "e18cf287723f: Pull complete\n",
      "Digest: sha256:0075a1dc7e0a80914a0d9bec230bb483e0e90197efa7ec684aa3b2f3073c6848\n",
      "Status: Downloaded newer image for pipelines5112a485.azurecr.io/azureml/azureml_080bb68af85f96b85eb7cff522629683:latest\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_3e11f9e75c8a8d7bc0659f3abd4c450373af1d0600864c784b3c97723b044749_d.txt\n",
      "===============================================================================================================\n",
      "bash: /azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Entering job preparation. Current time:2020-06-12T22:48:37.580342\n",
      "Starting job preparation. Current time:2020-06-12T22:48:38.248818\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: 639874b4-fe43-4687-b1cc-6719e34740b7\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 50\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "downloadDataStore - Download from datastores if requested.\n",
      "Entering context manager injector. Current time:2020-06-12T22:48:43.210988\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "bash: /azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "bash: /azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Entering context manager injector. Current time:2020-06-12T22:48:47.588595\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 106\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ dataprep.py ] with arguments: ['--output_path', '/mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/4e8dd414-da72-49da-85ef-b3f21506ba81/mounts/workspaceblobstore/azureml/4e8dd414-da72-49da-85ef-b3f21506ba81/titanic_train']\n",
      "After variable expansion, calling script [ dataprep.py ] with arguments: ['--output_path', '/mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/4e8dd414-da72-49da-85ef-b3f21506ba81/mounts/workspaceblobstore/azureml/4e8dd414-da72-49da-85ef-b3f21506ba81/titanic_train']\n",
      "\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 106\n",
      "\n",
      "\n",
      "The experiment failed. Finalizing run...\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_3e11f9e75c8a8d7bc0659f3abd4c450373af1d0600864c784b3c97723b044749_d.txt\n",
      "===============================================================================================================\n",
      "bash: /azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Entering job release. Current time:2020-06-12T22:48:54.900397\n",
      "Starting job release. Current time:2020-06-12T22:48:56.145416\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 152\n",
      "Entering context manager injector. Current time:2020-06-12T22:48:56.169130\n",
      "Job release is complete. Current time:2020-06-12T22:49:00.557145\n",
      "\n",
      "StepRun(dataprep) Execution Summary\n",
      "====================================\n",
      "StepRun( dataprep ) Status: Failed\n",
      "\n",
      "Warnings:\n",
      "This compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\n",
      "Please enable Docker in the environment section of your run configuration to stop seeing this warning message.\n",
      "{\n",
      "  \"error\": {\n",
      "    \"code\": \"UserError\",\n",
      "    \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\",\n",
      "    \"messageFormat\": null,\n",
      "    \"messageParameters\": null,\n",
      "    \"referenceCode\": null,\n",
      "    \"detailsUri\": null,\n",
      "    \"target\": null,\n",
      "    \"details\": [],\n",
      "    \"innerError\": null,\n",
      "    \"debugInfo\": null\n",
      "  },\n",
      "  \"correlation\": {\n",
      "    \"operation\": null,\n",
      "    \"request\": \"5d49358f5b9f0f30\"\n",
      "  },\n",
      "  \"environment\": \"westus\",\n",
      "  \"location\": \"westus\",\n",
      "  \"time\": \"2020-06-12T22:49:04.4115698+00:00\",\n",
      "  \"componentName\": \"execution-worker\"\n",
      "}\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with ModuleNotFoundError: No module named 'pyarrow'\",\n        \"detailsUri\": \"https://aka.ms/azureml-known-errors\",\n        \"details\": [],\n        \"debugInfo\": {\n            \"type\": \"ModuleNotFoundError\",\n            \"message\": \"No module named 'pyarrow'\",\n            \"stackTrace\": \"  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/4e8dd414-da72-49da-85ef-b3f21506ba81/mounts/workspaceblobstore/azureml/4e8dd414-da72-49da-85ef-b3f21506ba81/azureml-setup/context_manager_injector.py\\\", line 148, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"/azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/python3.6/runpy.py\\\", line 263, in run_path\\n    pkg_name=pkg_name, script_name=fname)\\n  File \\\"/azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/python3.6/runpy.py\\\", line 96, in _run_module_code\\n    mod_name, mod_spec, pkg_name, script_name)\\n  File \\\"/azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/python3.6/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"dataprep.py\\\", line 5, in <module>\\n    import pyarrow as pa\\n\"\n        },\n        \"messageParameters\": {}\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with ModuleNotFoundError: No module named 'pyarrow'\\\",\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-known-errors\\\",\\n        \\\"details\\\": [],\\n        \\\"debugInfo\\\": {\\n            \\\"type\\\": \\\"ModuleNotFoundError\\\",\\n            \\\"message\\\": \\\"No module named 'pyarrow'\\\",\\n            \\\"stackTrace\\\": \\\"  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/4e8dd414-da72-49da-85ef-b3f21506ba81/mounts/workspaceblobstore/azureml/4e8dd414-da72-49da-85ef-b3f21506ba81/azureml-setup/context_manager_injector.py\\\\\\\", line 148, in execute_with_context\\\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\\\\\"__main__\\\\\\\")\\\\n  File \\\\\\\"/azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/python3.6/runpy.py\\\\\\\", line 263, in run_path\\\\n    pkg_name=pkg_name, script_name=fname)\\\\n  File \\\\\\\"/azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/python3.6/runpy.py\\\\\\\", line 96, in _run_module_code\\\\n    mod_name, mod_spec, pkg_name, script_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/python3.6/runpy.py\\\\\\\", line 85, in _run_code\\\\n    exec(code, run_globals)\\\\n  File \\\\\\\"dataprep.py\\\\\\\", line 5, in <module>\\\\n    import pyarrow as pa\\\\n\\\"\\n        },\\n        \\\"messageParameters\\\": {}\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-8f83d25d4fd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Use configured environment? {USE_CURATED_ENV} Duration in seconds {duration}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/miniconda3/envs/azureml/lib/python3.7/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    289\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                             step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[0;32m--> 291\u001b[0;31m                                                          raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    292\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtimeout_seconds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/miniconda3/envs/azureml/lib/python3.7/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[0;32m--> 716\u001b[0;31m                                                raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The output streaming for the run interrupted.\\n\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/miniconda3/envs/azureml/lib/python3.7/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with ModuleNotFoundError: No module named 'pyarrow'\",\n        \"detailsUri\": \"https://aka.ms/azureml-known-errors\",\n        \"details\": [],\n        \"debugInfo\": {\n            \"type\": \"ModuleNotFoundError\",\n            \"message\": \"No module named 'pyarrow'\",\n            \"stackTrace\": \"  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/4e8dd414-da72-49da-85ef-b3f21506ba81/mounts/workspaceblobstore/azureml/4e8dd414-da72-49da-85ef-b3f21506ba81/azureml-setup/context_manager_injector.py\\\", line 148, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"/azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/python3.6/runpy.py\\\", line 263, in run_path\\n    pkg_name=pkg_name, script_name=fname)\\n  File \\\"/azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/python3.6/runpy.py\\\", line 96, in _run_module_code\\n    mod_name, mod_spec, pkg_name, script_name)\\n  File \\\"/azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/python3.6/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"dataprep.py\\\", line 5, in <module>\\n    import pyarrow as pa\\n\"\n        },\n        \"messageParameters\": {}\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with ModuleNotFoundError: No module named 'pyarrow'\\\",\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-known-errors\\\",\\n        \\\"details\\\": [],\\n        \\\"debugInfo\\\": {\\n            \\\"type\\\": \\\"ModuleNotFoundError\\\",\\n            \\\"message\\\": \\\"No module named 'pyarrow'\\\",\\n            \\\"stackTrace\\\": \\\"  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/4e8dd414-da72-49da-85ef-b3f21506ba81/mounts/workspaceblobstore/azureml/4e8dd414-da72-49da-85ef-b3f21506ba81/azureml-setup/context_manager_injector.py\\\\\\\", line 148, in execute_with_context\\\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\\\\\"__main__\\\\\\\")\\\\n  File \\\\\\\"/azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/python3.6/runpy.py\\\\\\\", line 263, in run_path\\\\n    pkg_name=pkg_name, script_name=fname)\\\\n  File \\\\\\\"/azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/python3.6/runpy.py\\\\\\\", line 96, in _run_module_code\\\\n    mod_name, mod_spec, pkg_name, script_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_6162e2d2e32d3224150f0271123ffbfb/lib/python3.6/runpy.py\\\\\\\", line 85, in _run_code\\\\n    exec(code, run_globals)\\\\n  File \\\\\\\"dataprep.py\\\\\\\", line 5, in <module>\\\\n    import pyarrow as pa\\\\n\\\"\\n        },\\n        \\\"messageParameters\\\": {}\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "start = time.time()\n",
    "run.wait_for_completion()\n",
    "duration = start - time.time()\n",
    "print(f\"Use configured environment? {USE_CURATED_ENV} Duration in seconds {duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automl_run = next(r for r in run.get_children() if r.name == 'AutoML_Classification')\n",
    "# outputs = automl_run.get_outputs()\n",
    "# metrics = outputs['default_metrics_AutoML_Classification']\n",
    "# model = outputs['default_model_AutoML_Classification']\n",
    "\n",
    "# metrics.get_port_data_reference().download('.')\n",
    "# model.get_port_data_reference().download('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_output = run.get_pipeline_output('metrics_output')\n",
    "num_file_downloaded = metrics_output.download('.', show_progress=True)\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import json\n",
    "with open(metrics_output._path_on_datastore) as f:\n",
    "   metrics_output_result = f.read()\n",
    "   \n",
    "deserialized_metrics_output = json.loads(metrics_output_result)\n",
    "df = pd.DataFrame(deserialized_metrics_output)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_file_downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(metrics_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
