{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/miniconda3/envs/azureml/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "from azureml.core import Dataset, ComputeTarget\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "from azureml.core import Experiment \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='pipelines', subscription_id='65a1016d-0f67-45d2-b838-b8f373d6d52e', resource_group='laobri-ml')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config(auth=InteractiveLoginAuthentication(tenant_id=os.environ[\"AML_TENANT_ID\"]))\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_name = \"cpu-compute3\"\n",
    "if not compute_name in ws.compute_targets :\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\n",
    "                                                                min_nodes=0,\n",
    "                                                                max_nodes=1)\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # Show the result\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmlCompute(workspace=Workspace.create(name='pipelines', subscription_id='65a1016d-0f67-45d2-b838-b8f373d6d52e', resource_group='laobri-ml'), name=cpu-compute3, id=/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourceGroups/laobri-ml/providers/Microsoft.MachineLearningServices/workspaces/pipelines/computes/cpu-compute3, type=AmlCompute, provisioning_state=Succeeded, location=westus, tags=None)\n"
     ]
    }
   ],
   "source": [
    "compute = AmlCompute(ws, compute_name)\n",
    "print(compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_run_config = RunConfiguration()\n",
    "aml_run_config.target = compute\n",
    "\n",
    "# Use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "aml_run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# Specify CondaDependencies obj, add necessary packages\n",
    "aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=['pandas','scikit-learn', 'pyarrow'], \n",
    "    pip_packages=['azureml-sdk', 'azureml-dataprep[fuse,pandas]'], \n",
    "    pin_sdk_version=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Grab an open dataset and register it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is baseline data. If the `Dataset` does not exist, create and register it. Not a part of the Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'titanic_ds' in ws.datasets.keys() :\n",
    "    # create a TabularDataset from Titanic training data\n",
    "    web_paths = ['https://dprepdata.blob.core.windows.net/demo/Titanic.csv',\n",
    "                 'https://dprepdata.blob.core.windows.net/demo/Titanic2.csv']\n",
    "    titanic_ds = Dataset.Tabular.from_delimited_files(path=web_paths)\n",
    "\n",
    "    titanic_ds.register(workspace = ws,\n",
    "                                     name = 'titanic_ds',\n",
    "                                     description = 'new titanic training data',\n",
    "                                     create_new_version = True)\n",
    "\n",
    "titanic_ds = Dataset.get_by_name(ws, 'titanic_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "azureml.data.tabular_dataset.TabularDataset"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(titanic_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'titanic_files_ds' in ws.datasets.keys() :\n",
    "    # create a TabularDataset from Titanic training data\n",
    "    web_paths = ['https://dprepdata.blob.core.windows.net/demo/Titanic.csv',\n",
    "                 'https://dprepdata.blob.core.windows.net/demo/Titanic2.csv']\n",
    "    titanic_ds = Dataset.File.from_files(path=web_paths)\n",
    "\n",
    "    titanic_ds.register(workspace = ws,\n",
    "                                     name = 'titanic_files_ds',\n",
    "                                     description = 'File Dataset of titanic training data',\n",
    "                                     create_new_version = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataprep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataprep.py\n",
    "from azureml.core import Run\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "\n",
    "RANDOM_SEED=42\n",
    "\n",
    "def prepare_age(df):\n",
    "    # Fill in missing Age values from distribution of present Age values \n",
    "    mean = df[\"Age\"].mean()\n",
    "    std = df[\"Age\"].std()\n",
    "    is_null = df[\"Age\"].isnull().sum()\n",
    "    # compute enough (== is_null().sum()) random numbers between the mean, std\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    # fill NaN values in Age column with random values generated\n",
    "    age_slice = df[\"Age\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    df[\"Age\"] = age_slice\n",
    "    df[\"Age\"] = df[\"Age\"].astype(int)\n",
    "    \n",
    "    # Quantize age into 5 classes\n",
    "    df['Age_Group'] = pd.qcut(df['Age'],5, labels=False)\n",
    "    df.drop(['Age'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def prepare_fare(df):\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    df['Fare_Group'] = pd.qcut(df['Fare'],5,labels=False)\n",
    "    df.drop(['Fare'], axis=1, inplace=True)\n",
    "    return df \n",
    "\n",
    "def prepare_genders(df):\n",
    "    genders = {\"male\": 0, \"female\": 1, \"unknown\": 2}\n",
    "    df['Sex'] = df['Sex'].map(genders)\n",
    "    df['Sex'].fillna(2, inplace=True)\n",
    "    df['Sex'] = df['Sex'].astype(int)\n",
    "    return df\n",
    "\n",
    "def prepare_embarked(df):\n",
    "    df['Embarked'].replace('', 'U', inplace=True)\n",
    "    df['Embarked'].fillna('U', inplace=True)\n",
    "    ports = {\"S\": 0, \"C\": 1, \"Q\": 2, \"U\": 3}\n",
    "    df['Embarked'] = df['Embarked'].map(ports)\n",
    "    return df\n",
    "    \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_path', dest='output_path', required=True)\n",
    "args = parser.parse_args()\n",
    "    \n",
    "titanic_ds = Run.get_context().input_datasets['titanic_ds']\n",
    "df = titanic_ds.to_pandas_dataframe().drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "df = prepare_embarked(prepare_genders(prepare_fare(prepare_age(df))))\n",
    "\n",
    "os.makedirs(os.path.dirname(args.output_path), exist_ok=True)\n",
    "pq.write_table(pa.Table.from_pandas(df), args.output_path)\n",
    "\n",
    "print(f\"Wrote test to {args.output_path} and train to {args.output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepped_data_path = PipelineData(\"titanic_train\", datastore).as_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprep_step = PythonScriptStep(\n",
    "    name=\"dataprep\", \n",
    "    script_name=\"dataprep.py\", \n",
    "    compute_target=compute, \n",
    "    runconfig=aml_run_config,\n",
    "    arguments=[\"--output_path\", prepped_data_path],\n",
    "    inputs=[titanic_ds.as_named_input(\"titanic_ds\")],\n",
    "    outputs=[prepped_data_path]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train with AutoMLStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - The AutoMLConfig inputs you have specified will soon be deprecated. Please use the AutoMLConfig shown in our documentation: https://aka.ms/AutoMLConfig\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML config created.\n"
     ]
    }
   ],
   "source": [
    "prepped_data_potds = prepped_data_path.parse_parquet_files(file_extension=None)\n",
    "\n",
    "X = prepped_data_potds.drop_columns('Survived')\n",
    "y = prepped_data_potds.keep_columns('Survived')\n",
    "\n",
    "train_model_folder = './scripts/trainmodel'\n",
    "# Change iterations to a reasonable number (50) to get better accuracy\n",
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\" : 20,\n",
    "    \"iterations\" : 50,\n",
    "    \"primary_metric\" : 'AUC_weighted',\n",
    "    \"n_cross_validations\" : 2\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automated_ml_errors.log',\n",
    "                             path = train_model_folder,\n",
    "                             compute_target = compute,\n",
    "                             run_configuration = aml_run_config,\n",
    "                             featurization = 'auto',\n",
    "                             X = X,\n",
    "                             y = y,\n",
    "                             **automl_settings)\n",
    "                             \n",
    "print(\"AutoML config created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_step created.\n"
     ]
    }
   ],
   "source": [
    "train_step = AutoMLStep(name='AutoML_Classification',\n",
    "                                 automl_config=automl_config,\n",
    "                                 passthru_automl_config=False,\n",
    "                                 allow_reuse=True)\n",
    "print(\"train_step created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not 'titanic_automl' in ws.experiments.keys() :\n",
    "    Experiment(ws, 'titanic_automl')\n",
    "experiment = ws.experiments['titanic_automl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(ws, [dataprep_step, train_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step dataprep [9fdf6357][639c7dcb-f77d-4575-929f-07bdd5153f83], (This step will run and generate new outputs)\n",
      "Created step AutoML_Classification [66b8ab90][571d3341-c354-44e5-86fc-8f13471e5777], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun e725300c-42d1-424a-bcc6-949f67b68b15\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/e725300c-42d1-424a-bcc6-949f67b68b15?wsid=/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourcegroups/laobri-ml/workspaces/pipelines\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(pipeline, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: e725300c-42d1-424a-bcc6-949f67b68b15\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/e725300c-42d1-424a-bcc6-949f67b68b15?wsid=/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourcegroups/laobri-ml/workspaces/pipelines\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 752c1768-0cba-4fc7-b429-8091a50fd302\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/752c1768-0cba-4fc7-b429-8091a50fd302?wsid=/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourcegroups/laobri-ml/workspaces/pipelines\n",
      "StepRun( dataprep ) Status: NotStarted\n",
      "StepRun( dataprep ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_303589db597669d23c9339e30d8e37f5624b1aeaf57b65a356a79e3a03a13417_d.txt\n",
      "========================================================================================================================\n",
      "2020-04-25T01:08:57Z Starting output-watcher...\n",
      "2020-04-25T01:08:57Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_b75709396e112eb3c528ff9421e54d7f\n",
      "a1298f4ce990: Pulling fs layer\n",
      "04a3282d9c4b: Pulling fs layer\n",
      "9b0d3db6dc03: Pulling fs layer\n",
      "8269c605f3f1: Pulling fs layer\n",
      "6504d449e70c: Pulling fs layer\n",
      "4e38f320d0d4: Pulling fs layer\n",
      "b0a763e8ee03: Pulling fs layer\n",
      "11917a028ca4: Pulling fs layer\n",
      "a6c378d11cbf: Pulling fs layer\n",
      "6cc007ad9140: Pulling fs layer\n",
      "6c1698a608f3: Pulling fs layer\n",
      "b973edc5c15f: Pulling fs layer\n",
      "bfa2b834c7db: Pulling fs layer\n",
      "29a23d12f534: Pulling fs layer\n",
      "0409a3f615fa: Pulling fs layer\n",
      "b5ef8cf9303f: Pulling fs layer\n",
      "20d705353530: Pulling fs layer\n",
      "6cc007ad9140: Waiting\n",
      "6c1698a608f3: Waiting\n",
      "b973edc5c15f: Waiting\n",
      "bfa2b834c7db: Waiting\n",
      "29a23d12f534: Waiting\n",
      "8269c605f3f1: Waiting\n",
      "6504d449e70c: Waiting\n",
      "4e38f320d0d4: Waiting\n",
      "0409a3f615fa: Waiting\n",
      "b5ef8cf9303f: Waiting\n",
      "b0a763e8ee03: Waiting\n",
      "20d705353530: Waiting\n",
      "11917a028ca4: Waiting\n",
      "a6c378d11cbf: Waiting\n",
      "04a3282d9c4b: Verifying Checksum\n",
      "04a3282d9c4b: Download complete\n",
      "9b0d3db6dc03: Download complete\n",
      "8269c605f3f1: Verifying Checksum\n",
      "8269c605f3f1: Download complete\n",
      "a1298f4ce990: Verifying Checksum\n",
      "a1298f4ce990: Download complete\n",
      "4e38f320d0d4: Verifying Checksum\n",
      "4e38f320d0d4: Download complete\n",
      "6504d449e70c: Verifying Checksum\n",
      "6504d449e70c: Download complete\n",
      "b0a763e8ee03: Verifying Checksum\n",
      "b0a763e8ee03: Download complete\n",
      "6cc007ad9140: Verifying Checksum\n",
      "6cc007ad9140: Download complete\n",
      "6c1698a608f3: Verifying Checksum\n",
      "6c1698a608f3: Download complete\n",
      "11917a028ca4: Verifying Checksum\n",
      "11917a028ca4: Download complete\n",
      "a6c378d11cbf: Verifying Checksum\n",
      "a6c378d11cbf: Download complete\n",
      "b973edc5c15f: Verifying Checksum\n",
      "b973edc5c15f: Download complete\n",
      "bfa2b834c7db: Verifying Checksum\n",
      "bfa2b834c7db: Download complete\n",
      "0409a3f615fa: Verifying Checksum\n",
      "0409a3f615fa: Download complete\n",
      "29a23d12f534: Download complete\n",
      "20d705353530: Verifying Checksum\n",
      "20d705353530: Download complete\n",
      "b5ef8cf9303f: Verifying Checksum\n",
      "b5ef8cf9303f: Download complete\n",
      "a1298f4ce990: Pull complete\n",
      "04a3282d9c4b: Pull complete\n",
      "9b0d3db6dc03: Pull complete\n",
      "8269c605f3f1: Pull complete\n",
      "6504d449e70c: Pull complete\n",
      "4e38f320d0d4: Pull complete\n",
      "b0a763e8ee03: Pull complete\n",
      "11917a028ca4: Pull complete\n",
      "a6c378d11cbf: Pull complete\n",
      "6cc007ad9140: Pull complete\n",
      "6c1698a608f3: Pull complete\n",
      "b973edc5c15f: Pull complete\n",
      "bfa2b834c7db: Pull complete\n",
      "29a23d12f534: Pull complete\n",
      "0409a3f615fa: Pull complete\n",
      "b5ef8cf9303f: Pull complete\n",
      "20d705353530: Pull complete\n",
      "Digest: sha256:62b7fce4c24105552a76254a9d0302cb865ceaf6bfe5a270bab062b65807110f\n",
      "Status: Downloaded newer image for pipelines5112a485.azurecr.io/azureml/azureml_b75709396e112eb3c528ff9421e54d7f:latest\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_303589db597669d23c9339e30d8e37f5624b1aeaf57b65a356a79e3a03a13417_d.txt\n",
      "===============================================================================================================\n",
      "Starting job_prep.py script\n",
      "Starting job preparation. Current time:2020-04-25T01:12:13.089145\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: 0559decc-fde2-46e3-b6f9-9a7c4ba54dd4\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 76\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "Download from datastores if requested.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 129\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ dataprep.py ] with arguments: ['--output_path', '/mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/752c1768-0cba-4fc7-b429-8091a50fd302/mounts/workspaceblobstore/azureml/752c1768-0cba-4fc7-b429-8091a50fd302/titanic_train']\n",
      "After variable expansion, calling script [ dataprep.py ] with arguments: ['--output_path', '/mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/752c1768-0cba-4fc7-b429-8091a50fd302/mounts/workspaceblobstore/azureml/752c1768-0cba-4fc7-b429-8091a50fd302/titanic_train']\n",
      "\n",
      "usage: dataprep.py [-h] --train_path TRAIN_PATH --test_path TEST_PATH\n",
      "dataprep.py: error: the following arguments are required: --train_path, --test_path\n",
      "\n",
      "\n",
      "The experiment failed. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "1 items cleaning up...\n",
      "Cleanup took 0.052187442779541016 seconds\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 129\n",
      "2020/04/25 01:12:22 mpirun version string: {\n",
      "Intel(R) MPI Library for Linux* OS, Version 2018 Update 3 Build 20180411 (id: 18329)\n",
      "Copyright 2003-2018 Intel Corporation.\n",
      "}\n",
      "2020/04/25 01:12:22 MPI publisher: intel ; version: 2018\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_303589db597669d23c9339e30d8e37f5624b1aeaf57b65a356a79e3a03a13417_d.txt\n",
      "===============================================================================================================\n",
      "Starting job release. Current time:2020-04-25T01:12:26.913564\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 170\n",
      "Job release is complete. Current time:2020-04-25T01:12:30.778115\n",
      "\n",
      "StepRun(dataprep) Execution Summary\n",
      "====================================\n",
      "StepRun( dataprep ) Status: Failed\n",
      "\n",
      "Warnings:\n",
      "This compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\n",
      "Please enable Docker in the environment section of your run configuration to stop seeing this warning message.\n",
      "{\n",
      "  \"error\": {\n",
      "    \"code\": \"UserError\",\n",
      "    \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\",\n",
      "    \"messageFormat\": null,\n",
      "    \"messageParameters\": null,\n",
      "    \"referenceCode\": null,\n",
      "    \"detailsUri\": null,\n",
      "    \"target\": null,\n",
      "    \"details\": [],\n",
      "    \"innerError\": null,\n",
      "    \"debugInfo\": null\n",
      "  },\n",
      "  \"correlation\": {\n",
      "    \"operation\": null,\n",
      "    \"request\": \"5993d3dc58fde1ce\"\n",
      "  },\n",
      "  \"environment\": \"westus\",\n",
      "  \"location\": \"westus\",\n",
      "  \"time\": \"2020-04-25T01:12:33.1262975+00:00\"\n",
      "}\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with SystemExit: 2\",\n        \"detailsUri\": \"https://aka.ms/azureml-known-errors\",\n        \"details\": [],\n        \"debugInfo\": {\n            \"type\": \"SystemExit\",\n            \"message\": \"2\",\n            \"stackTrace\": \"  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/752c1768-0cba-4fc7-b429-8091a50fd302/mounts/workspaceblobstore/azureml/752c1768-0cba-4fc7-b429-8091a50fd302/azureml-setup/context_manager_injector.py\\\", line 127, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\", line 263, in run_path\\n    pkg_name=pkg_name, script_name=fname)\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\", line 96, in _run_module_code\\n    mod_name, mod_spec, pkg_name, script_name)\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"dataprep.py\\\", line 53, in <module>\\n    args = parser.parse_args()\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\", line 1730, in parse_args\\n    args, argv = self.parse_known_args(args, namespace)\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\", line 1762, in parse_known_args\\n    namespace, args = self._parse_known_args(args, namespace)\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\", line 1997, in _parse_known_args\\n    ', '.join(required_actions))\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\", line 2389, in error\\n    self.exit(2, _('%(prog)s: error: %(message)s\\\\n') % args)\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\", line 2376, in exit\\n    _sys.exit(status)\\n\"\n        },\n        \"messageParameters\": {}\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with SystemExit: 2\\\",\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-known-errors\\\",\\n        \\\"details\\\": [],\\n        \\\"debugInfo\\\": {\\n            \\\"type\\\": \\\"SystemExit\\\",\\n            \\\"message\\\": \\\"2\\\",\\n            \\\"stackTrace\\\": \\\"  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/752c1768-0cba-4fc7-b429-8091a50fd302/mounts/workspaceblobstore/azureml/752c1768-0cba-4fc7-b429-8091a50fd302/azureml-setup/context_manager_injector.py\\\\\\\", line 127, in execute_with_context\\\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\\\\\"__main__\\\\\\\")\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\\\\\", line 263, in run_path\\\\n    pkg_name=pkg_name, script_name=fname)\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\\\\\", line 96, in _run_module_code\\\\n    mod_name, mod_spec, pkg_name, script_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\\\\\", line 85, in _run_code\\\\n    exec(code, run_globals)\\\\n  File \\\\\\\"dataprep.py\\\\\\\", line 53, in <module>\\\\n    args = parser.parse_args()\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\\\\\", line 1730, in parse_args\\\\n    args, argv = self.parse_known_args(args, namespace)\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\\\\\", line 1762, in parse_known_args\\\\n    namespace, args = self._parse_known_args(args, namespace)\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\\\\\", line 1997, in _parse_known_args\\\\n    ', '.join(required_actions))\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\\\\\", line 2389, in error\\\\n    self.exit(2, _('%(prog)s: error: %(message)s\\\\\\\\n') % args)\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\\\\\", line 2376, in exit\\\\n    _sys.exit(status)\\\\n\\\"\\n        },\\n        \\\"messageParameters\\\": {}\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0d078c003346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/miniconda3/envs/azureml/lib/python3.7/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    289\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                             step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[0;32m--> 291\u001b[0;31m                                                          raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    292\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtimeout_seconds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/miniconda3/envs/azureml/lib/python3.7/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[0;32m--> 716\u001b[0;31m                                                raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The output streaming for the run interrupted.\\n\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/miniconda3/envs/azureml/lib/python3.7/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with SystemExit: 2\",\n        \"detailsUri\": \"https://aka.ms/azureml-known-errors\",\n        \"details\": [],\n        \"debugInfo\": {\n            \"type\": \"SystemExit\",\n            \"message\": \"2\",\n            \"stackTrace\": \"  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/752c1768-0cba-4fc7-b429-8091a50fd302/mounts/workspaceblobstore/azureml/752c1768-0cba-4fc7-b429-8091a50fd302/azureml-setup/context_manager_injector.py\\\", line 127, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\", line 263, in run_path\\n    pkg_name=pkg_name, script_name=fname)\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\", line 96, in _run_module_code\\n    mod_name, mod_spec, pkg_name, script_name)\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"dataprep.py\\\", line 53, in <module>\\n    args = parser.parse_args()\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\", line 1730, in parse_args\\n    args, argv = self.parse_known_args(args, namespace)\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\", line 1762, in parse_known_args\\n    namespace, args = self._parse_known_args(args, namespace)\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\", line 1997, in _parse_known_args\\n    ', '.join(required_actions))\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\", line 2389, in error\\n    self.exit(2, _('%(prog)s: error: %(message)s\\\\n') % args)\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\", line 2376, in exit\\n    _sys.exit(status)\\n\"\n        },\n        \"messageParameters\": {}\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with SystemExit: 2\\\",\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-known-errors\\\",\\n        \\\"details\\\": [],\\n        \\\"debugInfo\\\": {\\n            \\\"type\\\": \\\"SystemExit\\\",\\n            \\\"message\\\": \\\"2\\\",\\n            \\\"stackTrace\\\": \\\"  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/pipelines/azureml/752c1768-0cba-4fc7-b429-8091a50fd302/mounts/workspaceblobstore/azureml/752c1768-0cba-4fc7-b429-8091a50fd302/azureml-setup/context_manager_injector.py\\\\\\\", line 127, in execute_with_context\\\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\\\\\"__main__\\\\\\\")\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\\\\\", line 263, in run_path\\\\n    pkg_name=pkg_name, script_name=fname)\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\\\\\", line 96, in _run_module_code\\\\n    mod_name, mod_spec, pkg_name, script_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\\\\\", line 85, in _run_code\\\\n    exec(code, run_globals)\\\\n  File \\\\\\\"dataprep.py\\\\\\\", line 53, in <module>\\\\n    args = parser.parse_args()\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\\\\\", line 1730, in parse_args\\\\n    args, argv = self.parse_known_args(args, namespace)\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\\\\\", line 1762, in parse_known_args\\\\n    namespace, args = self._parse_known_args(args, namespace)\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\\\\\", line 1997, in _parse_known_args\\\\n    ', '.join(required_actions))\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\\\\\", line 2389, in error\\\\n    self.exit(2, _('%(prog)s: error: %(message)s\\\\\\\\n') % args)\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/argparse.py\\\\\\\", line 2376, in exit\\\\n    _sys.exit(status)\\\\n\\\"\\n        },\\n        \\\"messageParameters\\\": {}\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "run.wait_for_completion()\n",
    "run.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_run = next(r for r in run.get_children() if r.name == 'AutoML_Classification')\n",
    "outputs = automl_run.get_outputs()\n",
    "metrics = outputs['default_metrics_AutoML_Classification']\n",
    "model = outputs['default_model_AutoML_Classification']\n",
    "\n",
    "metrics.get_port_data_reference().download('.')\n",
    "model.get_port_data_reference().download('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-71cacc06bb91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
